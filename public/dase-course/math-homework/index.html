<!DOCTYPE html>
<html lang="zh" dir="auto" data-theme="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>数学基础——数学篇作业集 | Minjie&#39;s Blog</title>
<meta name="keywords" content="线性代数, 矩阵分解, 数值分析, 数学证明">
<meta name="description" content="本作业集包含四次数学基础作业的完整解答，涵盖：
矩阵范数理论、特征值与特征多项式、正交投影、
LU分解、Cholesky分解、QR分解、SVD奇异值分解、
最小二乘法、图像处理应用（旋转与压缩）、
以及 kNN 分类器的实现。每道题目都配有详细的
数学推导过程和部分编程实现代码。
">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/dase-course/math-homework/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/code.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/code.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/code.png">
<link rel="apple-touch-icon" href="http://localhost:1313/code.png">
<link rel="mask-icon" href="http://localhost:1313/code.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="http://localhost:1313/dase-course/math-homework/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel="stylesheet">
<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Minjie&#39;s Blog (Alt + H)">Minjie&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="Minjie&#39;s Blog">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="关于我">
                    <span>关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      数学基础——数学篇作业集
    </h1>
    <div class="post-description">
      本作业集包含四次数学基础作业的完整解答，涵盖：
矩阵范数理论、特征值与特征多项式、正交投影、
LU分解、Cholesky分解、QR分解、SVD奇异值分解、
最小二乘法、图像处理应用（旋转与压缩）、
以及 kNN 分类器的实现。每道题目都配有详细的
数学推导过程和部分编程实现代码。

    </div>
    <div class="post-meta"><span title='2025-12-29 13:25:26 +0800 CST'>2025年12月29日</span>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e4%b8%80" aria-label="作业一">作业一</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1%e5%b9%82%e7%ad%89%e7%9f%a9%e9%98%b5%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="习题 1：幂等矩阵的性质">习题 1：幂等矩阵的性质</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2%e7%89%b9%e5%be%81%e5%a4%9a%e9%a1%b9%e5%bc%8f%e7%9a%84%e7%9b%b8%e7%ad%89%e6%80%a7" aria-label="习题 2：特征多项式的相等性">习题 2：特征多项式的相等性</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3%e7%9f%a9%e9%98%b5%e8%8c%83%e6%95%b0%e7%9a%84%e8%ae%a1%e7%ae%97" aria-label="习题 3：矩阵范数的计算">习题 3：矩阵范数的计算</a><ul>
                        <ul>
                        
                <li>
                    <a href="#%e5%af%b9%e4%ba%8e%e7%9f%a9%e9%98%b5" aria-label="对于矩阵 $A_1$">对于矩阵 $A_1$</a></li>
                <li>
                    <a href="#%e5%af%b9%e4%ba%8e%e7%9f%a9%e9%98%b5-1" aria-label="对于矩阵 $A_2$">对于矩阵 $A_2$</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4%e8%af%b1%e5%af%bc%e8%8c%83%e6%95%b0%e7%9a%84%e8%af%81%e6%98%8e" aria-label="习题 4：诱导范数的证明">习题 4：诱导范数的证明</a><ul>
                        <ul>
                        
                <li>
                    <a href="#1-%e8%af%81%e6%98%8e-1-%e8%8c%83%e6%95%b0%e5%92%8c%e6%97%a0%e7%a9%b7%e8%8c%83%e6%95%b0" aria-label="(1) 证明 1-范数和无穷范数">(1) 证明 1-范数和无穷范数</a></li>
                <li>
                    <a href="#2-%e5%85%83%e7%b4%a0%e5%bd%a2%e5%bc%8f%e8%8c%83%e6%95%b0%e4%b8%8e%e8%af%b1%e5%af%bc%e8%8c%83%e6%95%b0%e7%9a%84%e5%85%b3%e7%b3%bb" aria-label="(2) 元素形式范数与诱导范数的关系">(2) 元素形式范数与诱导范数的关系</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5frobenius-%e8%8c%83%e6%95%b0%e7%9a%84%e4%b8%8d%e7%ad%89%e5%bc%8f" aria-label="习题 5：Frobenius 范数的不等式">习题 5：Frobenius 范数的不等式</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6%e8%b7%9d%e7%a6%bb%e5%87%bd%e6%95%b0%e7%9a%84%e5%88%a4%e6%96%ad" aria-label="习题 6：距离函数的判断">习题 6：距离函数的判断</a><ul>
                        <ul>
                        
                <li>
                    <a href="#1-%e4%bd%99%e5%bc%a6%e8%b7%9d%e7%a6%bb" aria-label="(1) 余弦距离">(1) 余弦距离</a></li>
                <li>
                    <a href="#2-%e7%bc%96%e8%be%91%e8%b7%9d%e7%a6%bb" aria-label="(2) 编辑距离">(2) 编辑距离</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-7%e6%ad%a3%e5%ae%9a%e7%9f%a9%e9%98%b5%e4%b8%8e%e5%90%91%e9%87%8f%e8%8c%83%e6%95%b0" aria-label="习题 7：正定矩阵与向量范数">习题 7：正定矩阵与向量范数</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-8%e7%9f%a9%e9%98%b5%e6%9c%80%e5%a4%a7%e8%8c%83%e6%95%b0" aria-label="习题 8：矩阵最大范数">习题 8：矩阵最大范数</a><ul>
                        
                <li>
                    <a href="#1-%e6%ad%a3%e5%ae%9a%e6%80%a7" aria-label="(1) 正定性">(1) 正定性</a></li>
                <li>
                    <a href="#2-%e9%bd%90%e6%ac%a1%e6%80%a7" aria-label="(2) 齐次性">(2) 齐次性</a></li>
                <li>
                    <a href="#3-%e4%b8%89%e8%a7%92%e4%b8%8d%e7%ad%89%e5%bc%8f" aria-label="(3) 三角不等式">(3) 三角不等式</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e4%ba%8c" aria-label="作业二">作业二</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1%e5%90%91%e9%87%8f%e7%9a%84%e6%ad%a3%e4%ba%a4%e6%8a%95%e5%bd%b1" aria-label="习题 1：向量的正交投影">习题 1：向量的正交投影</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2%e5%90%91%e9%87%8f%e5%9c%a8%e4%bb%bf%e5%b0%84%e5%ad%90%e7%a9%ba%e9%97%b4%e4%b8%8a%e7%9a%84%e6%ad%a3%e4%ba%a4%e6%8a%95%e5%bd%b1" aria-label="习题 2：向量在仿射子空间上的正交投影">习题 2：向量在仿射子空间上的正交投影</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3%e5%af%b9%e7%a7%b0%e6%ad%a3%e5%ae%9a%e7%9f%a9%e9%98%b5%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="习题 3：对称正定矩阵的性质">习题 3：对称正定矩阵的性质</a><ul>
                        
                <li>
                    <a href="#1-%e8%af%81%e6%98%8e" aria-label="(1) 证明 $A^T = A$">(1) 证明 $A^T = A$</a></li>
                <li>
                    <a href="#2-%e6%ad%a3%e4%ba%a4%e7%9f%a9%e9%98%b5%e4%bf%9d%e6%8c%81%e8%8c%83%e6%95%b0%e4%b8%8d%e5%8f%98" aria-label="(2) 正交矩阵保持范数不变">(2) 正交矩阵保持范数不变</a></li>
                <li>
                    <a href="#3-%e7%9f%a9%e9%98%b5%e8%8c%83%e6%95%b0%e7%9a%84%e5%85%b3%e7%b3%bb" aria-label="(3) 矩阵范数的关系">(3) 矩阵范数的关系</a></li>
                <li>
                    <a href="#4-%e5%85%b7%e4%bd%93%e8%ae%a1%e7%ae%97" aria-label="(4) 具体计算">(4) 具体计算</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4%e6%8a%95%e5%bd%b1%e7%9f%a9%e9%98%b5%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="习题 4：投影矩阵的性质">习题 4：投影矩阵的性质</a><ul>
                        
                <li>
                    <a href="#1-%e6%8a%95%e5%bd%b1%e7%9f%a9%e9%98%b5%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%80%a7%e8%b4%a8" aria-label="(1) 投影矩阵的基本性质">(1) 投影矩阵的基本性质</a></li>
                <li>
                    <a href="#2-%e7%89%b9%e5%be%81%e5%80%bc%e4%b8%8e%e5%af%b9%e8%a7%92%e5%8c%96" aria-label="(2) 特征值与对角化">(2) 特征值与对角化</a></li>
                <li>
                    <a href="#3-%e8%a1%8c%e5%88%97%e5%bc%8f%e4%b8%ba%e9%9b%b6" aria-label="(3) 行列式为零">(3) 行列式为零</a></li>
                <li>
                    <a href="#4-householder-%e5%8f%98%e6%8d%a2" aria-label="(4) Householder 变换">(4) Householder 变换</a></li>
                <li>
                    <a href="#5-%e6%ad%a3%e4%ba%a4%e6%8a%95%e5%bd%b1%e7%9f%a9%e9%98%b5%e7%9a%84%e6%9e%84%e9%80%a0" aria-label="(5) 正交投影矩阵的构造">(5) 正交投影矩阵的构造</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5lu-%e5%88%86%e8%a7%a3%e7%9a%84%e5%88%a4%e6%96%ad" aria-label="习题 5：LU 分解的判断">习题 5：LU 分解的判断</a><ul>
                        
                <li>
                    <a href="#1-%e5%88%a4%e6%96%ad%e4%b8%8e%e5%88%86%e6%9e%90" aria-label="(1) 判断与分析">(1) 判断与分析</a></li>
                <li>
                    <a href="#2-lu-%e5%88%86%e8%a7%a3%e8%ae%a1%e7%ae%97" aria-label="(2) LU 分解计算">(2) LU 分解计算</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6%e7%9f%a9%e9%98%b5%e7%9a%84-lu-%e5%88%86%e8%a7%a3" aria-label="习题 6：矩阵的 LU 分解">习题 6：矩阵的 LU 分解</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e4%b8%89" aria-label="作业三">作业三</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1cholesky-%e5%88%86%e8%a7%a3%e4%b8%8d%e5%b8%a6%e5%b9%b3%e6%96%b9%e6%a0%b9" aria-label="习题 1：Cholesky 分解（不带平方根）">习题 1：Cholesky 分解（不带平方根）</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2%e5%af%b9%e7%a7%b0%e6%80%a7%e7%9a%84%e4%bf%9d%e6%8c%81" aria-label="习题 2：对称性的保持">习题 2：对称性的保持</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3qr-%e5%88%86%e8%a7%a3%e6%b1%82%e8%a7%a3%e7%ba%bf%e6%80%a7%e6%96%b9%e7%a8%8b%e7%bb%84" aria-label="习题 3：QR 分解求解线性方程组">习题 3：QR 分解求解线性方程组</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4cholesky-%e5%88%86%e8%a7%a3%e4%b8%8e%e8%8c%83%e6%95%b0" aria-label="习题 4：Cholesky 分解与范数">习题 4：Cholesky 分解与范数</a><ul>
                        
                <li>
                    <a href="#1-cholesky-%e5%88%86%e8%a7%a3" aria-label="(1) Cholesky 分解">(1) Cholesky 分解</a></li>
                <li>
                    <a href="#2-%e8%8c%83%e6%95%b0%e5%85%b3%e7%b3%bb" aria-label="(2) 范数关系">(2) 范数关系</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5svd-%e5%88%86%e8%a7%a3%e5%8f%8a%e5%ba%94%e7%94%a8" aria-label="习题 5：SVD 分解及应用">习题 5：SVD 分解及应用</a><ul>
                        
                <li>
                    <a href="#1-svd-%e5%88%86%e8%a7%a3" aria-label="(1) SVD 分解">(1) SVD 分解</a></li>
                <li>
                    <a href="#2-%e7%9f%a9%e9%98%b5%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="(2) 矩阵的性质">(2) 矩阵的性质</a></li>
                <li>
                    <a href="#3-%e6%9c%80%e4%bd%b3%e7%a7%a9-k-%e9%80%bc%e8%bf%91" aria-label="(3) 最佳秩-k 逼近">(3) 最佳秩-k 逼近</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6svd-%e5%88%86%e8%a7%a3%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="习题 6：SVD 分解的性质">习题 6：SVD 分解的性质</a><ul>
                        
                <li>
                    <a href="#1-%e9%80%86%e7%9f%a9%e9%98%b5%e7%9a%84-svd-%e5%88%86%e8%a7%a3" aria-label="(1) 逆矩阵的 SVD 分解">(1) 逆矩阵的 SVD 分解</a></li>
                <li>
                    <a href="#2-%e6%ad%a3%e4%ba%a4%e7%9f%a9%e9%98%b5%e7%9a%84-svd-%e5%88%86%e8%a7%a3" aria-label="(2) 正交矩阵的 SVD 分解">(2) 正交矩阵的 SVD 分解</a></li>
                <li>
                    <a href="#3-%e7%9b%b8%e4%bc%bc%e5%8f%98%e6%8d%a2%e4%bf%9d%e6%8c%81%e5%a5%87%e5%bc%82%e5%80%bc" aria-label="(3) 相似变换保持奇异值">(3) 相似变换保持奇异值</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-7%e9%80%9a%e8%bf%87%e5%af%b9%e8%a7%92%e5%8c%96%e8%8e%b7%e5%be%97-svd" aria-label="习题 7：通过对角化获得 SVD">习题 7：通过对角化获得 SVD</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-8%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e8%a7%a3%e7%9a%84%e6%ad%a3%e8%a7%84%e6%96%b9%e7%a8%8b" aria-label="习题 8：最小二乘解的正规方程">习题 8：最小二乘解的正规方程</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e5%9b%9b" aria-label="作业四">作业四</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1qr-%e5%88%86%e8%a7%a3%e6%b1%82%e8%a7%a3%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e9%97%ae%e9%a2%98" aria-label="习题 1：QR 分解求解最小二乘问题">习题 1：QR 分解求解最小二乘问题</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e8%a7%a3%e7%9a%84%e6%80%a7%e8%b4%a8" aria-label="习题 2：最小二乘解的性质">习题 2：最小二乘解的性质</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3gerschgorin-%e5%9c%86%e7%9b%98%e5%ae%9a%e7%90%86%e4%bc%b0%e8%ae%a1%e7%89%b9%e5%be%81%e5%80%bc%e8%8c%83%e5%9b%b4" aria-label="习题 3：Gerschgorin 圆盘定理估计特征值范围">习题 3：Gerschgorin 圆盘定理估计特征值范围</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4%e5%b9%82%e6%b3%95%e6%b1%82%e6%a8%a1%e6%9c%80%e5%a4%a7%e7%89%b9%e5%be%81%e5%80%bc" aria-label="习题 4：幂法求模最大特征值">习题 4：幂法求模最大特征值</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5%e5%8f%8d%e5%b9%82%e6%b3%95%e6%b1%82%e6%a8%a1%e6%9c%80%e5%b0%8f%e7%89%b9%e5%be%81%e5%80%bc" aria-label="习题 5：反幂法求模最小特征值">习题 5：反幂法求模最小特征值</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6%e5%8e%9f%e7%82%b9%e4%bd%8d%e7%a7%bb%e6%b3%95%e6%b1%82%e5%85%a8%e9%83%a8%e7%89%b9%e5%be%81%e5%80%bc" aria-label="习题 6：原点位移法求全部特征值">习题 6：原点位移法求全部特征值</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-7gerschgorin-%e5%9c%86%e7%9b%98%e5%ae%9a%e7%90%86%e4%b8%8e%e6%9d%a1%e4%bb%b6%e6%95%b0" aria-label="习题 7：Gerschgorin 圆盘定理与条件数">习题 7：Gerschgorin 圆盘定理与条件数</a><ul>
                        
                <li>
                    <a href="#1-gerschgorin-%e5%9c%86%e7%9b%98%e5%ae%9a%e7%90%86%e8%af%81%e6%98%8e" aria-label="(1) Gerschgorin 圆盘定理证明">(1) Gerschgorin 圆盘定理证明</a></li>
                <li>
                    <a href="#2-%e5%b9%82%e6%b3%95%e4%b8%8e%e5%8f%8d%e5%b9%82%e6%b3%95%e8%ae%a1%e7%ae%97%e6%9d%a1%e4%bb%b6%e6%95%b0" aria-label="(2) 幂法与反幂法计算条件数">(2) 幂法与反幂法计算条件数</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e4%ba%94" aria-label="作业五">作业五</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%97" aria-label="习题 1：梯度计算">习题 1：梯度计算</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2%e4%ba%8c%e6%ac%a1%e5%9e%8b%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="习题 2：二次型的梯度">习题 2：二次型的梯度</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3%e8%bf%b9%e5%be%ae%e5%88%86%e6%b3%95%e6%b1%82%e6%a2%af%e5%ba%a6" aria-label="习题 3：迹微分法求梯度">习题 3：迹微分法求梯度</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4softmax-%e5%87%bd%e6%95%b0%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="习题 4：Softmax 函数的梯度">习题 4：Softmax 函数的梯度</a><ul>
                        
                <li>
                    <a href="#1-%e8%af%81%e6%98%8e%e5%85%b3%e4%ba%8e--%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="(1) 证明关于 $z$ 的梯度">(1) 证明关于 $z$ 的梯度</a></li>
                <li>
                    <a href="#2-%e8%af%81%e6%98%8e%e5%85%b3%e4%ba%8e--%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="(2) 证明关于 $W$ 的梯度">(2) 证明关于 $W$ 的梯度</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5%e5%a4%9a%e5%85%83%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e7%9a%84%e6%9e%81%e5%a4%a7%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1" aria-label="习题 5：多元正态分布的极大似然估计">习题 5：多元正态分布的极大似然估计</a><ul>
                        
                <li>
                    <a href="#1-%e5%85%b3%e4%ba%8e--%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="(1) 关于 $\mu$ 的梯度">(1) 关于 $\mu$ 的梯度</a></li>
                <li>
                    <a href="#2-%e5%85%b3%e4%ba%8e--%e7%9a%84%e6%a2%af%e5%ba%a6" aria-label="(2) 关于 $\Sigma$ 的梯度">(2) 关于 $\Sigma$ 的梯度</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6%e4%ba%92%e4%bf%a1%e6%81%af%e7%9a%84%e5%8c%96%e7%ae%80" aria-label="习题 6：互信息的化简">习题 6：互信息的化简</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-7kl-%e6%95%a3%e5%ba%a6%e4%b8%8e%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1" aria-label="习题 7：KL 散度与最大似然估计">习题 7：KL 散度与最大似然估计</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%9a%e5%85%ad" aria-label="作业六">作业六</a><ul>
                        
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-1%e8%b4%9d%e5%8f%b6%e6%96%af%e6%8e%a8%e6%96%ad%e6%b1%82%e5%90%8e%e9%aa%8c%e5%88%86%e5%b8%83" aria-label="习题 1：贝叶斯推断求后验分布">习题 1：贝叶斯推断求后验分布</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-2gauss-%e7%b4%af%e7%a7%af%e5%88%86%e5%b8%83%e5%87%bd%e6%95%b0%e7%9a%84%e5%af%b9%e6%95%b0%e5%87%b9%e6%80%a7" aria-label="习题 2：Gauss 累积分布函数的对数凹性">习题 2：Gauss 累积分布函数的对数凹性</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-3%e5%85%b1%e8%bd%ad%e5%87%bd%e6%95%b0%e7%9a%84%e8%ae%a1%e7%ae%97" aria-label="习题 3：共轭函数的计算">习题 3：共轭函数的计算</a><ul>
                        
                <li>
                    <a href="#1" aria-label="(1) $f(x) = -\log x$">(1) $f(x) = -\log x$</a></li>
                <li>
                    <a href="#2" aria-label="(2) $f(x) = e^x$">(2) $f(x) = e^x$</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-4kkt-%e6%9d%a1%e4%bb%b6%e7%9a%84%e5%ba%94%e7%94%a8" aria-label="习题 4：KKT 条件的应用">习题 4：KKT 条件的应用</a><ul>
                        
                <li>
                    <a href="#1-%e6%9c%80%e5%a4%a7%e5%8c%96%e9%97%ae%e9%a2%98" aria-label="(1) 最大化问题">(1) 最大化问题</a></li>
                <li>
                    <a href="#2-%e6%9c%80%e5%b0%8f%e5%8c%96%e9%97%ae%e9%a2%98" aria-label="(2) 最小化问题">(2) 最小化问题</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-5lagrange-%e4%b9%98%e5%ad%90%e6%b3%95%e8%af%81%e6%98%8e%e7%9f%a9%e9%98%b5-2-%e8%8c%83%e6%95%b0" aria-label="习题 5：Lagrange 乘子法证明矩阵 2-范数">习题 5：Lagrange 乘子法证明矩阵 2-范数</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-6%e6%ac%a0%e5%ae%9a%e6%96%b9%e7%a8%8b%e7%9a%84%e6%9c%80%e5%b0%8f%e4%ba%8c%e8%8c%83%e6%95%b0%e8%a7%a3" aria-label="习题 6：欠定方程的最小二范数解">习题 6：欠定方程的最小二范数解</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-7%e6%9c%80%e9%80%9f%e4%b8%8b%e9%99%8d%e6%b3%95" aria-label="习题 7：最速下降法">习题 7：最速下降法</a></li>
                <li>
                    <a href="#%e4%b9%a0%e9%a2%98-8dfp-%e6%b3%95%e6%b1%82%e4%ba%8c%e6%ac%a1%e5%87%bd%e6%95%b0%e6%9e%81%e5%b0%8f%e7%82%b9" aria-label="习题 8：DFP 法求二次函数极小点">习题 8：DFP 法求二次函数极小点</a><ul>
                        
                <li>
                    <a href="#%e7%ac%ac%e4%b8%80%e6%ac%a1%e8%bf%ad%e4%bb%a3" aria-label="第一次迭代">第一次迭代</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e6%ac%a1%e8%bf%ad%e4%bb%a3" aria-label="第二次迭代">第二次迭代</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="作业一">作业一<a hidden class="anchor" aria-hidden="true" href="#作业一">#</a></h1>
<hr>
<h2 id="习题-1幂等矩阵的性质">习题 1：幂等矩阵的性质<a hidden class="anchor" aria-hidden="true" href="#习题-1幂等矩阵的性质">#</a></h2>
<p><strong>题目</strong>：矩阵 $A^2 = A, B^2 = B$，并且 $B$ 的列是 $A$ 的列的线性组合。证明 $AB = B$。</p>
<p><strong>证明</strong>：</p>
<p>设 $B$ 的列是 $A$ 的列的线性组合，则存在矩阵 $C$ 使得 $B = AC$。</p>
<p>现在计算 $AB$，由于 $A^2 = A$：</p>
$$AB = A(AC) = A^2C = AC = B$$<p>因此 $AB = B$。 $\square$</p>
<hr>
<h2 id="习题-2特征多项式的相等性">习题 2：特征多项式的相等性<a hidden class="anchor" aria-hidden="true" href="#习题-2特征多项式的相等性">#</a></h2>
<p><strong>题目</strong>：设 $A, B$ 为任意两个 $n$ 阶方阵，证明：$AB$ 和 $BA$ 具有相同的特征多项式，即 $|\lambda E - AB| = |\lambda E - BA|$。</p>
<p><strong>证明</strong>：</p>
<p>设</p>
$$\begin{pmatrix} E & 0 \\ A & E \end{pmatrix} \begin{pmatrix} \lambda E & B \\ 0 & \lambda E - AB \end{pmatrix} \begin{pmatrix} E & 0 \\ -A & E \end{pmatrix} = \begin{pmatrix} \lambda E - BA & B \\ 0 & \lambda E \end{pmatrix}$$<p>取行列式，利用行列式的乘法性质，有</p>
$$\left|\begin{array}{cc} \lambda E & B \\ 0 & \lambda E - AB \end{array}\right| = \left|\begin{array}{cc} \lambda E - BA & B \\ 0 & \lambda E \end{array}\right|$$<p>由于</p>
$$\left|\begin{array}{cc} \lambda E & B \\ 0 & \lambda E - AB \end{array}\right| = \lambda^n |\lambda E - AB|, \qquad \left|\begin{array}{cc} \lambda E - BA & B \\ 0 & \lambda E \end{array}\right| = \lambda^n |\lambda E - BA|$$<p>因此有</p>
$$\lambda^n |\lambda E - AB| = \lambda^n |\lambda E - BA|$$<p>当 $\lambda \neq 0$ 时，两边可同时除以 $\lambda^n$，得到</p>
$$|\lambda E - AB| = |\lambda E - BA|$$<p>两边都是关于 $\lambda$ 的多项式，故此恒等式对任意 $\lambda$（包括 $\lambda=0$）均成立。 $\square$</p>
<hr>
<h2 id="习题-3矩阵范数的计算">习题 3：矩阵范数的计算<a hidden class="anchor" aria-hidden="true" href="#习题-3矩阵范数的计算">#</a></h2>
<p><strong>题目</strong>：求下面矩阵的 1-范数、2-范数和无穷范数：</p>
$$A_1 = \begin{pmatrix} 1 & 2 \\ 1 & 0 \end{pmatrix}, \quad A_2 = \begin{pmatrix} -1 & 0 \\ 1 & 2 \end{pmatrix}$$<p><strong>解</strong>：</p>
<h4 id="对于矩阵">对于矩阵 $A_1$<a hidden class="anchor" aria-hidden="true" href="#对于矩阵">#</a></h4>
<p><strong>1-范数</strong>（列和范数）：</p>
$$\|A_1\|_1 = \max\{|1|+|1|, |2|+|0|\} = \max\{2, 2\} = 2$$<p><strong>无穷范数</strong>（行和范数）：</p>
$$\|A_1\|_\infty = \max\{|1|+|2|, |1|+|0|\} = \max\{3, 1\} = 3$$<p><strong>2-范数</strong>（谱范数，即 $\sqrt{\rho(A_1^T A_1)}$）：</p>
<p>首先计算 $A_1^T A_1$：</p>
$$A_1^T A_1 = \begin{pmatrix} 1 & 1 \\ 2 & 0 \end{pmatrix} \begin{pmatrix} 1 & 2 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 2 & 2 \\ 2 & 4 \end{pmatrix}$$<p>求特征值：</p>
$$\det(\lambda E - A_1^T A_1) = \det\begin{pmatrix} \lambda-2 & -2 \\ -2 & \lambda-4 \end{pmatrix} = (\lambda-2)(\lambda-4) - 4 = \lambda^2 - 6\lambda + 4 = 0$$<p>解得：$\lambda = \frac{6 \pm \sqrt{36-16}}{2} = \frac{6 \pm \sqrt{20}}{2} = 3 \pm \sqrt{5}$</p>
<p>最大特征值为 $\lambda_{\max} = 3 + \sqrt{5}$</p>
<p>因此：</p>
$$\|A_1\|_2 = \sqrt{3 + \sqrt{5}}$$<h4 id="对于矩阵-1">对于矩阵 $A_2$<a hidden class="anchor" aria-hidden="true" href="#对于矩阵-1">#</a></h4>
<p><strong>1-范数</strong>：</p>
$$\|A_2\|_1 = \max\{|-1|+|1|, |0|+|2|\} = \max\{2, 2\} = 2$$<p><strong>无穷范数</strong>：</p>
$$\|A_2\|_\infty = \max\{|-1|+|0|, |1|+|2|\} = \max\{1, 3\} = 3$$<p><strong>2-范数</strong>：</p>
<p>计算 $A_2^T A_2$：</p>
$$A_2^T A_2 = \begin{pmatrix} -1 & 1 \\ 0 & 2 \end{pmatrix} \begin{pmatrix} -1 & 0 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 2 & 2 \\ 2 & 4 \end{pmatrix}$$<p>这与 $A_1^T A_1$ 相同，因此：</p>
$$\|A_2\|_2 = \sqrt{3 + \sqrt{5}}$$<hr>
<h2 id="习题-4诱导范数的证明">习题 4：诱导范数的证明<a hidden class="anchor" aria-hidden="true" href="#习题-4诱导范数的证明">#</a></h2>
<p><strong>题目</strong>：矩阵的范数主要包括三种主要类型：诱导范数，元素形式范数和 Schatten 范数。诱导范数又称矩阵空间上的算子范数 (operator norm)，常用的诱导范数为 $p$ 范数，定义如下</p>
$$
\|A\|_p = \sup_{\|x\|_p \neq 0} \frac{\|Ax\|_p}{\|x\|_p} = \sup_{\|x\|_p = 1} \|Ax\|_p
$$<p>
<strong>(1)</strong> 设 $A = (a_{ij}) \in \mathbb{C}^{m \times n}$，证明 1 范数为列和范数，无穷范数为行和范数
</p>
$$
\|A\|_{\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |a_{ij}|, \quad \|A\|_1 = \max_{1 \leq j \leq n} \sum_{i=1}^{m} |a_{ij}|
$$<p>
元素形式范数即矩阵按列排成向量，然后采用向量范数的定义得到的矩阵范数，一般称 $l_p$ 范数。</p>
$$
l_p: \|A\|_p = \sqrt[p]{\sum_{i,j} |a_{ij}|^p}
$$<p>
<strong>(2)</strong> 试比较 $l_1$ 范数
</p>
$$
l_1: \|A\|_1 = \sum_{i,j} |a_{ij}|^1
$$<p>
与诱导范数的关系。</p>
<h4 id="1-证明-1-范数和无穷范数">(1) 证明 1-范数和无穷范数<a hidden class="anchor" aria-hidden="true" href="#1-证明-1-范数和无穷范数">#</a></h4>
<p>设 $A = (a_{ij}) \in \mathbb{C}^{m \times n}$，证明 1 范数为列和范数，无穷范数为行和范数</p>
$$
\|A\|_{\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |a_{ij}|, \quad \|A\|_1 = \max_{1 \leq j \leq n} \sum_{i=1}^{m} |a_{ij}|
$$<p>
<strong>证明</strong>：
</p>
$$
对于A = (a_1,...a_n)来说
$$<p><strong>(i) 证明 1-范数为列和范数</strong></p>
<p>对于任意 $x \in \mathbb{C}^n$ 且 $\|x\|_1 = 1$，利用三角不等式：</p>
$$
\|Ax\|_1 = \sum_{i=1}^m \left|\sum_{j=1}^n a_{ij}x_j\right| \leq \sum_{j=1}^n |x_j| \sum_{i=1}^m |a_{ij}| \leq \max_{1 \leq j \leq n} \sum_{i=1}^m |a_{ij}|
$$<p>
设第 $k$ 列使得列和最大，取 $x = e_k$，则</p>
$$
\|Ax\|_1 = \sum_{i=1}^m |a_{ik}| = \max_{1 \leq j \leq n} \sum_{i=1}^m |a_{ij}|
$$<p>
故上界可达到。因此 $\|A\|_1 = \max_{1 \leq j \leq n} \sum_{i=1}^m |a_{ij}|$。</p>
<p><strong>(ii) 证明无穷范数为行和范数</strong></p>
<p>对于任意 $x \in \mathbb{C}^n$ 且 $\|x\|_\infty = 1$，有：</p>
$$
\|Ax\|_\infty = \max_{1 \leq i \leq m} \left|\sum_{j=1}^n a_{ij}x_j\right| \leq \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{ij}||x_j| \leq \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{ij}|
$$<p>
设第 $k$ 行使得行和最大，取 $
x_j =
\begin{cases}
\dfrac{\overline{a_{kj}}}{|a_{kj}|}, & a_{kj} \neq 0,\\[6pt]
0, & a_{kj} = 0.
\end{cases}
$，则
</p>
$$
\|Ax\|_\infty \leq \sum_{j=1}^n |a_{kj}| = \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{ij}|
$$<p>
故 $\|A\|_\infty = \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{ij}|$。 $\square$</p>
<h4 id="2-元素形式范数与诱导范数的关系">(2) 元素形式范数与诱导范数的关系<a hidden class="anchor" aria-hidden="true" href="#2-元素形式范数与诱导范数的关系">#</a></h4>
<p>以 $l_1$ 范数与$1$范数，无穷范数为例，有</p>
$$
\|X\|_1 \le \|X\|_{1(l_1)} \le n\|X\|_1
$$$$
\|X\|_\infty \le \|X\|_{1(l_1)} \le m\|X\|_\infty
$$<hr>
<h2 id="习题-5frobenius-范数的不等式">习题 5：Frobenius 范数的不等式<a hidden class="anchor" aria-hidden="true" href="#习题-5frobenius-范数的不等式">#</a></h2>
<p><strong>题目</strong>：证明：$\|AB\|_F \leq \|A\|_F \|B\|_F$ 和 $\|AB\|_F \leq \|A\|_F \|B\|_2$。</p>
<p><strong>证明</strong>：</p>
<p>Frobenius 范数定义为 $\|A\|_F = \sqrt{\sum_{i,j} |a_{ij}|^2} =\|(a_{11},…,a_{mn})\|_2= \sqrt{\text{tr}(A^*A)}$</p>
<p><strong>(1) 证明第一个不等式：$\|AB\|_F \leq \|A\|_F \|B\|_F$</strong></p>
<p>将 $B$ 按列分块：$B = [b_1, b_2, \ldots, b_p]$，其中 $b_j$ 是 $B$ 的第 $j$ 列。则：</p>
$$
AB = [Ab_1, Ab_2, \ldots, Ab_p]​
$$<p>
由 Frobenius 范数的性质：</p>
$$
\|AB\|_F^2 = \sum_{j=1}^p \|Ab_j\|_2^2
$$<p>对每一列 $Ab_j$，设 $A$ 的第 $i$ 行为 $a_i^*$，则 $(Ab_j)_i = a_i^* b_j$。由 <strong>柯西-施瓦茨不等式</strong></p>
$$
|(Ab_j)_i|^2 = |a_i^* b_j|^2 \leq \|a_i^*\|_2^2 \|b_j\|_2^2​
$$<p>
因此：</p>
$$
\|Ab_j\|_2^2 = \sum_{i=1}^m |(Ab_j)_i|^2 \leq \sum_{i=1}^m \|a_i^*\|_2^2 \|b_j\|_2^2 = \|A\|_F^2 \|b_j\|_2^2​
$$<p>
代入得：
</p>
$$
\|AB\|_F^2 = \sum_{j=1}^p \|Ab_j\|_2^2 \leq \sum_{j=1}^p \|A\|_F^2 \|b_j\|_2^2 = \|A\|_F^2 \sum_{j=1}^p \|b_j\|_2^2 = \|A\|_F^2 \|B\|_F^2​
$$<p>
因此 $\|AB\|_F \leq \|A\|_F \|B\|_F$。</p>
<p><strong>(2) 证明第二个不等式：$\|AB\|_F \leq \|A\|_F \|B\|_2$</strong></p>
<p>将 $A$ 按行分块，设 $A$ 的第 $i$ 行为 $a_i^*$（$1 \leq i \leq m$），则 $AB$ 的第 $i$ 行为 $a_i^* B$。因此：</p>
$$
\|AB\|_F^2 = \sum_{i=1}^m \|a_i^* B\|_2^2
$$<p>
由算子范数的性质 $\|a_i^* B\|_2 \leq \|a_i^*\|_2 \|B\|_2$，得：</p>
$$
\|AB\|_F^2 \leq \sum_{i=1}^m \|a_i^*\|_2^2 \|B\|_2^2 = \|B\|_2^2 \sum_{i=1}^m \|a_i^*\|_2^2 = \|B\|_2^2 \|A\|_F^2
$$<p>
因此 $\|AB\|_F \leq \|A\|_F \|B\|_2$。 $\square$</p>
<hr>
<h2 id="习题-6距离函数的判断">习题 6：距离函数的判断<a hidden class="anchor" aria-hidden="true" href="#习题-6距离函数的判断">#</a></h2>
<p><strong>题目</strong>：有些平时称之为&quot;距离&quot;的函数其实并不是数学意义上的距离，请判断以下两种所谓的&quot;距离&quot;是否是数学意义上的距离并说明理由。</p>
<p><strong>(1)</strong> 假设向量 $a, b \in \mathbb{R}^n$，定义余弦距离为 $d(a, b) = 1 - \cos\langle a, b\rangle$，其中 $\langle a, b\rangle$ 为向量 $a, b$ 间的夹角。</p>
<p><strong>(2)</strong> 假设 $S_1, S_2$ 分别表示两个字符串，定义 $S_1, S_2$ 的编辑距离 $d(S_1, S_2)$ 为由 $S_1$ 转成 $S_2$ 所需的最少编辑操作次数。其中一次编辑操作可以是：将 $S_1$ 中的一个字符替换为另一个字符；在 $S_1$ 中插入一个字符；在 $S_1$ 中删除一个字符。例如：kitten 和 sitting 的编辑距离是 3。</p>
<h4 id="1-余弦距离">(1) 余弦距离<a hidden class="anchor" aria-hidden="true" href="#1-余弦距离">#</a></h4>
<p>假设向量 $a, b \in \mathbb{R}^n$，定义余弦距离为 $d(a, b) = 1 - \cos\langle a, b\rangle$，其中 $\langle a, b\rangle$ 为向量 $a, b$ 间的夹角。</p>
<p><strong>解</strong>：</p>
<p>余弦距离<strong>不是</strong>数学意义上的距离（度量）。</p>
<p>度量需要满足三个条件：非负性与同一性、对称性、三角不等式。余弦距离违反了<strong>同一性</strong>。</p>
<p><strong>反例</strong>：取 $a = (1,0)$，$b = (2,0)$，则 $a, b$ 的夹角为 $0°$，因此：
</p>
$$
d(a,b) = 1 - \cos 0° = 1 - 1 = 0
$$<p>
但显然 $a \neq b$，所以不满足&quot;$d(a,b) = 0 \Leftrightarrow a = b$&ldquo;这一条件。</p>
<p>因此余弦距离不是数学意义上的距离。</p>
<h4 id="2-编辑距离">(2) 编辑距离<a hidden class="anchor" aria-hidden="true" href="#2-编辑距离">#</a></h4>
<p>假设 $S_1, S_2$ 分别表示两个字符串，定义 $S_1, S_2$ 的编辑距离 $d(S_1, S_2)$ 为由 $S_1$ 转成 $S_2$ 所需的最少编辑操作次数。其中一次编辑操作可以是：将 $S_1$ 中的一个字符替换为另一个字符；在 $S_1$ 中插入一个字符；在 $S_1$ 中删除一个字符。例如：kitten 和 sitting 的编辑距离是 3。</p>
<p><strong>解</strong>：</p>
<p>编辑距离（Levenshtein距离）<strong>是</strong>数学意义上的距离（度量）。</p>
<p><strong>验证三个条件：</strong></p>
<p><strong>(i) 非负性与同一性</strong></p>
<p>编辑次数显然非负，且只有两个字符串完全相同时，所需的编辑次数最少为 0，即满足非负性：</p>
$$d(S_1, S_2) \geq 0, \quad \text{且} \quad d(S_1, S_2) = 0 \Leftrightarrow S_1 = S_2$$<p><strong>(ii) 对称性</strong></p>
<p>$d(S_1, S_2) = d(S_2, S_1)$</p>
<p>插入和删除字符<strong>互为逆操作</strong>、将某个字符 $a$ 替换为字符 $b$ 的逆操作为将字符 $b$ 替换为字符 $a$，不难看出每种编辑操作均可逆，即满足对称性。</p>
<p><strong>(iii) 三角不等式</strong></p>
<p>$d(S_1, S_2) \leq d(S_1, S_3) + d(S_3, S_2)$</p>
<p>将 $S_1$ 编辑为 $S_2$ 的过程拆解成两部分：将 $S_1$ 编辑为 $S_3$ 以及将 $S_3$ 编辑为 $S_2$，考虑到其中这两部分可能存在<strong>冗余操作</strong>。所以直接从 $S_1$ 编辑为 $S_2$ 所需的最优编辑次数只会更少，即满足三角不等式。</p>
<p>综上 (i), (ii), (iii) 所述，编辑距离是数学意义上的距离。</p>
<hr>
<h2 id="习题-7正定矩阵与向量范数">习题 7：正定矩阵与向量范数<a hidden class="anchor" aria-hidden="true" href="#习题-7正定矩阵与向量范数">#</a></h2>
<p><strong>题目</strong>：证明：在 $\mathbb{R}^n$ 上，当且仅当 $A$ 是正定矩阵时，函数 $f(\boldsymbol{x}) = (\boldsymbol{x}^{\mathrm{T}} A\boldsymbol{x})^{\frac{1}{2}}$ 是一个向量范数。</p>
<p><strong>证明</strong>：</p>
<p>向量范数需要满足三个条件：</p>
<ol>
<li>正定性：$f(x) \geq 0$，且 $f(x) = 0 \Leftrightarrow x = 0$</li>
<li>齐次性：$f(\alpha x) = |\alpha| f(x)$，$\forall \alpha \in \mathbb{R}$</li>
<li>三角不等式：$f(x+y) \leq f(x) + f(y)$</li>
</ol>
<p><strong>(1) 必要性</strong></p>
<p>假设 $f(x)$ 是范数，证明 $A$ 必须是正定矩阵。</p>
<p>由范数的正定性，$f(x) = 0 \Leftrightarrow x = 0$，即：</p>
$$
x^T A x = 0 \Leftrightarrow x = 0
$$<p>
这表明对所有 $x \neq 0$，有 $x^T A x > 0$。又因为 $f(x) = \sqrt{x^T A x}$ 要有意义，需要 $x^T A x \geq 0$ 对所有 $x$ 成立。综上，$A$ 是正定矩阵。</p>
<p><strong>(2) 充分性</strong></p>
<p>假设 $A$ 是正定矩阵，证明 $f(x)$ 满足范数的三个性质。</p>
<p>由于 $A$ 正定，故 $A$ 是对称矩阵，且对所有 $x \in \mathbb{R}^n$，有 $x^T A x \geq 0$，当且仅当 $x = 0$ 时 $f(x) = 0$。</p>
<p><strong>① 正定性</strong></p>
<p>由 $A$ 正定知，对所有 $x \neq 0$，有 $x^T A x > 0$，因此：</p>
$$
f(x) = \sqrt{x^T A x} > 0
$$<p>
且显然 $f(0) = 0$，满足正定性。</p>
<p><strong>② 齐次性</strong></p>
<p>将 $\alpha x$ 代入可得：</p>
$$
f(\alpha x) = \sqrt{(\alpha x)^T A (\alpha x)} = \sqrt{\alpha^2 x^T A x} = |\alpha| \sqrt{x^T A x} = |\alpha| f(x)​
$$<p>
故满足齐次性。</p>
<p><strong>③ 三角不等式</strong></p>
<p>根据 $A$ 的对称性可得：</p>
$$f(x+y) = \sqrt{(x+y)^T A(x+y)} = \sqrt{x^T Ax + 2x^T Ay + y^T Ay}$$<p>由 <strong>柯西-施瓦茨不等式</strong> 不等式：</p>
$$
|x^T Ay| \leq \sqrt{(x^T Ax)(y^T Ay)}
$$<p>
因此：</p>
$$
f(x+y) = \sqrt{x^T Ax + 2x^T Ay + y^T Ay} \leq \sqrt{x^T Ax + 2\sqrt{(x^T Ax)(y^T Ay)} + y^T Ay}
$$$$
= \sqrt{\left(\sqrt{x^T Ax} + \sqrt{y^T Ay}\right)^2} = \sqrt{x^T Ax} + \sqrt{y^T Ay} = f(x) + f(y)
$$<p>故满足三角不等式。</p>
<p>综上所述，当且仅当 $A$ 是正定矩阵时，$f(x) = \sqrt{x^T A x}$ 是 $\mathbb{R}^n$ 上的向量范数。 $\square$</p>
<hr>
<h2 id="习题-8矩阵最大范数">习题 8：矩阵最大范数<a hidden class="anchor" aria-hidden="true" href="#习题-8矩阵最大范数">#</a></h2>
<p><strong>题目</strong>：证明：对任意 $A \in \mathbb{R}^{m \times n}$，由</p>
$$
\|A\|_{m\infty} := \max_{1 \leq i \leq m, 1 \leq j \leq n} |a_{ij}|
$$<p>定义的范数是 $\mathbb{R}^{m \times n}$ 上的（广义）矩阵范数。</p>
<hr>
<p><strong>证明</strong>：</p>
<p>广义矩阵范数需要满足以下三个性质：</p>
<h3 id="1-正定性">(1) 正定性<a hidden class="anchor" aria-hidden="true" href="#1-正定性">#</a></h3>
<p>显然：</p>
$$
\|A\|_{m\infty} = \max_{1 \leq i \leq m, 1 \leq j \leq n} |a_{ij}| \geq 0
$$<p>且：</p>
$$
\|A\|_{m\infty} = 0 \Leftrightarrow |a_{ij}| = 0 \text{ 对所有 } i, j \text{ 成立} \Leftrightarrow A = O
$$<h3 id="2-齐次性">(2) 齐次性<a hidden class="anchor" aria-hidden="true" href="#2-齐次性">#</a></h3>
<p>对任意 $\alpha \in \mathbb{R}$：</p>
$$
\|\alpha A\|_{m\infty} = \max_{1 \leq i \leq m, 1 \leq j \leq n} |\alpha a_{ij}|
$$$$
= \max_{1 \leq i \leq m, 1 \leq j \leq n} |\alpha| |a_{ij}|
$$$$
= |\alpha| \max_{1 \leq i \leq m, 1 \leq j \leq n} |a_{ij}|
$$$$
= |\alpha| \|A\|_{m\infty}
$$<h3 id="3-三角不等式">(3) 三角不等式<a hidden class="anchor" aria-hidden="true" href="#3-三角不等式">#</a></h3>
<p>对任意 $A, B \in \mathbb{R}^{m \times n}$，对于任意 $1 \leq i \leq m, 1 \leq j \leq n$，由三角不等式有：</p>
$$
|a_{ij} + b_{ij}| \leq |a_{ij}| + |b_{ij}| \leq \|A\|_{m\infty} + \|B\|_{m\infty}
$$<p>其中第二个不等式是因为 $|a_{ij}| \leq \|A\|_{m\infty}$ 且 $|b_{ij}| \leq \|B\|_{m\infty}$。</p>
<p>由于上述不等式对所有 $i, j$ 成立，两边取最大值得：</p>
$$
\|A + B\|_{m\infty} = \max_{1 \leq i \leq m, 1 \leq j \leq n} |a_{ij} + b_{ij}| \leq \|A\|_{m\infty} + \|B\|_{m\infty}
$$<p>因此，这个范数满足广义矩阵范数的所有性质。$\square$</p>
<h1 id="作业二">作业二<a hidden class="anchor" aria-hidden="true" href="#作业二">#</a></h1>
<hr>
<h2 id="习题-1向量的正交投影">习题 1：向量的正交投影<a hidden class="anchor" aria-hidden="true" href="#习题-1向量的正交投影">#</a></h2>
<p><strong>题目</strong>：求向量 $(1,1,1)^T$ 在一维子空间 $\text{span}([1,-1,1]^T)$ 上的正交投影。</p>
<p><strong>解</strong>：</p>
<p>设 $v = (1,1,1)^T$，$u = [1,-1,1]^T$。</p>
<p>向量 $v$ 在 $u$ 上的正交投影为：</p>
$$\text{proj}_u(v) = \frac{\langle v, u \rangle}{\langle u, u \rangle} u$$<p>计算内积：</p>
$$\langle v, u \rangle = 1 \cdot 1 + 1 \cdot (-1) + 1 \cdot 1 = 1$$$$\langle u, u \rangle = 1^2 + (-1)^2 + 1^2 = 3$$<p>因此正交投影为：</p>
$$\text{proj}_u(v) = \frac{1}{3} \begin{pmatrix} 1 \\ -1 \\ 1 \end{pmatrix} = \begin{pmatrix} 1/3 \\ -1/3 \\ 1/3 \end{pmatrix}$$<hr>
<h2 id="习题-2向量在仿射子空间上的正交投影">习题 2：向量在仿射子空间上的正交投影<a hidden class="anchor" aria-hidden="true" href="#习题-2向量在仿射子空间上的正交投影">#</a></h2>
<p><strong>题目</strong>：求向量 $(1,1,1)^T$ 在仿射子空间 $\text{span}\{[1,-1,1]^T, (1,1,0)^T\} + (1,2,1)^T$ 上的正交投影。</p>
<p><strong>解</strong>：</p>
<p>首先将子空间改写为标准形式。注意到题目表述的子空间为仿射子空间（平移后的子空间）。</p>
<p>设 $v = (1,1,1)^T$，$u_1 = [1,-1,1]^T$，$u_2 = (1,1,0)^T$，$a = (1,2,1)^T$。</p>
<p>首先求 $v - a = (0,-1,0)^T$ 在 $\text{span}\{u_1, u_2\}$ 上的正交投影。</p>
<p>正交化 $u_1, u_2$，由于$（u_1,u_2)=0$，故</p>
$$
w_1 = u_1 = [1,-1,1]^T
$$$$
w_2 = u_2 = (1,1,0)^T
$$<p>现在计算 $(v-a)$ 在正交基 $\{w_1, w_2\}$ 上的投影：</p>
$$
\text{proj}(v-a) = \frac{\langle v-a, w_1 \rangle}{\|w_1\|^2} w_1 + \frac{\langle v-a, w_2 \rangle}{\|w_2\|^2} w_2​
$$<p>
计算：</p>
$$
\langle (0,-1,0)^T, w_1 \rangle = 0 \cdot 1 + (-1) \cdot (-1) + 0 \cdot 1 = 1
$$$$
\langle (0,-1,0)^T, w_2 \rangle = 0 \cdot 1 + (-1) \cdot 1 + 0 \cdot 0 = -1
$$$$
\|w_1\|^2 = 3, \quad \|w_2\|^2 = 2
$$<p>因此：</p>
$$
\text{proj}(v-a) = \frac{1}{3}(1,-1,1)^T + \frac{-1}{2}(1,1,0)^T = \left(-\frac{1}{6}, -\frac{5}{6}, \frac{1}{3}\right)^T
$$<p>
最终投影为：</p>
$$
\text{proj}(v) = \text{proj}(v-a) + a = \left(\frac{5}{6}, \frac{7}{6}, \frac{4}{3}\right)^T
$$<hr>
<h2 id="习题-3对称正定矩阵的性质">习题 3：对称正定矩阵的性质<a hidden class="anchor" aria-hidden="true" href="#习题-3对称正定矩阵的性质">#</a></h2>
<p><strong>题目</strong>：设 $M, P, Q \in \mathbb{R}^{n \times n}$ 为对称，$P$ 为正定。</p>
$$
A = \begin{pmatrix} M & PM \\ MP & PMP \end{pmatrix} \in \mathbb{R}^{2n \times 2n}
$$<p><strong>(1)</strong> 证明 $A^T = A$。</p>
<p><strong>(2)</strong> 假设 $U \in \mathbb{R}^{m \times n}$，$V \in \mathbb{R}^{n \times n}$ 是正交矩阵，$D \in \mathbb{R}^{m \times n}$，证明 $\|UDV\|_2 = \|D\|_2$，$\|UDV\|_F = \|D\|_F$。</p>
<p><strong>(3)</strong> 证明 $\|A\|_F = 2\|M\|_F$，$\|A\|_2 \leq 2\|M\|_2$（提示：将 $A$ 分解，并利用 (2) 结论）</p>
<p><strong>(4)</strong> 假设 $n = 4$，$M = \text{diag}_{4 \times 4}(-2,1,0,0)$，$P = (c_1|c_2|c_3|c_4)$。证明 $\|A\|_F = 2\sqrt{5}$，$\|A\|_p = 2, \forall p \in [1, \infty]$</p>
<hr>
<h3 id="1-证明">(1) 证明 $A^T = A$<a hidden class="anchor" aria-hidden="true" href="#1-证明">#</a></h3>
<p><strong>证明</strong>：</p>
<p>直接计算 $A^T$：</p>
$$
A^T = \begin{pmatrix} M^T & (MP)^T \\ (PM)^T & (PMP)^T \end{pmatrix} = \begin{pmatrix} M^T & P^TM^T \\ M^TP^T & P^TM^TP^T \end{pmatrix}
$$<p>由于 $M^T = M$，$P^T = P$（对称性），有：</p>
$$
A^T = \begin{pmatrix} M & PM \\ MP & PMP \end{pmatrix} = A
$$<p>因此 $A$ 是对称矩阵。$\square$</p>
<hr>
<h3 id="2-正交矩阵保持范数不变">(2) 正交矩阵保持范数不变<a hidden class="anchor" aria-hidden="true" href="#2-正交矩阵保持范数不变">#</a></h3>
<p><strong>证明</strong>：</p>
<p><strong>对于2-范数</strong>：</p>
<p>先证 $\|UD\|_2 = \|D\|_2$：</p>
$$
\|UD\|_2 = \sqrt{\lambda_{\max}(D^TU^TUD)} = \sqrt{\lambda_{\max}(D^TD)} = \|D\|_2
$$<p>再证 $\|DV\|_2 = \|D\|_2$：</p>
<p>由于 $\|Vx\|_2 = \sqrt{x^TV^TVx} = \sqrt{x^Tx} = \|x\|_2$</p>
<p>因此：</p>
$$
\|DV\|_2 = \sup_{\|x\|_2=1} \|DVx\|_2 = \sup_{\|Vx\|_2=1} \|D(Vx)\|_2 = \sup_{\|y\|_2=1} \|Dy\|_2 = \|D\|_2
$$<p>结合两者得 $\|UDV\|_2 = \|D\|_2$。</p>
<p><strong>对于Frobenius范数</strong>：</p>
$$
\|UDV\|_F^2 = \text{tr}((UDV)^T(UDV)) = \text{tr}(V^TD^TU^TUDV)
$$$$
= \text{tr}(V^TD^TDV) = \text{tr}(D^TDVV^T) = \text{tr}(D^TD) = \|D\|_F^2
$$<p>因此 $\|UDV\|_F = \|D\|_F$。$\square$</p>
<hr>
<h3 id="3-矩阵范数的关系">(3) 矩阵范数的关系<a hidden class="anchor" aria-hidden="true" href="#3-矩阵范数的关系">#</a></h3>
<p><strong>证明</strong>：</p>
<p><strong>对于Frobenius范数</strong>：</p>
<p>将 $A$ 写成分块形式：</p>
$$
\|A\|_F = \left\|\begin{pmatrix} M & M \\ M & M \end{pmatrix}\right\|_F = \left\|\begin{pmatrix} I \\ I \end{pmatrix} M \begin{pmatrix} I & I \end{pmatrix}\right\|_F
$$$$
= \sqrt{\text{tr}\left(\begin{pmatrix} I \\ I \end{pmatrix} M \begin{pmatrix} I & I \end{pmatrix} \begin{pmatrix} I \\ I \end{pmatrix} M \begin{pmatrix} I & I \end{pmatrix}\right)}
$$$$
= \sqrt{2\text{tr}\left(M \begin{pmatrix} I & I \end{pmatrix} \begin{pmatrix} I \\ I \end{pmatrix} M\right)}
$$$$
= 2\sqrt{\text{tr}(M^2)} = 2\|M\|_F
$$<p><strong>另一种直接计算方法</strong>：</p>
$$
\|A\|_F^2 = \|M\|_F^2 + \|MP\|_F^2 + \|PM\|_F^2 + \|PMP\|_F^2 = 4\|M\|_F^2
$$<p><strong>对于2-范数</strong>：</p>
<p>对任意 $w = \begin{pmatrix} x \\ y \end{pmatrix}$，其中 $\|w\|_2^2 = \|x\|_2^2 + \|y\|_2^2 = 1$：</p>
$$
\|Aw\|_2^2 = \left\|\begin{pmatrix} Mx + PMy \\ MPx + PMPy \end{pmatrix}\right\|_2^2
$$$$
= \|Mx + PMy\|_2^2 + \|MPx + PMPy\|_2^2
$$$$
\leq (\|Mx\|_2 + \|PMy\|_2)^2 + (\|MPx\|_2 + \|PMPy\|_2)^2
$$$$
\leq 2\|Mx\|_2^2 + 2\|PMy\|_2^2 + 2\|MPx\|_2^2 + 2\|PMPy\|_2^2
$$$$
\leq 2\|M\|_2^2\|x\|_2^2 + 2\|PM\|_2^2\|y\|_2^2 + 2\|MP\|_2^2\|x\|_2^2 + 2\|PMP\|_2^2\|y\|_2^2
$$$$
= 2\|M\|_2^2\|x\|_2^2 + 2\|M\|_2^2\|y\|_2^2 + 2\|M\|_2^2\|x\|_2^2 + 2\|M\|_2^2\|y\|_2^2
$$$$
= 4\|M\|_2^2(\|x\|_2^2 + \|y\|_2^2)
$$$$
= 4\|M\|_2^2\|w\|_2^2
$$<p>因此 $\|A\|_2 \leq 2\|M\|_2$。$\square$</p>
<hr>
<h3 id="4-具体计算">(4) 具体计算<a hidden class="anchor" aria-hidden="true" href="#4-具体计算">#</a></h3>
<p><strong>解</strong>：</p>
<p>给定 $M = \text{diag}(-2, 1, 0, 0)$，$P$ 为正交矩阵。</p>
<p>计算 $\|M\|_F$：</p>
$$
\|M\|_F = \sqrt{(-2)^2 + 1^2 + 0^2 + 0^2} = \sqrt{5}
$$<p>由 (3) 的结论：</p>
$$
\|A\|_F = 2\|M\|_F = 2\sqrt{5}
$$<p>对于 $p$-范数，观察 $A$ 的结构。以 $Ax$ 为例，其中 $x = (x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8)^T$：</p>
$$
Ax = (-2x_1, x_2, x_6, -2x_5, -2x_4, x_3, x_7, -2x_8)^T
$$$$
\|Ax\|_p^p = |-2x_1|^p + |x_2|^p + |x_6|^p + |-2x_5|^p + |-2x_4|^p + |x_3|^p + |x_7|^p + |-2x_8|^p
$$$$
= 2^p|x_1|^p + |x_2|^p + |x_3|^p + 2^p|x_4|^p + 2^p|x_5|^p + |x_6|^p + |x_7|^p + 2^p|x_8|^p
$$$$
\leq 2^p(|x_1|^p + |x_2|^p + |x_3|^p + |x_4|^p + |x_5|^p + |x_6|^p + |x_7|^p + |x_8|^p)
$$$$
= 2^p\|x\|_p^p
$$<p>因此 $\|A\|_p = \sup_{\|x\|_p=1} \|Ax\|_p = 2$，对所有 $p \in [1, \infty]$ 成立。(即如果一个变换只将某些维度倍乘并交换顺序，不作维度间相加的操作，那矩阵范数即最大拉伸倍数)</p>
<hr>
<h2 id="习题-4投影矩阵的性质">习题 4：投影矩阵的性质<a hidden class="anchor" aria-hidden="true" href="#习题-4投影矩阵的性质">#</a></h2>
<p><strong>题目</strong>：假设 $P \in \mathbb{R}^{n \times n}$ 满足 $P^2 = P$。</p>
<p><strong>(1)</strong> 证明 $Py = y, \forall y \in \mathcal{R}(P)$，$Px - x \in \mathcal{N}(P), \forall x \in \mathbb{R}^n$。</p>
<p>（即证明投影 $P$ 沿着零空间 $\mathcal{N}(P)$ 投影到列空间 $\mathcal{R}(P)$）</p>
<p><strong>(2)</strong> 证明 $P$ 的特征值 $\lambda \in \{0,1\}$。假设 $\mathcal{R}(P) = \text{span}(u_1, \ldots, u_r)$，$\mathcal{N}(P) = \text{span}(v_{r+1}, \ldots, v_n)$，找到 $P$ 的对角化 $P = XDX^{-1}$ 并证明 $\text{tr}(P) = \text{rank}(P)$。（提示：利用 (1) 结论）</p>
<p><strong>(3)</strong> 证明当 $P \neq I_n$ 时，$\det(P) = 0$</p>
<p><strong>(4)</strong> 证明当 $P$ 是正交投影矩阵 $(P^2 = P = P^T)$ 时，$I_n - 2P$ 是正交矩阵。</p>
<p><strong>(5)</strong> 假设 $A \in \mathbb{R}^{m \times n}$，$m \leq n$，$\text{rank}(A) = m$，$P = A(A^TA)^{-1}A^T$。证明 $P$ 是正交投影矩阵，$\text{rank}(P) = m$。（提示：利用 (2) 结论）</p>
<hr>
<h3 id="1-投影矩阵的基本性质">(1) 投影矩阵的基本性质<a hidden class="anchor" aria-hidden="true" href="#1-投影矩阵的基本性质">#</a></h3>
<p><strong>证明</strong>：</p>
<p>若 $y \in \mathcal{R}(P)$，则存在 $x$ 使得 $y = Px$。</p>
<p>由于 $P^2 = P$（幂等性），有：</p>
$$
Py = P(Px) = P^2x = Px = y
$$<p>对任意 $x \in \mathbb{R}^n$，考虑 $Px - x$：</p>
$$
P(Px - x) = P^2x - Px = Px - Px = 0
$$<p>因此 $Px - x \in \mathcal{N}(P)$。$\square$</p>
<hr>
<h3 id="2-特征值与对角化">(2) 特征值与对角化<a hidden class="anchor" aria-hidden="true" href="#2-特征值与对角化">#</a></h3>
<p><strong>证明</strong>：</p>
<p><strong>特征值只能是 0 或 1</strong>：</p>
<p>若 $\lambda$ 是 $P$ 的特征值，对应特征向量 $x \neq 0$，则 $Px = \lambda x$。</p>
<p>由 $P^2 = P$，有：</p>
$$
\lambda^2 x = P^2x = Px = \lambda x
$$<p>因此 $\lambda^2 = \lambda$，即 $\lambda(\lambda - 1) = 0$，所以 $\lambda \in \{0, 1\}$。</p>
<p><strong>对角化</strong>：</p>
<p>由 (1) 可知：</p>
<ul>
<li>对 $u_i \in \mathcal{R}(P)$（$i = 1, \ldots, r$），有 $Pu_i = u_i$（特征值为1）</li>
<li>对 $v_j \in \mathcal{N}(P)$（$j = r+1, \ldots, n$），有 $Pv_j = 0$（特征值为0）</li>
</ul>
<p>令：</p>
$$
X = (u_1 | \cdots | u_r | v_{r+1} | \cdots | v_n) \in \mathbb{R}^{n \times n}
$$$$
D = \text{diag}_{n \times n}(\underbrace{1, \ldots, 1}_{r \text{ 个}}, \underbrace{0, \ldots, 0}_{n-r \text{ 个}}) \in \mathbb{R}^{n \times n}
$$<p>则 $P = XDX^{-1}$。</p>
<p><strong>证明 $\text{tr}(P) = \text{rank}(P)$</strong>：</p>
$$
\text{tr}(P) = \text{tr}(XDX^{-1}) = \text{tr}(DX^{-1}X) = \text{tr}(D) = r = \text{rank}(P)
$$<p>（注：也可理解为 SVD 分解 $P = UDV^T$，其中 $U \in \mathcal{R}(P)$，$V \in \mathcal{N}(P)$）$\square$</p>
<hr>
<h3 id="3-行列式为零">(3) 行列式为零<a hidden class="anchor" aria-hidden="true" href="#3-行列式为零">#</a></h3>
<p><strong>证明</strong>（反证法）：</p>
<p>假设 $\det(P) \neq 0$，则 $P$ 可逆。</p>
<p>由于 $P^2 = P$，两边同时左乘 $P^{-1}$：</p>
$$
P^{-1}P^2 = P^{-1}P
$$$$
P = I_n
$$<p>这与 $P \neq I_n$ 矛盾。因此当 $P \neq I_n$ 时，$\det(P) = 0$。$\square$</p>
<hr>
<h3 id="4-householder-变换">(4) Householder 变换<a hidden class="anchor" aria-hidden="true" href="#4-householder-变换">#</a></h3>
<p><strong>证明</strong>：</p>
<p>需要证明 $(I_n - 2P)^T(I_n - 2P) = I_n$。</p>
<p>由于 $P$ 是正交投影，$P^2 = P = P^T$。令 $Q := I_n - 2P$，则：</p>
$$
Q^T = (I_n - 2P)^T = I_n - 2P^T = I_n - 2P = Q
$$$$
Q^2 = (I_n - 2P)^2 = I_n - 4P + 4P^2 = I_n - 4P + 4P = I_n
$$<p>因此：</p>
$$
Q^TQ = Q^2 = I_n
$$<p>即 $I_n - 2P$ 是正交矩阵。$\square$</p>
<hr>
<h3 id="5-正交投影矩阵的构造">(5) 正交投影矩阵的构造<a hidden class="anchor" aria-hidden="true" href="#5-正交投影矩阵的构造">#</a></h3>
<p><strong>证明</strong>：</p>
<p>首先验证 $P^2 = P$：</p>
$$
P^2 = [A(A^TA)^{-1}A^T][A(A^TA)^{-1}A^T]= A(A^TA)^{-1}[A^TA](A^TA)^{-1}A^T
$$$$
= A(A^TA)^{-1}A^T = P
$$<p>验证 $P^T = P$：</p>
$$
P^T = [A(A^TA)^{-1}A^T]^T= A[(A^TA)^{-1}]^TA^T
$$$$
= A[(A^TA)^T]^{-1}A^T= A(A^TA)^{-1}A^T = P
$$<p>因此 $P$ 是正交投影矩阵。</p>
<p>由 (2) 的结论：</p>
$$
\text{rank}(P) = \text{tr}(P) = \text{tr}(A(A^TA)^{-1}A^T) = \text{tr}((A^TA)^{-1}A^TA) = \text{tr}(I_m) = m
$$<hr>
<h2 id="习题-5lu-分解的判断">习题 5：LU 分解的判断<a hidden class="anchor" aria-hidden="true" href="#习题-5lu-分解的判断">#</a></h2>
<p><strong>题目</strong>：对矩阵 $C = \begin{pmatrix} 3 & 2 & -1 \\ -1 & 0 & 0 \\ -1 & 3 & 0 \end{pmatrix}$ 和 $B = \begin{pmatrix} 0 & 2 & -1 \\ -1 & 4 & -1 \\ 1 & 3 & -5 \end{pmatrix}$ 能否进行 $LU$ 分解。</p>
<p><strong>(1)</strong> 分析不能进行 $LU$ 分解的原因。对于这样的矩阵，是否可以进行 $LU$ 分解。</p>
<p><strong>(2)</strong> 对于上述能分解的矩阵，试分解之。</p>
<h3 id="1-判断与分析">(1) 判断与分析<a hidden class="anchor" aria-hidden="true" href="#1-判断与分析">#</a></h3>
<p><strong>解</strong>：</p>
<p><strong>判断条件</strong>：矩阵能进行LU分解的充要条件是所有顺序主子式都不为零。</p>
<p><strong>对于矩阵 $C$：</strong></p>
<p>计算顺序主子式：</p>
$$|C_1| = 3 \neq 0$$$$|C_2| = \begin{vmatrix} 3 & 2 \\ -1 & 0 \end{vmatrix} = 2 \neq 0$$$$|C_3| = \det(C) = 3 \neq 0$$<p>所有顺序主子式都不为0，因此 $C$ 可以进行 $LU$ 分解。</p>
<p><strong>对于矩阵 $B$：</strong></p>
<p>计算第一个顺序主子式：$|B_1| = 0$，第一个顺序主子式为0，因此 $B$ 不能直接进行 $LU$ 分解。</p>
<p>但通过行交换可以进行 $PLU$ 分解。交换第1行和第2行后：</p>
$$
\begin{pmatrix} 0 & 2 & -1 \\ -1 & 4 & -1 \\ 1 & 3 & -5 \end{pmatrix} \xrightarrow{R_1 \leftrightarrow R_2} \begin{pmatrix} -1 & 4 & -1 \\ 0 & 2 & -1 \\ 1 & 3 & -5 \end{pmatrix}
$$<p>
然后可以对行交换后的矩阵进行 $LU$ 分解。</p>
<h3 id="2-lu-分解计算">(2) LU 分解计算<a hidden class="anchor" aria-hidden="true" href="#2-lu-分解计算">#</a></h3>
<p><strong>解</strong>：</p>
<p><strong>对矩阵 $C$ 进行 LU 分解：</strong></p>
<p>第一步消元（$R_2 + \frac{1}{3}R_1$，$R_3 + \frac{1}{3}R_1$）：</p>
$$
\begin{pmatrix} 3 & 2 & -1 \\ -1 & 0 & 0 \\ -1 & 3 & 0 \end{pmatrix} \rightarrow \begin{pmatrix} 3 & 2 & -1 \\ 0 & \frac{2}{3} & -\frac{1}{3} \\ 0 & \frac{11}{3} & -\frac{1}{3} \end{pmatrix}
$$<p>
第二步消元（$R_3 - \frac{11}{2}R_2$）：</p>
$$
\rightarrow \begin{pmatrix} 3 & 2 & -1 \\ 0 & \frac{2}{3} & -\frac{1}{3} \\ 0 & 0 & \frac{3}{2} \end{pmatrix}​
$$<p>
因此：</p>
$$
L = \begin{pmatrix} 1 & 0 & 0 \\ -\frac{1}{3} & 1 & 0 \\ -\frac{1}{3} & \frac{11}{2} & 1 \end{pmatrix}, \quad U = \begin{pmatrix} 3 & 2 & -1 \\ 0 & \frac{2}{3} & -\frac{1}{3} \\ 0 & 0 & \frac{3}{2} \end{pmatrix}
$$$$
C = LU
$$<hr>
<h2 id="习题-6矩阵的-lu-分解">习题 6：矩阵的 LU 分解<a hidden class="anchor" aria-hidden="true" href="#习题-6矩阵的-lu-分解">#</a></h2>
<p><strong>题目</strong>：求矩阵 $A = \begin{pmatrix} 2 & 1 & 1 \\ 1 & 2 & 1 \\ 1 & 1 & 0 \end{pmatrix}$ 的 $LU$ 分解。</p>
<p><strong>解</strong>：</p>
<p>进行高斯消元：</p>
<p>第一步（$R_2 - \frac{1}{2}R_1$，$R_3 - \frac{1}{2}R_1$）：</p>
$$
\begin{pmatrix} 2 & 1 & 1 \\ 1 & 2 & 1 \\ 1 & 1 & 0 \end{pmatrix} \rightarrow \begin{pmatrix} 2 & 1 & 1 \\ 0 & \frac{3}{2} & \frac{1}{2} \\ 0 & \frac{1}{2} & -\frac{1}{2} \end{pmatrix}
$$<p>
第二步（$R_3 - \frac{1}{3}R_2$）：</p>
$$
\rightarrow \begin{pmatrix} 2 & 1 & 1 \\ 0 & \frac{3}{2} & \frac{1}{2} \\ 0 & 0 & -\frac{2}{3} \end{pmatrix}
$$<p>
因此：</p>
$$
L = \begin{pmatrix} 1 & 0 & 0 \\ \frac{1}{2} & 1 & 0 \\ \frac{1}{2} & \frac{1}{3} & 1 \end{pmatrix}, \quad U = \begin{pmatrix} 2 & 1 & 1 \\ 0 & \frac{3}{2} & \frac{1}{2} \\ 0 & 0 & -\frac{2}{3} \end{pmatrix}
$$$$
A = LU
$$<h1 id="作业三">作业三<a hidden class="anchor" aria-hidden="true" href="#作业三">#</a></h1>
<hr>
<h2 id="习题-1cholesky-分解不带平方根">习题 1：Cholesky 分解（不带平方根）<a hidden class="anchor" aria-hidden="true" href="#习题-1cholesky-分解不带平方根">#</a></h2>
<p><strong>题目</strong>：求对称正定矩阵$A = \begin{pmatrix} 5 & 2 & -4 \\ 2 & 1 & -2 \\ -4 & -2 & 5 \end{pmatrix}$的不带平方根的 Cholesky 分解。</p>
<p><strong>解</strong>：</p>
<p>不带平方根的 Cholesky 分解形式为 $A = LDL^T$，其中 $L$ 是单位下三角矩阵，$D$ 是对角矩阵。</p>
<p><strong>第一步：</strong> 计算第一列</p>
$$
d_1 = a_{11} = 5\quad\quad  l_{21} = \frac{a_{21}}{d_1} = \frac{2}{5}\quad \quad l_{31} = \frac{a_{31}}{d_1} = \frac{-4}{5}
$$<p><strong>第二步：</strong> 计算第二列
</p>
$$
d_2 = a_{22} - l_{21}^2 d_1 = 1 - \left(\frac{2}{5}\right)^2 \cdot 5 = \frac{1}{5}\quad\quad\quad l_{32} = \frac{a_{32} - l_{31}l_{21}d_1}{d_2} = \frac{-2 + \frac{8}{5}}{\frac{1}{5}} = -2
$$<p>
<strong>第三步：</strong> 计算第三列
</p>
$$
d_3 = a_{33} - l_{31}^2 d_1 - l_{32}^2 d_2 = 5 - \frac{16}{5} - \frac{4}{5} = 1
$$<p>
因此，分解结果为：</p>
$$
L = \begin{pmatrix} 1 & 0 & 0 \\ \frac{2}{5} & 1 & 0 \\ -\frac{4}{5} & -2 & 1 \end{pmatrix}, \quad D = \begin{pmatrix} 5 & 0 & 0 \\ 0 & \frac{1}{5} & 0 \\ 0 & 0 & 1 \end{pmatrix}, \quad L^T = \begin{pmatrix} 1 & \frac{2}{5} & -\frac{4}{5} \\ 0 & 1 & -2 \\ 0 & 0 & 1 \end{pmatrix}
$$<p>
验证：$A = LDL^T$</p>
<hr>
<h2 id="习题-2对称性的保持">习题 2：对称性的保持<a hidden class="anchor" aria-hidden="true" href="#习题-2对称性的保持">#</a></h2>
<p><strong>题目</strong>：设 $A$ 对称且 $a_{11} \neq 0$，并假设经过一步 Gauss 消去之后，$A$ 具有如下形式
</p>
$$
\begin{bmatrix} a_{11} & a_1^T \\ \mathbf{0} & A_2 \end{bmatrix}
$$<p>
证明 $A_2$ 仍是对称阵。</p>
<p><strong>证明</strong>：</p>
<p>由于 $A$ 是对称矩阵，有 $A = A^T$，记矩阵$A$和高斯变换矩阵分别为</p>
$$
G = \begin{bmatrix} 1 & 0^T \\ l_1 & I \end{bmatrix},\quad  A = \begin{bmatrix} a_{11} & a_1^T \\ a_1 & A_1 \end{bmatrix}
$$<p>
则
</p>
$$
GA =\begin{bmatrix} a_{11} & a_1^T \\ -a_{11}l_1+a_1 & -l_1a_1^T+A_1 \end{bmatrix}
$$<p>经过一步 Gauss 消元，我们使用消元矩阵：</p>
$$
L_1 = \begin{bmatrix} 1 & \mathbf{0} \\ -\frac{1}{a_{11}}a_1 & I \end{bmatrix}
$$<p>
则有：</p>
$$
L_1 A = \begin{bmatrix} a_{11} & a_1^T \\ \mathbf{0} & A_0 - \frac{1}{a_{11}}a_1 a_1^T \end{bmatrix}
$$<p>
记 $A_2 = A_0 - \frac{1}{a_{11}}a_1 a_1^T$。由于 $A_0$ 对称，且 $a_1 a_1^T$ 是对称矩阵（秩1矩阵的对称性），因此：</p>
$$
A_2^T = \left(A_0 - \frac{1}{a_{11}}a_1 a_1^T\right)^T = A_0^T - \frac{1}{a_{11}}(a_1 a_1^T)^T = A_0 - \frac{1}{a_{11}}a_1 a_1^T = A_2
$$<p>
所以 $A_2$ 是对称矩阵。 $\square$</p>
<hr>
<h2 id="习题-3qr-分解求解线性方程组">习题 3：QR 分解求解线性方程组<a hidden class="anchor" aria-hidden="true" href="#习题-3qr-分解求解线性方程组">#</a></h2>
<p>好的，我只调整数学公式的居中问题，保持你原有的格式结构：</p>
<p><strong>题目</strong>：利用 $QR$ 分解求解下述线性方程组的解（最终结果可只需写出其矩阵与向量的乘积形式即可）：</p>
$$
\begin{bmatrix} 1 & 2 & 2 \\ 2 & 1 & 2 \\ 1 & 2 & 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
$$<p><strong>解</strong>：</p>
<p>设 $A = \begin{bmatrix} 1 & 2 & 2 \\ 2 & 1 & 2 \\ 1 & 2 & 1 \end{bmatrix}$，$b = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$。</p>
<p>对矩阵 $A$ 的列向量 $a_1 = \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}$，$a_2 = \begin{pmatrix} 2 \\ 1 \\ 2 \end{pmatrix}$，$a_3 = \begin{pmatrix} 2 \\ 2 \\ 1 \end{pmatrix}$ 进行 Gram-Schmidt 正交化，得到正交矩阵 $Q$ 和上三角矩阵 $R$：</p>
$$
Q = \begin{bmatrix} \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{3}} & \frac{1}{\sqrt{2}} \\ \frac{2}{\sqrt{6}} & -\frac{1}{\sqrt{3}} & 0 \\ \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{3}} & -\frac{1}{\sqrt{2}} \end{bmatrix}, \quad R = \begin{bmatrix} \sqrt{6} & \sqrt{6} & \frac{7}{\sqrt{6}} \\ 0 & \sqrt{3} & \frac{1}{\sqrt{3}} \\ 0 & 0 & \sqrt{2} \end{bmatrix}
$$<p>因此，方程组的解为：</p>
$$
x = R^{-1}Q^T b = \begin{bmatrix} \sqrt{6} & \sqrt{6} & \frac{7}{\sqrt{6}} \\ 0 & \sqrt{3} & \frac{1}{\sqrt{3}} \\ 0 & 0 & \sqrt{2} \end{bmatrix}^{-1} \begin{bmatrix} \frac{1}{\sqrt{6}} & \frac{2}{\sqrt{6}} & \frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{3}} & -\frac{1}{\sqrt{3}} & \frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{2}} & 0 & -\frac{1}{\sqrt{2}} \end{bmatrix} \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
$$<hr>
<h2 id="习题-4cholesky-分解与范数">习题 4：Cholesky 分解与范数<a hidden class="anchor" aria-hidden="true" href="#习题-4cholesky-分解与范数">#</a></h2>
<p><strong>题目</strong>：定义</p>
$$
A = \begin{pmatrix} 2 & -2 & 1 \\ -1 & 1 & -1 \\ -3 & -1 & 1 \end{pmatrix}
$$<p><strong>(1)</strong> 给出矩阵 $A^TA$ 的 Cholesky 分解 $A^TA = GG^T$</p>
<p><strong>(2)</strong> 试说明 $\|A^TA\|_2 = \|A\|_2^2 = \|G\|_2^2$</p>
<hr>
<h3 id="1-cholesky-分解">(1) Cholesky 分解<a hidden class="anchor" aria-hidden="true" href="#1-cholesky-分解">#</a></h3>
<p><strong>解</strong>：</p>
<p>对矩阵 $M = A^TA = \begin{pmatrix} 14 & -2 & 0 \\ -2 & 6 & -4 \\ 0 & -4 & 3 \end{pmatrix}$ 进行 Cholesky 分解 $M = GG^T$，其中 $G$ 是下三角矩阵。</p>
<p><strong>第一步：</strong> 计算第一列</p>
$$
g_{11} = \sqrt{m_{11}} = \sqrt{14} \quad\quad g_{21} = \frac{m_{21}}{g_{11}} = \frac{-2}{\sqrt{14}} = -\frac{\sqrt{14}}{7} \quad\quad g_{31} = \frac{m_{31}}{g_{11}} = 0
$$<p><strong>第二步：</strong> 计算第二列</p>
$$
g_{22} = \sqrt{m_{22} - g_{21}^2} = \sqrt{6 - \frac{2}{7}} = \sqrt{\frac{40}{7}} = \frac{2\sqrt{70}}{7}
$$$$
g_{32} = \frac{m_{32} - g_{31}g_{21}}{g_{22}} = \frac{-4}{\frac{2\sqrt{70}}{7}} = -\frac{14}{2\sqrt{70}} = -\frac{\sqrt{70}}{5}
$$<p><strong>第三步：</strong> 计算第三列</p>
$$
g_{33} = \sqrt{m_{33} - g_{31}^2 - g_{32}^2} = \sqrt{3 - 0 - \frac{14}{5}} = \sqrt{\frac{1}{5}} = \frac{\sqrt{5}}{5}
$$<p>因此，分解结果为：</p>
$$
G = \begin{pmatrix} \sqrt{14} & 0 & 0 \\ -\frac{\sqrt{14}}{7} & \frac{2\sqrt{70}}{7} & 0 \\ 0 & -\frac{\sqrt{70}}{5} & \frac{\sqrt{5}}{5} \end{pmatrix}, \quad G^T = \begin{pmatrix} \sqrt{14} & -\frac{\sqrt{14}}{7} & 0 \\ 0 & \frac{2\sqrt{70}}{7} & -\frac{\sqrt{70}}{5} \\ 0 & 0 & \frac{\sqrt{5}}{5} \end{pmatrix}
$$<p><strong>验证：$A^TA = GG^T$</strong></p>
<h3 id="2-范数关系">(2) 范数关系<a hidden class="anchor" aria-hidden="true" href="#2-范数关系">#</a></h3>
<p><strong>证明</strong>：</p>
<p>令 $G = U\Sigma V^T$ 为 $G$ 的奇异值分解，其中 $U, V \in \mathbb{R}^{n \times n}$ 正交，$\Sigma = \text{diag}(\sigma_1, \ldots, \sigma_n)$ 且 $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_n \geq 0$。</p>
<p>由于 $A^TA = GG^T$，则 $A^TA$ 的奇异值是 $\sigma_1^2, \ldots, \sigma_n^2$。因此：</p>
$$
\|A^T A\|_2 = \sigma_1^2 = \|G\|_2^2
$$<p>同样，矩阵的2-范数定义为：</p>
$$
\|A\|_2 = \max_{\|x\|_2=1} \|Ax\|_2 = \sqrt{\lambda_{\max}(A^TA)}
$$<p>因此：</p>
$$
\|A\|_2^2 = \lambda_{\max}(A^TA) = \|A^TA\|_2
$$<p>综上所述，$\|A^TA\|_2 = \|A\|_2^2 = \|G\|_2^2$。</p>
<hr>
<h2 id="习题-5svd-分解及应用">习题 5：SVD 分解及应用<a hidden class="anchor" aria-hidden="true" href="#习题-5svd-分解及应用">#</a></h2>
<p><strong>题目</strong>：对 $k \in \mathbb{N}_0$，定义</p>
$$
A = \begin{pmatrix} -8 & 5 & 1 \\ -4 & 7 & 5 \\ -8 & 5 & 1 \\ -4 & 7 & 5 \end{pmatrix}, \quad \gamma_k = \inf_{\substack{M \in \mathbb{R}^{3 \times 4} \\ \text{rk}(M) \leq k}} \|A^T - M\|_2
$$<p><strong>(1)</strong> 计算矩阵 $A$ 的 $SVD$ 分解 $A = U\Sigma V^T$，并使 $2U$ 为 Hadamard 矩阵</p>
<p><strong>(2)</strong> 使用 (1) 中的结论，求 $\text{rank}(A)$，$\mathcal{R}(A)$，$\mathcal{N}(A)$，$\|A\|_2$，$\|A\|_F$</p>
<p><strong>(3)</strong> 对每个 $k \in \mathbb{N}_0$，计算 $\gamma_k$ 并找出矩阵 $A_k \in \mathbb{R}^{3 \times 4}$ 使得 $\text{rank}(A_k) \leq k$ 且 $\|A^T - A_k\|_2 = \gamma_k$</p>
<hr>
<h3 id="1-svd-分解">(1) SVD 分解<a hidden class="anchor" aria-hidden="true" href="#1-svd-分解">#</a></h3>
<p><strong>解</strong>：</p>
<p>首先计算 $A^TA$：</p>
$$
A^TA = \begin{pmatrix} 160 & -68 & -28 \\ -68 & 148 & 80 \\ -28 & 80 & 52 \end{pmatrix}
$$<p>特征多项式为 $p_{A^TA}(z) = \det(\lambda I  - A^TA) = \lambda(\lambda - 36)(\lambda - 324)$。</p>
<p>$A^TA$ 的特征值为：</p>
$$
\lambda_1 = 324, \quad \lambda_2 = 36, \quad \lambda_3 = 0
$$<p>对应的特征空间为：</p>
$$
E_{\lambda_1} = \text{span}\left((-2, 2, 1)^T\right), \quad E_{\lambda_2} = \text{span}\left((2, 1, -2)^T\right), \quad E_{\lambda_3} = \text{span}\left((1, 2, 2)^T\right)
$$<p>经正交化后：</p>
$$
v_1 = \frac{1}{3}(-2, 2, 1)^T, \quad v_2 = \frac{1}{3}(2, 1, -2)^T, \quad v_3 = \frac{1}{3}(1, 2, 2)^T
$$<p>令 $V = (v_1 | v_2 | v_3)$。</p>
<p>奇异值为：</p>
$$
\sigma_1 = \sqrt{\lambda_1} = 18, \quad \sigma_2 = \sqrt{\lambda_2} = 6, \quad \sigma_3 = \sqrt{\lambda_3} = 0
$$<p>令 $\Sigma = \text{diag}_{4 \times 3}(\sigma_1, \sigma_2, \sigma_3)$。</p>
<p>计算 $U = (u_1 | u_2 | u_3 | u_4) \in \mathbb{R}^{4 \times 4}$ 使得 $Av_i = \sigma_i u_i$：</p>
$$
u_1 = \frac{Av_1}{\sigma_1} = \frac{1}{2}(1, 1, 1, 1)^T, \quad u_2 = \frac{Av_2}{\sigma_2} = \frac{1}{2}(-1, 1, -1, 1)^T
$$$$
u_3 = \frac{1}{2}(1, 1, -1, -1)^T, \quad u_4 = \frac{1}{2}(-1, 1, 1, -1)^T
$$<p>因此 $A$ 的 $SVD$ 分解为：</p>
$$
A = \begin{pmatrix} \frac{1}{2} & -\frac{1}{2} & \frac{1}{2} & -\frac{1}{2} \\ \frac{1}{2} & \frac{1}{2} & \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & -\frac{1}{2} & -\frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{2} & -\frac{1}{2} & -\frac{1}{2} \end{pmatrix} \begin{pmatrix} 18 & 0 & 0 \\ 0 & 6 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix} \begin{pmatrix} -\frac{2}{3} & \frac{2}{3} & \frac{1}{3} \\ \frac{2}{3} & \frac{1}{3} & -\frac{2}{3} \\ \frac{1}{3} & \frac{2}{3} & \frac{2}{3} \end{pmatrix}^T = U\Sigma V^T
$$<hr>
<h3 id="2-矩阵的性质">(2) 矩阵的性质<a hidden class="anchor" aria-hidden="true" href="#2-矩阵的性质">#</a></h3>
<p><strong>解</strong>：</p>
<p>$A$ 有两个非零奇异值，故 $\text{rank}(A) = 2$。</p>
$$
\mathcal{R}(A) = \text{span}(u_1, u_2) = \text{span}\left(\frac{1}{2}(1, 1, 1, 1)^T, \frac{1}{2}(-1, 1, -1, 1)^T\right)
$$$$
\mathcal{N}(A) = \text{span}(v_3) = \text{span}\left(\frac{1}{3}(1, 2, 2)^T\right)
$$$$
\|A\|_2 = \sigma_1 = 18, \quad \|A\|_F = \sqrt{\sigma_1^2 + \sigma_2^2} = \sqrt{324 + 36} = 6\sqrt{10}
$$<hr>
<h3 id="3-最佳秩-k-逼近">(3) 最佳秩-k 逼近<a hidden class="anchor" aria-hidden="true" href="#3-最佳秩-k-逼近">#</a></h3>
<p><strong>解</strong>：</p>
<p>根据 (1) 中 $A$ 的 $SVD$ 分解，令 $A^T = \tilde{U}\tilde{\Sigma}\tilde{V}^T$，其中 $\tilde{U} = V$，$\tilde{V} = U$，$\tilde{\Sigma} = \Sigma^T$。</p>
<p><strong>$k = 0$：</strong></p>
<p>定义 $A_0 = 0_{3 \times 4}$，则</p>
$$
\gamma_0 = \|A^T\|_2 = \sigma_1 = 18
$$<p><strong>$k = 1$：</strong></p>
<p>利用 Eckart-Young-Mirsky 定理：</p>
$$
A_1 = \sigma_1 v_1 u_1^T = 18 \begin{pmatrix} -\frac{2}{3} \\ \frac{2}{3} \\ \frac{1}{3} \end{pmatrix} \begin{pmatrix} \frac{1}{2} & \frac{1}{2} & \frac{1}{2} & \frac{1}{2} \end{pmatrix} = \begin{pmatrix} -6 & -6 & -6 & -6 \\ 6 & 6 & 6 & 6 \\ 3 & 3 & 3 & 3 \end{pmatrix}
$$$$
\gamma_1 = \|A^T - A_1\|_2 = \sigma_2 = 6
$$<p><strong>$k \geq 2$：</strong></p>
<p>因为 $\text{rank}(A^T) = 2$，令 $A_k = A^T$，对每个 $k \in \mathbb{N}_{\geq 2}$ 都有 $\gamma_k = 0$。</p>
<hr>
<h2 id="习题-6svd-分解的性质">习题 6：SVD 分解的性质<a hidden class="anchor" aria-hidden="true" href="#习题-6svd-分解的性质">#</a></h2>
<p><strong>题目</strong>：</p>
<p><strong>(1)</strong> 假设 $A$ 可逆，根据 $A$ 的 $SVD$ 结果给出 $A^{-1}$ 的 $SVD$ 分解（提示：$Av_i = \sigma_i u_i \,\forall i \in \{1,\ldots,n\}$）</p>
<p><strong>(2)</strong> 假设 $Q$ 是正交阵，给出 $Q$ 的 $SVD$ 分解及其奇异值</p>
<p><strong>(3)</strong> 假设 $A = QBQ^T$，其中 $Q$ 是正交阵，说明 $A$ 和 $B$ 有相同奇异值</p>
<h3 id="1-逆矩阵的-svd-分解">(1) 逆矩阵的 SVD 分解<a hidden class="anchor" aria-hidden="true" href="#1-逆矩阵的-svd-分解">#</a></h3>
<p><strong>解</strong>：</p>
<p>设 $A$ 的 $SVD$ 分解为</p>
$$
A = U\Sigma V^T = (u_1 | \cdots | u_n) [\text{diag}_{n \times n}(\sigma_1, \ldots, \sigma_n)] (v_1 | \cdots | v_n)^T
$$<p>
其中 $U, V \in \mathbb{R}^{n \times n}$ 正交，$\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_n > 0$（由于 $A$ 可逆）。</p>
<p>因为 $A = U\Sigma V^T$，有 $Av_i = \sigma_i u_i \,\forall i \in \{1, \ldots, n\}$。</p>
<p>因此</p>
$$
A^{-1}u_i = A^{-1}\left(\frac{1}{\sigma_i}Av_i\right) = \frac{1}{\sigma_i}v_i
$$<p>
注意到 $\frac{1}{\sigma_n} \geq \cdots \geq \frac{1}{\sigma_2} \geq \frac{1}{\sigma_1} > 0$，故</p>
$$
A^{-1} = (v_n | \cdots | v_2 | v_1) \left[\text{diag}_{n \times n}\left(\frac{1}{\sigma_n}, \ldots, \frac{1}{\sigma_2}, \frac{1}{\sigma_1}\right)\right] (u_n | \cdots | u_2 | u_1)^T
$$<p>
记 $P = (e_n | \cdots | e_2 | e_1) \in \mathbb{R}^{n \times n}$（$P$ 是正交阵），则：</p>
$$
A^{-1} = (VP)(P\Sigma^{-1}P)(UP)^T
$$<h3 id="2-正交矩阵的-svd-分解">(2) 正交矩阵的 SVD 分解<a hidden class="anchor" aria-hidden="true" href="#2-正交矩阵的-svd-分解">#</a></h3>
<p><strong>解</strong>：</p>
<p>对于正交矩阵 $Q \in \mathbb{R}^{n \times n}$，有 $Q = QI_nI_n^T$，这即为 $Q$ 的 $SVD$ 分解。所有奇异值均为 1。</p>
<h3 id="3-相似变换保持奇异值">(3) 相似变换保持奇异值<a hidden class="anchor" aria-hidden="true" href="#3-相似变换保持奇异值">#</a></h3>
<p><strong>解</strong>：</p>
<p>设 $B$ 的 $SVD$ 分解为 $B = U\Sigma V^T$，则</p>
$$
A = QBQ^T = QU\Sigma V^TQ^T = QU\Sigma(QV)^T = (QU)\Sigma(QV)^T
$$<p>
由于 $Q$ 正交，$QU$ 和 $QV$ 也是正交矩阵，因此 $A$ 与 $B$ 有相同的奇异值。</p>
<hr>
<h2 id="习题-7通过对角化获得-svd">习题 7：通过对角化获得 SVD<a hidden class="anchor" aria-hidden="true" href="#习题-7通过对角化获得-svd">#</a></h2>
<p><strong>题目</strong>：假设 $D$ 是一个 $n \times d$ 的矩阵，矩阵 $B$ 是 $(n+d) \times (n+d)$ 定义为
</p>
$$
B = \begin{pmatrix} 0 & D^T \\ D & 0 \end{pmatrix}
$$<p>
显然 $B$ 是对称矩阵。请证明矩阵 $B$ 的对角化会产生 $D$ 的奇异值分解所需要的所有信息。</p>
<p><strong>证明</strong>：</p>
<p>$D$ 的奇异值分解所需的所有信息为 $D^TD$ 的特征值和特征向量，以及 $DD^T$ 的特征值和特征向量。</p>
<p>设 $\lambda^2$（$\lambda > 0$）是 $D^TD$ 的特征值，对应的单位特征向量为 $x_1$（$\|x_1\|_2 = 1$）；$\lambda^2$ 也是 $DD^T$ 的特征值，对应的单位特征向量为 $x_2$（$\|x_2\|_2 = 1$）。因此，$D^TDx_1 = \lambda^2x_1$ 以及 $DD^Tx_2 = \lambda^2x_2$。</p>
<p>由第一个式子：</p>
$$
(DD^T)Dx_1 = D(D^TDx_1) = D(\lambda^2x_1) = \lambda^2 Dx_1
$$<p>
所以存在常数 $k$ 使得 $Dx_1 = kx_2$。由于 $\|x_1\|_2 = \|x_2\|_2 = 1$，可得 $k = \lambda$，即 $Dx_1 = \lambda x_2$。</p>
<p>同样地，由 $DD^Tx_2 = \lambda^2x_2$ 可得 $D^Tx_2 = \lambda x_1$。</p>
<p>下面证明 $x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}$ 是矩阵 $B$ 的特征值为 $\lambda$ 的特征向量：</p>
$$
Bx = \begin{pmatrix} 0 & D^T \\ D & 0 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} D^Tx_2 \\ Dx_1 \end{pmatrix} = \begin{pmatrix} \lambda x_1 \\ \lambda x_2 \end{pmatrix} = \lambda \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}
$$<p>因此，$D$ 的奇异值分解所需信息完全包含在 $B$ 的对角化过程中。 $\square$</p>
<hr>
<h2 id="习题-8最小二乘解的正规方程">习题 8：最小二乘解的正规方程<a hidden class="anchor" aria-hidden="true" href="#习题-8最小二乘解的正规方程">#</a></h2>
<p><strong>题目</strong>：利用等式</p>
$$
\|A(\boldsymbol{x} + \alpha\boldsymbol{w}) - \boldsymbol{b}\|_2^2 = \|A\boldsymbol{x} - \boldsymbol{b}\|_2^2 + 2\alpha\boldsymbol{w}^TA^T(A\boldsymbol{x} - \boldsymbol{b}) + \alpha^2\|A\boldsymbol{w}\|_2^2
$$<p>证明：如果 $\boldsymbol{x} \in X_{LS}$，那么 $A^TA\boldsymbol{x} = A^T\boldsymbol{b}$</p>
<p><strong>证明</strong>：</p>
<p>设 $\boldsymbol{x} \in X_{LS}$ 是最小二乘解，即 $\boldsymbol{x}$ 使得 $\|A\boldsymbol{x} - \boldsymbol{b}\|_2^2$ 最小。</p>
<p>对于任意 $\boldsymbol{w}$ 和 $\alpha$，有：</p>
$$
\|A(\boldsymbol{x} + \alpha\boldsymbol{w}) - \boldsymbol{b}\|_2^2 \geq \|A\boldsymbol{x} - \boldsymbol{b}\|_2^2
$$<p>根据给定的等式：</p>
$$
\|A\boldsymbol{x} - \boldsymbol{b}\|_2^2 + 2\alpha\boldsymbol{w}^TA^T(A\boldsymbol{x} - \boldsymbol{b}) + \alpha^2\|A\boldsymbol{w}\|_2^2 \geq \|A\boldsymbol{x} - \boldsymbol{b}\|_2^2
$$<p>简化得：</p>
$$
2\alpha\boldsymbol{w}^TA^T(A\boldsymbol{x} - \boldsymbol{b}) + \alpha^2\|A\boldsymbol{w}\|_2^2 \geq 0
$$<p>这对所有 $\alpha$ 成立。当 $\alpha \to 0$ 时，主导项是 $2\alpha\boldsymbol{w}^TA^T(A\boldsymbol{x} - \boldsymbol{b})$。</p>
<p>为使不等式对正负 $\alpha$ 都成立，必须有：</p>
$$
\boldsymbol{w}^TA^T(A\boldsymbol{x} - \boldsymbol{b}) = 0
$$<p>由于 $\boldsymbol{w}$ 是任意的,因此：</p>
$$
A^T(A\boldsymbol{x} - \boldsymbol{b}) = 0 \quad \Rightarrow \quad A^TA\boldsymbol{x} = A^T\boldsymbol{b}
$$<p>$\square$</p>
<hr>
<h1 id="作业四">作业四<a hidden class="anchor" aria-hidden="true" href="#作业四">#</a></h1>
<h2 id="习题-1qr-分解求解最小二乘问题">习题 1：QR 分解求解最小二乘问题<a hidden class="anchor" aria-hidden="true" href="#习题-1qr-分解求解最小二乘问题">#</a></h2>
<p><strong>题目</strong>：设</p>
$$
A = \begin{pmatrix} 1 & 3 & 1 & 1 \\ 2 & 0 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}, \quad b = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}
$$<p>利用 QR 分解求对应的 LS 问题的全部解。</p>
<p><strong>解</strong>：</p>
<p>观察矩阵 $A$，第3、4列相同，且通过简单计算可知 $\text{rank}(A) = 2 < 4$，该 LS 问题有无穷多解。</p>
<p><strong>第一步：对 $A$ 进行 QR 分解</strong></p>
<p>由于 $\text{rank}(A) = 2$，只需计算 $q_1, q_2$。设 $a_1 = \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}$，$a_2 = \begin{pmatrix} 3 \\ 0 \\ 0 \end{pmatrix}$。</p>
<p>使用 Gram-Schmidt 正交化：</p>
<p>计算 $q_1$：</p>
$$
r_{11} = \|a_1\| = \sqrt{6}, \quad q_1 = \frac{1}{\sqrt{6}} \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}
$$<p>计算 $q_2$：</p>
$$
r_{12} = a_2^T q_1 = \frac{\sqrt{6}}{2}
$$$$
\tilde{q}_2 = a_2 - r_{12}q_1 = \begin{pmatrix} 3 \\ 0 \\ 0 \end{pmatrix} - \frac{1}{2} \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix} = \begin{pmatrix} 5/2 \\ -1 \\ -1/2 \end{pmatrix}
$$$$
r_{22} = \|\tilde{q}_2\| = \frac{\sqrt{30}}{2}, \quad q_2 = \frac{1}{\sqrt{30}} \begin{pmatrix} 5 \\ -2 \\ -1 \end{pmatrix}
$$<p>计算 $R$ 矩阵的其余元素（通过投影得到）：</p>
$$
r_{13} = a_3^T q_1 = \frac{1}{\sqrt{6}}, \quad r_{23} = a_3^T q_2 = \frac{5}{\sqrt{30}}
$$$$
r_{14} = a_4^T q_1 = \frac{1}{\sqrt{6}}, \quad r_{24} = a_4^T q_2 = \frac{5}{\sqrt{30}}
$$<p>因此：</p>
$$
Q_1 = \begin{pmatrix} \frac{1}{\sqrt{6}} & \frac{5}{\sqrt{30}} \\ \frac{2}{\sqrt{6}} & -\frac{2}{\sqrt{30}} \\ \frac{1}{\sqrt{6}} & -\frac{1}{\sqrt{30}} \end{pmatrix}, \quad R_1 = \begin{bmatrix} \sqrt{6} & \frac{\sqrt{6}}{2} & \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{6}} \\ 0 & \frac{\sqrt{30}}{2} & \frac{5}{\sqrt{30}} & \frac{5}{\sqrt{30}} \end{bmatrix}
$$<p><strong>第二步：计算 $Q_1^T b$</strong></p>
$$
Q_1^T b = \begin{bmatrix} \frac{1}{\sqrt{6}} & \frac{2}{\sqrt{6}} & \frac{1}{\sqrt{6}} \\ \frac{5}{\sqrt{30}} & -\frac{2}{\sqrt{30}} & -\frac{1}{\sqrt{30}} \end{bmatrix} \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix} = \begin{bmatrix} \frac{2\sqrt{6}}{3} \\ \frac{\sqrt{30}}{15} \end{bmatrix}
$$<p><strong>第三步：求解 $R_1 x = Q_1^T b$</strong></p>
<p>由于 $\text{rank}(A) = 2$，将 $x$ 分为 $(x_1, x_2)^T$（基本变量）和 $(x_3, x_4)^T$（自由变量）。</p>
<p>方程组为：</p>
$$
\begin{cases}
\sqrt{6}x_1 + \frac{\sqrt{6}}{2}x_2 + \frac{\sqrt{6}}{6}x_3 + \frac{\sqrt{6}}{6}x_4 = \frac{2\sqrt{6}}{3} \\
\frac{\sqrt{30}}{2}x_2 + \frac{\sqrt{30}}{6}x_3 + \frac{\sqrt{30}}{6}x_4 = \frac{\sqrt{30}}{15}
\end{cases}
$$<p>简化得：</p>
$$
\begin{cases}
x_1 + \frac{1}{2}x_2 + \frac{1}{6}x_3 + \frac{1}{6}x_4 = \frac{2}{3} \\
3x_2 + x_3 + x_4 = \frac{2}{5}
\end{cases}
$$<p>从第二个方程：</p>
$$
x_2 = \frac{2}{15} - \frac{1}{3}x_3 - \frac{1}{3}x_4
$$<p>代入第一个方程：</p>
$$
x_1 + \frac{1}{2}\left(\frac{2}{15} - \frac{1}{3}x_3 - \frac{1}{3}x_4\right) + \frac{1}{6}x_3 + \frac{1}{6}x_4 = \frac{2}{3}
$$$$
x_1 + \frac{1}{15} - \frac{1}{6}x_3 - \frac{1}{6}x_4 + \frac{1}{6}x_3 + \frac{1}{6}x_4 = \frac{2}{3}
$$$$
x_1 = \frac{2}{3} - \frac{1}{15} = \frac{3}{5}
$$<p><strong>全部解：</strong></p>
$$
x = \begin{pmatrix} 3/5 \\ 2/15 \\ 0 \\ 0 \end{pmatrix} + x_3 \begin{pmatrix} 0 \\ -1/3 \\ 1 \\ 0 \end{pmatrix} + x_4 \begin{pmatrix} 0 \\ -1/3 \\ 0 \\ 1 \end{pmatrix}, \quad x_3, x_4 \in \mathbb{R}
$$<hr>
<h2 id="习题-2最小二乘解的性质">习题 2：最小二乘解的性质<a hidden class="anchor" aria-hidden="true" href="#习题-2最小二乘解的性质">#</a></h2>
<p><strong>题目</strong>：设 $A \in \mathbb{R}^{m\times n}$ 且存在 $X \in \mathbb{R}^{n\times m}$ 使得对每一个 $b \in \mathbb{R}^m$，$x = Xb$ 均极小化 $\|Ax - b\|_2$。</p>
<p>证明：$AXA = A$ 和 $(AX)^T = AX$。</p>
<p><strong>证明</strong>：</p>
<p>由最小二乘理论，$x = Xb$ 满足正规方程 $A^T(Ax - b) = 0$，代入得：</p>
$$
A^TAXb = A^Tb, \quad \forall b \in \mathbb{R}^m
$$<p>因此：</p>
$$
A^TAX = A^T \tag{1}
$$<p>对任意 $y \in \mathbb{R}^n$，令 $b = Ay$，则 $x = XAy$ 是 $\min_x \|Ax - Ay\|_2$ 的解。由于 $x = y$ 使目标函数为零，故：</p>
$$
\|AXAy - Ay\|_2 = 0, \quad \forall y \in \mathbb{R}^n
$$<p>因此：</p>
$$
AXA = A \tag{2}
$$<p>由 (1) 和 (2)，有：</p>
$$
(AX)^2 = AXAX = A(XA)X = AAX = AX
$$<p>即 $AX$ 是幂等矩阵。</p>
<p>由 (1)，两边取转置得 $X^TA^TA = A$，因此：</p>
$$
(AX)^TAX = X^TA^TAX = X^TA^T = (AX)^T
$$<p>结合 $(AX)^2 = AX$：</p>
$$
(AX)^T = (AX)^TAX = (AX)AX = AX
$$<p>因此 $(AX)^T = AX$。</p>
<p>$\square$</p>
<hr>
<h2 id="习题-3gerschgorin-圆盘定理估计特征值范围">习题 3：Gerschgorin 圆盘定理估计特征值范围<a hidden class="anchor" aria-hidden="true" href="#习题-3gerschgorin-圆盘定理估计特征值范围">#</a></h2>
<p><strong>题目</strong>：估计矩阵</p>
$$
A = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 2 & 1 \\ 0 & 1 & -4 \end{pmatrix}
$$<p>的特征值范围。</p>
<p><strong>解</strong>：</p>
<p>使用 Gerschgorin 圆盘定理。该定理指出：矩阵 $A$ 的所有特征值都位于 Gerschgorin 圆盘</p>
$$
D_i = \{z \in \mathbb{C} : |z - a_{ii}| \leq R_i\}, \quad R_i = \sum_{j\neq i} |a_{ij}|
$$<p>的并集中。</p>
<p>计算各圆盘：</p>
<p><strong>圆盘 $D_1$：</strong> 中心 $a_{11} = 0$，半径 $R_1 = |1| + |0| = 1$</p>
$$
D_1: |z| \leq 1 \quad \Rightarrow \quad [-1, 1]
$$<p><strong>圆盘 $D_2$：</strong> 中心 $a_{22} = 2$，半径 $R_2 = |1| + |1| = 2$</p>
$$
D_2: |z - 2| \leq 2 \quad \Rightarrow \quad [0, 4]
$$<p><strong>圆盘 $D_3$：</strong> 中心 $a_{33} = -4$，半径 $R_3 = |0| + |1| = 1$</p>
$$
D_3: |z + 4| \leq 1 \quad \Rightarrow \quad [-5, -3]
$$<p>由于 $A$ 是实对称矩阵，特征值必为实数。因此特征值范围为：</p>
$$
\lambda \in D_1 \cup D_2 \cup D_3 = [-1, 1] \cup [0, 4] \cup [-5, -3] = [-5, -3] \cup [-1, 4]
$$<hr>
<h2 id="习题-4幂法求模最大特征值">习题 4：幂法求模最大特征值<a hidden class="anchor" aria-hidden="true" href="#习题-4幂法求模最大特征值">#</a></h2>
<p><strong>题目</strong>：利用幂法求解矩阵</p>
$$
A = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 2 & 1 \\ 0 & 1 & -4 \end{pmatrix}
$$<p>模最大的特征值与对应的特征向量。（可编程计算结果，特征值答案保留两位有效数字，特征向量答案保留三位有效数字）</p>
<p><strong>解</strong>：</p>
<p><strong>幂法迭代：</strong></p>
<p>取初始向量 $v^{(0)} = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}$，按迭代公式 $v^{(k+1)} = \frac{Av^{(k)}}{\|Av^{(k)}\|_2}$ 进行计算，特征值估计为 $\lambda^{(k)} = (v^{(k)})^T Av^{(k)}$。</p>
<p>主要迭代过程：</p>
<p><strong>迭代 1：</strong></p>
$$
Av^{(0)} = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}, \quad \|Av^{(0)}\|_2 = 1, \quad v^{(1)} = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}, \quad \lambda^{(1)} = 0
$$<p><strong>迭代 2：</strong></p>
$$
Av^{(1)} = \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}, \quad \|Av^{(1)}\|_2 = \sqrt{6} \approx 2.449, \quad v^{(2)} = \begin{pmatrix} 0.408 \\ 0.816 \\ 0.408 \end{pmatrix}, \quad \lambda^{(2)} = 2.000
$$<p><strong>迭代 5：</strong></p>
$$
v^{(5)} = \begin{pmatrix} 0.189 \\ 0.694 \\ -0.694 \end{pmatrix}, \quad \lambda^{(5)} = -0.043
$$<p><strong>迭代 11：</strong></p>
$$
v^{(11)} = \begin{pmatrix} -0.025 \\ 0.203 \\ -0.979 \end{pmatrix}, \quad \lambda^{(11)} = -4.140
$$<p>迭代约 30 次后收敛。</p>
<p><strong>最终结果：</strong></p>
<p>模最大特征值：$\lambda = -4.2$ （两位有效数字）</p>
<p>对应特征向量：$v = \begin{pmatrix} 0.040 \\ -0.166 \\ 0.985 \end{pmatrix}$ （三位有效数字）</p>
<p><strong>验证：</strong> 使用 NumPy 计算得矩阵所有特征值为 $\lambda_1 \approx 2.546$，$\lambda_2 \approx -0.377$，$\lambda_3 \approx -4.169$，确认 $|\lambda_3|$ 最大，幂法结果正确。</p>
<hr>
<h2 id="习题-5反幂法求模最小特征值">习题 5：反幂法求模最小特征值<a hidden class="anchor" aria-hidden="true" href="#习题-5反幂法求模最小特征值">#</a></h2>
<p><strong>题目</strong>：利用反幂法求解矩阵</p>
$$
A = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 2 & 1 \\ 0 & 1 & -4 \end{pmatrix}
$$<p>模最小的特征值与对应的特征向量。（可编程计算结果，特征值答案保留两位有效数字，特征向量答案保留三位有效数字）</p>
<p><strong>解</strong>：</p>
<p><strong>反幂法迭代：</strong></p>
<p>反幂法通过求解线性方程组 $Av^{(k)} = v^{(k-1)}$ 并归一化来迭代，收敛到模最小特征值对应的特征向量。</p>
<p>取初始向量 $v^{(0)} = \frac{1}{\sqrt{3}}\begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0.577 \\ 0.577 \\ 0.577 \end{pmatrix}$。</p>
<p>主要迭代过程：</p>
<p><strong>迭代 1：</strong></p>
<p>求解 $Ax = v^{(0)}$ 得 $x = \begin{pmatrix} -0.577 \\ 0.577 \\ 0 \end{pmatrix}$，归一化后</p>
$$
v^{(1)} = \begin{pmatrix} -0.707 \\ 0.707 \\ 0 \end{pmatrix}, \quad \lambda^{(1)} = 0
$$<p><strong>迭代 2：</strong></p>
$$
v^{(2)} = \begin{pmatrix} 0.953 \\ -0.293 \\ -0.073 \end{pmatrix}, \quad \lambda^{(2)} = -0.366
$$<p><strong>迭代 3：</strong></p>
$$
v^{(3)} = \begin{pmatrix} -0.928 \\ 0.360 \\ 0.097 \end{pmatrix}, \quad \lambda^{(3)} = -0.377
$$<p><strong>迭代 5：</strong></p>
$$
v^{(5)} = \begin{pmatrix} -0.931 \\ 0.351 \\ 0.097 \end{pmatrix}, \quad \lambda^{(5)} = -0.377
$$<p>迭代约 11 次后收敛。</p>
<p><strong>最终结果：</strong></p>
<p>模最小特征值：$\lambda = -0.38$ （两位有效数字）</p>
<p>对应特征向量：$v = \begin{pmatrix} 0.931 \\ -0.351 \\ -0.097 \end{pmatrix}$ （三位有效数字）</p>
<p><strong>验证：</strong> 使用 NumPy 计算得矩阵所有特征值为 $\lambda_1 \approx 2.546$，$\lambda_2 \approx -0.377$，$\lambda_3 \approx -4.169$，确认 $|\lambda_2|$ 最小，反幂法结果正确。残差 $\|Av - \lambda v\| \approx 1.25 \times 10^{-16}$。</p>
<hr>
<h2 id="习题-6原点位移法求全部特征值">习题 6：原点位移法求全部特征值<a hidden class="anchor" aria-hidden="true" href="#习题-6原点位移法求全部特征值">#</a></h2>
<p><strong>题目</strong>：利用原点位移法求解矩阵</p>
$$
A = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 2 & 1 \\ 0 & 1 & -4 \end{pmatrix}
$$<p>全部特征值与对应的特征向量。（可编程计算结果，特征值答案保留两位有效数字，特征向量答案保留三位有效数字）</p>
<p><strong>解</strong>：</p>
<p><strong>求解策略：</strong></p>
<p>原点位移法通过选择不同的位移参数 $\mu$，利用 $A - \mu I$ 的特征值为 $\lambda - \mu$ 的性质，结合幂法和反幂法求得全部特征值。</p>
<p><strong>第一步：幂法求模最大特征值</strong></p>
<p>对 $A$ 使用标准幂法，收敛得：</p>
$$
\lambda_3 = -4.169, \quad v_3 = \begin{pmatrix} 0.040 \\ -0.166 \\ 0.985 \end{pmatrix}
$$<p><strong>第二步：反幂法求模最小特征值</strong></p>
<p>对 $A$ 使用反幂法，收敛得：</p>
$$
\lambda_2 = -0.377, \quad v_2 = \begin{pmatrix} 0.931 \\ -0.351 \\ -0.097 \end{pmatrix}
$$<p><strong>第三步：带位移反幂法求中间特征值</strong></p>
<p>选择位移 $\mu = 2.5$（接近估计的中间特征值），对 $A - 2.5I$ 使用反幂法。取初始向量 $v^{(0)} = \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}$，迭代 6 次后收敛得：</p>
$$
\lambda_1 = 2.546, \quad v_1 = \begin{pmatrix} 0.362 \\ 0.921 \\ 0.141 \end{pmatrix}
$$<p><strong>最终结果汇总（按从大到小排序）：</strong></p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">特征值（两位有效数字）</th>
          <th style="text-align: center">特征向量（三位有效数字）</th>
          <th style="text-align: center">残差</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">$\lambda_1 = 2.5$</td>
          <td style="text-align: center">$\begin{pmatrix} 0.362 \\ 0.921 \\ 0.141 \end{pmatrix}$</td>
          <td style="text-align: center">$2.10 \times 10^{-11}$</td>
      </tr>
      <tr>
          <td style="text-align: center">$\lambda_2 = -0.38$</td>
          <td style="text-align: center">$\begin{pmatrix} 0.931 \\ -0.351 \\ -0.097 \end{pmatrix}$</td>
          <td style="text-align: center">$1.25 \times 10^{-16}$</td>
      </tr>
      <tr>
          <td style="text-align: center">$\lambda_3 = -4.2$</td>
          <td style="text-align: center">$\begin{pmatrix} 0.040 \\ -0.166 \\ 0.985 \end{pmatrix}$</td>
          <td style="text-align: center">$< 10^{-16}$</td>
      </tr>
  </tbody>
</table>
<p>所有残差 $\|Av_i - \lambda_i v_i\|$ 均在数值误差范围内，验证结果正确。</p>
<hr>
<h2 id="习题-7gerschgorin-圆盘定理与条件数">习题 7：Gerschgorin 圆盘定理与条件数<a hidden class="anchor" aria-hidden="true" href="#习题-7gerschgorin-圆盘定理与条件数">#</a></h2>
<p><strong>题目</strong>：设</p>
$$
A = \begin{pmatrix} 5 & -1 & 1 \\ -1 & 2 & 0 \\ 1 & 0 & 3 \end{pmatrix}
$$<p>记 $\Lambda(A) = \{\lambda_1, \lambda_2, \lambda_3\} \subseteq \mathbb{C}$ 且 $|\lambda_1| \geq |\lambda_2| \geq |\lambda_3|$。</p>
<p><strong>(1)</strong> 使用 Gerschgorin 圆盘定理，证明 $\frac{|\lambda_1|}{|\lambda_3|} \leq 7$。</p>
<p><strong>(2)</strong> （编程题）使用幂法与反幂法计算 $\frac{|\lambda_1|}{|\lambda_3|}$</p>
<h3 id="1-gerschgorin-圆盘定理证明">(1) Gerschgorin 圆盘定理证明<a hidden class="anchor" aria-hidden="true" href="#1-gerschgorin-圆盘定理证明">#</a></h3>
<p><strong>证明</strong>：</p>
<p>Gerschgorin 圆盘定理：矩阵 $A$ 的所有特征值都位于 Gerschgorin 圆盘的并集中，第 $i$ 个圆盘定义为：</p>
$$
D_i = \{z \in \mathbb{C} : |z - a_{ii}| \leq R_i\}, \quad R_i = \sum_{j\neq i} |a_{ij}|
$$<p>对于矩阵 $A = \begin{pmatrix} 5 & -1 & 1 \\ -1 & 2 & 0 \\ 1 & 0 & 3 \end{pmatrix}$：</p>
$$
D_1: a_{11} = 5, \; R_1 = |-1| + |1| = 2 \quad \Rightarrow \quad z \in [3, 7]
$$$$
D_2: a_{22} = 2, \; R_2 = |-1| + |0| = 1 \quad \Rightarrow \quad z \in [1, 3]
$$$$
D_3: a_{33} = 3, \; R_3 = |1| + |0| = 1 \quad \Rightarrow \quad z \in [2, 4]
$$<p>所有特征值 $\lambda \in D_1 \cup D_2 \cup D_3 = [1, 7]$。因为 $A$ 是实对称矩阵，所有特征值都是实数且为正。</p>
<p>从圆盘分析得：$|\lambda_1| \leq 7$，$|\lambda_3| \geq 1$，因此：</p>
$$
\kappa(A) = \frac{|\lambda_1|}{|\lambda_3|} \leq \frac{7}{1} = 7
$$<p>$\square$</p>
<h3 id="2-幂法与反幂法计算条件数">(2) 幂法与反幂法计算条件数<a hidden class="anchor" aria-hidden="true" href="#2-幂法与反幂法计算条件数">#</a></h3>
<p><strong>解</strong>：</p>
<p>通过编程实现幂法和反幂法，迭代计算如下：</p>
<p><strong>幂法求 $\lambda_{\max}$ 的前 5 步迭代：</strong></p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">迭代次数</th>
          <th style="text-align: center">特征值估计</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">1</td>
          <td style="text-align: center">4.880952</td>
      </tr>
      <tr>
          <td style="text-align: center">2</td>
          <td style="text-align: center">5.475970</td>
      </tr>
      <tr>
          <td style="text-align: center">3</td>
          <td style="text-align: center">5.612480</td>
      </tr>
      <tr>
          <td style="text-align: center">4</td>
          <td style="text-align: center">5.642355</td>
      </tr>
      <tr>
          <td style="text-align: center">5</td>
          <td style="text-align: center">5.649083</td>
      </tr>
  </tbody>
</table>
<p>收敛于第 32 步，得 $\lambda_{\max} = 5.6510934089$</p>
<p><strong>反幂法求 $\lambda_{\min}$ 的前 5 步迭代：</strong></p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">迭代次数</th>
          <th style="text-align: center">特征值估计</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">1</td>
          <td style="text-align: center">2.126100</td>
      </tr>
      <tr>
          <td style="text-align: center">2</td>
          <td style="text-align: center">1.769336</td>
      </tr>
      <tr>
          <td style="text-align: center">3</td>
          <td style="text-align: center">1.671936</td>
      </tr>
      <tr>
          <td style="text-align: center">4</td>
          <td style="text-align: center">1.640106</td>
      </tr>
      <tr>
          <td style="text-align: center">5</td>
          <td style="text-align: center">1.628943</td>
      </tr>
  </tbody>
</table>
<p>收敛于第 44 步，得 $\lambda_{\min} = 1.6227971460$</p>
<p><strong>条件数计算：</strong></p>
$$
\kappa(A) = \frac{|\lambda_{\max}|}{|\lambda_{\min}|} = \frac{5.6510934089}{1.6227971460} = 3.4823165808
$$<p>保留两位有效数字：$\kappa(A) \approx 3.48$</p>
<p><strong>验证：</strong></p>
$$
\kappa(A) = 3.48 < 7 \quad \checkmark
$$<p>这验证了 Gerschgorin 圆盘定理给出的上界估计是正确的。实际条件数远小于理论上界 7，说明理论估计较为保守但有效。</p>
<h1 id="作业五">作业五<a hidden class="anchor" aria-hidden="true" href="#作业五">#</a></h1>
<hr>
<h2 id="习题-1梯度计算">习题 1：梯度计算<a hidden class="anchor" aria-hidden="true" href="#习题-1梯度计算">#</a></h2>
<p><strong>题目</strong>：构建模型使得预测值与真实值的误差最小常用向量 2-范数度量，求解模型过程中需要计算梯度，求梯度：</p>
<p><strong>(1)</strong> $f(A) = \frac{1}{2}\|Ax + b - y\|_2^2$，求 $\frac{\partial f}{\partial A}$</p>
<p><strong>(2)</strong> $f(x) = \frac{1}{2}\|Ax + b - y\|_2^2$，求 $\frac{\partial f}{\partial x}$</p>
<p>其中 $A \in \mathbb{R}^{m\times n}$，$x \in \mathbb{R}^n$，$b, y \in \mathbb{R}^m$</p>
<p><strong>解</strong>：</p>
<p><strong>(1) 关于 $A$ 的梯度</strong></p>
<p>展开目标函数：</p>
$$
f(A) = \frac{1}{2}\|Ax + b - y\|_2^2 = \frac{1}{2}(Ax + b - y)^T(Ax + b - y)
$$$$
= \frac{1}{2}(x^TA^TAx + 2(b-y)^TAx + (b-y)^T(b-y))
$$<p>由于 $(b-y)^T(b-y)$ 是常数，对 $A$ 求导后为零：</p>
$$
\frac{\partial f}{\partial A} = \frac{\partial}{\partial A}\frac{1}{2}(x^TA^TAx + 2(b-y)^TAx)
$$<p>利用矩阵求导公式：</p>
<ul>
<li>$\frac{\partial x^TA^TAx}{\partial A} = 2Axx^T$</li>
<li>$\frac{\partial (b-y)^TAx}{\partial A} = (b-y)x^T$</li>
</ul>
<p>因此：</p>
$$
\frac{\partial f}{\partial A} = Axx^T + (b-y)x^T
$$<p><strong>(2) 关于 $x$ 的梯度</strong></p>
<p>同样展开目标函数，对 $x$ 求导：</p>
$$
\frac{\partial f}{\partial x} = \frac{\partial}{\partial x}\frac{1}{2}(x^TA^TAx + 2(b-y)^TAx + (b-y)^T(b-y))
$$<p>利用矩阵求导公式：</p>
<ul>
<li>$\frac{\partial x^TA^TAx}{\partial x} = 2A^TAx$</li>
<li>$\frac{\partial (b-y)^TAx}{\partial x} = A^T(b-y)$</li>
</ul>
<p>因此：</p>
$$
\frac{\partial f}{\partial x} = A^TAx + A^T(b-y)
$$<hr>
<h2 id="习题-2二次型的梯度">习题 2：二次型的梯度<a hidden class="anchor" aria-hidden="true" href="#习题-2二次型的梯度">#</a></h2>
<p><strong>题目</strong>：二次型是数据分析中常用函数，求 $\frac{\partial x^TAx}{\partial x}$，$\frac{\partial x^TAx}{\partial A}$，其中 $A \in \mathbb{R}^{m\times m}$，$x \in \mathbb{R}^m$</p>
<p><strong>解</strong>：</p>
<p><strong>(1) 关于 $x$ 的梯度</strong></p>
<p>对于二次型 $x^TAx$，利用矩阵微分的性质：</p>
$$
d(x^TAx) = (dx)^TAx + x^TAdx = x^TA^Tdx + x^TAdx = x^T(A + A^T)dx
$$<p>因此：</p>
$$
\frac{\partial x^TAx}{\partial x} = (A + A^T)x
$$<p><strong>注</strong>：当 $A$ 为对称矩阵时，$\frac{\partial x^TAx}{\partial x} = 2Ax$</p>
<p><strong>(2) 关于 $A$ 的梯度</strong></p>
<p>对于二次型 $x^TAx = \sum_{i,j} x_i A_{ij} x_j$，对 $A_{ij}$ 求偏导：</p>
$$
\frac{\partial x^TAx}{\partial A_{ij}} = x_ix_j
$$<p>因此，梯度矩阵的第 $(i,j)$ 元素为 $x_ix_j$，即：</p>
$$
\frac{\partial x^TAx}{\partial A} = xx^T
$$<hr>
<h2 id="习题-3迹微分法求梯度">习题 3：迹微分法求梯度<a hidden class="anchor" aria-hidden="true" href="#习题-3迹微分法求梯度">#</a></h2>
<p><strong>题目</strong>：利用迹微分法求解 $\frac{\partial \text{tr}(W^{-1})}{\partial W}$，其中 $W \in \mathbb{R}^{m\times m}$</p>
<p><strong>解</strong>：</p>
<p>首先计算 $W^{-1}$ 的微分。由恒等式 $WW^{-1} = I$，两边取微分：</p>
$$
d(WW^{-1}) = dW \cdot W^{-1} + W \cdot dW^{-1} = dI = 0
$$<p>因此：</p>
$$
W \cdot dW^{-1} = -dW \cdot W^{-1}
$$<p>两边左乘 $W^{-1}$：</p>
$$
dW^{-1} = -W^{-1}dW \cdot W^{-1}
$$<p>现在计算迹的微分：</p>
$$
d\,\text{tr}(W^{-1}) = \text{tr}(dW^{-1}) = \text{tr}(-W^{-1}dW \cdot W^{-1})
$$<p>利用迹的循环性质 $\text{tr}(ABC) = \text{tr}(CAB)$：</p>
$$
d\,\text{tr}(W^{-1}) = \text{tr}(-(W^{-1})^2dW) = \text{tr}(-(W^{-T})^2 dW)
$$<p>因此：</p>
$$
\frac{\partial \text{tr}(W^{-1})}{\partial W} = -(W^{-T})^2
$$<hr>
<h2 id="习题-4softmax-函数的梯度">习题 4：Softmax 函数的梯度<a hidden class="anchor" aria-hidden="true" href="#习题-4softmax-函数的梯度">#</a></h2>
<p><strong>题目</strong>：$(\exp(z))_i = \exp(z_i)$，$(\log(z))_i = \log(z_i)$，$f(z) = \frac{\exp(z)}{\mathbf{1}^T\exp(z)}$ 称为 softmax 函数，如果 $q = f(z)$，$J = -p^T\log(q)$，其中 $p, q, z \in \mathbb{R}^n$，并且 $\mathbf{1}^Tp = 1$，</p>
<p><strong>(1)</strong> 证明：$\frac{\partial J}{\partial z} = q - p$</p>
<p><strong>(2)</strong> 若 $z = Wx$，其中 $W \in \mathbb{R}^{n\times m}$，$x \in \mathbb{R}^m$，$\frac{\partial J}{\partial W} = (q - p)x^T$ 是否成立。</p>
<p><strong>解</strong>：</p>
<h3 id="1-证明关于--的梯度">(1) 证明关于 $z$ 的梯度<a hidden class="anchor" aria-hidden="true" href="#1-证明关于--的梯度">#</a></h3>
<p>将损失函数展开：</p>
$$
J = -p^T\log(q) = -p^T\log\left(\frac{\exp(z)}{\mathbf{1}^T\exp(z)}\right)
$$$$
= -p^T\log(\exp(z)) + p^T\log(\mathbf{1}^T\exp(z))\mathbf{1}
$$$$
= -p^Tz + p^T\mathbf{1}\log(\mathbf{1}^T\exp(z))
$$<p>由于 $p^T\mathbf{1} = 1$（概率分布的归一化条件）：</p>
$$
J = -p^Tz + \log(\mathbf{1}^T\exp(z))
$$<p>对 $z$ 求导：</p>
$$
\frac{\partial J}{\partial z} = -p + \frac{\partial \log(\mathbf{1}^T\exp(z))}{\partial z}= -p + \frac{1}{\mathbf{1}^T\exp(z)} \cdot \frac{\partial (\mathbf{1}^T\exp(z))}{\partial z}
$$$$
= -p + \frac{\exp(z)}{\mathbf{1}^T\exp(z)}= -p + q
$$<p>因此：</p>
$$
\frac{\partial J}{\partial z} = q - p
$$<h3 id="2-证明关于--的梯度">(2) 证明关于 $W$ 的梯度<a hidden class="anchor" aria-hidden="true" href="#2-证明关于--的梯度">#</a></h3>
<p>利用链式法则和迹微分法：</p>
$$
dJ = d\,\text{tr}(J) = \text{tr}(dJ)
$$<p>由 $z = Wx$，有 $dz = dW \cdot x$，因此：</p>
$$
dJ = \text{tr}\left[\left(\frac{\partial J}{\partial z}\right)^T dz\right] = \text{tr}[(q-p)^T dW \cdot x]
$$<p>利用迹的性质 $\text{tr}(ABC) = \text{tr}(CAB)$：</p>
$$
dJ = \text{tr}[x(q-p)^T dW]
$$<p>因此：</p>
$$
\frac{\partial J}{\partial W} = (q-p)x^T \quad \text{成立}
$$<hr>
<h2 id="习题-5多元正态分布的极大似然估计">习题 5：多元正态分布的极大似然估计<a hidden class="anchor" aria-hidden="true" href="#习题-5多元正态分布的极大似然估计">#</a></h2>
<p><strong>题目</strong>：以下内容是利用极大似然估计求解多元正态分布模型的关键步骤：</p>
$$
L = -\frac{Nd}{2}\ln(2\pi) - \frac{N}{2}\ln|\Sigma| - \frac{1}{2}\sum_{t=1}^N (x_t - \mu)^T\Sigma^{-1}(x_t - \mu)
$$<p>$L$ 是对数似然，$N$ 为样本数，$d$ 为样本维数，$\Sigma \in \mathbb{R}^{d\times d}$ 为协方差矩阵，$\mu \in \mathbb{R}^d$ 为期望向量。</p>
<p><strong>(1)</strong> 求 $\frac{\partial L}{\partial \mu}$</p>
<p><strong>(2)</strong> 当 $\mu = \frac{1}{N}\sum_{t=1}^N x_t$ 时，求 $\frac{\partial L}{\partial \Sigma}$，并求使 $\frac{\partial L}{\partial \Sigma} = 0$ 成立的 $\Sigma$。</p>
<p><strong>解</strong>：</p>
<h3 id="1-关于--的梯度">(1) 关于 $\mu$ 的梯度<a hidden class="anchor" aria-hidden="true" href="#1-关于--的梯度">#</a></h3>
<p>对数似然中只有第三项与 $\mu$ 相关：</p>
$$
\frac{\partial L}{\partial \mu} = \frac{\partial}{\partial \mu}\left[-\frac{1}{2}\sum_{t=1}^N (x_t - \mu)^T\Sigma^{-1}(x_t - \mu)\right]
$$<p>对每一项求导：</p>
$$
\frac{\partial}{\partial \mu}(x_t - \mu)^T\Sigma^{-1}(x_t - \mu) = -2\Sigma^{-1}(x_t - \mu)
$$<p>因此：</p>
$$
\frac{\partial L}{\partial \mu} = \sum_{t=1}^N \Sigma^{-1}(x_t - \mu)
$$<p>令 $\frac{\partial L}{\partial \mu} = 0$，得 $\mu = \frac{1}{N}\sum_{t=1}^N x_t$（样本均值）。</p>
<h3 id="2-关于--的梯度">(2) 关于 $\Sigma$ 的梯度<a hidden class="anchor" aria-hidden="true" href="#2-关于--的梯度">#</a></h3>
<p>使用迹微分法，将对数似然写成迹的形式：</p>
$$
dL = d\left[-\frac{N}{2}\ln|\Sigma|\right] - d\left[\frac{1}{2}\sum_{t=1}^N (x_t-\mu)^T\Sigma^{-1}(x_t-\mu)\right]
$$<p><strong>第一项：</strong></p>
$$
d\left[-\frac{N}{2}\ln|\Sigma|\right] = -\frac{N}{2}d[\ln|\Sigma|] = -\frac{N}{2}\text{tr}[\Sigma^{-1}d\Sigma]
$$<p><strong>第二项：</strong></p>
$$
d\left[\frac{1}{2}\sum_{t=1}^N (x_t-\mu)^T\Sigma^{-1}(x_t-\mu)\right] = \frac{1}{2}d\,\text{tr}\left[\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T\Sigma^{-1}\right]
$$$$
= \frac{1}{2}\text{tr}\left[\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T d(\Sigma^{-1})\right]
$$<p>利用 $d\Sigma^{-1} = -\Sigma^{-1}(d\Sigma)\Sigma^{-1}$：</p>
$$
= \frac{1}{2}\text{tr}\left[\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T(-\Sigma^{-1}d\Sigma \cdot \Sigma^{-1})\right]
$$$$
= -\frac{1}{2}\text{tr}\left[\Sigma^{-1}\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T\Sigma^{-1}d\Sigma\right]
$$<p>综合两项：</p>
$$
dL = \text{tr}\left[\left(-\frac{N}{2}\Sigma^{-1} + \frac{1}{2}\Sigma^{-1}\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T\Sigma^{-1}\right)d\Sigma\right]
$$<p>因此：</p>
$$
\frac{\partial L}{\partial \Sigma} = -\frac{N}{2}\Sigma^{-1} + \frac{1}{2}\Sigma^{-1}\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T\Sigma^{-1}
$$<p>令 $\frac{\partial L}{\partial \Sigma} = 0$：</p>
$$
N\Sigma^{-1} = \Sigma^{-1}\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T\Sigma^{-1}
$$<p>两边左乘 $\Sigma$，右乘 $\Sigma$：</p>
$$
N\Sigma = \sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T
$$<p>因此：</p>
$$
\Sigma = \frac{1}{N}\sum_{t=1}^N (x_t-\mu)(x_t-\mu)^T
$$<p>这就是样本协方差矩阵的极大似然估计。</p>
<hr>
<h2 id="习题-6互信息的化简">习题 6：互信息的化简<a hidden class="anchor" aria-hidden="true" href="#习题-6互信息的化简">#</a></h2>
<p><strong>题目</strong>：（互信息）假设 $X_1 \to X_2 \to X_3 \to \cdots \to X_n$ 是一个马尔科夫链，即</p>
$$
p(x_1, x_2, \ldots, x_n) = p(x_1)p(x_2|x_1)\cdots p(x_n|x_{n-1})
$$<p>试化简 $I(X_1; X_2, \ldots, X_n)$</p>
<p><strong>解</strong>：</p>
<p>互信息定义为：</p>
$$
I(X_1; X_2, \ldots, X_n) = H(X_1) - H(X_1 | X_2, \ldots, X_n)
$$<p>利用条件熵的性质：</p>
$$
= H(X_1) - [H(X_1, X_2, \ldots, X_n) - H(X_2, \ldots, X_n)]
$$<p>对于马尔科夫链，联合熵可以分解为：</p>
$$
H(X_1, X_2, \ldots, X_n) = \sum_{i=1}^n H(X_i|X_{i-1},\ldots,X_1)
$$<p>其中 $H(X_1|X_0,\ldots) = H(X_1)$。由马尔科夫性质：</p>
$$
H(X_i|X_{i-1},\ldots,X_1) = H(X_i|X_{i-1})
$$<p>类似地：</p>
$$
H(X_2, \ldots, X_n) = \sum_{i=2}^n H(X_i|X_{i-1},\ldots,X_2)
$$<p>代入得：</p>
$$
I(X_1; X_2, \ldots, X_n) = H(X_1) - \left[\left(H(X_1) + \sum_{i=2}^n H(X_i|X_{i-1})\right) - \left(H(X_2) + \sum_{i=3}^n H(X_i|X_{i-1})\right)\right]
$$$$
= H(X_1) - H(X_1) - H(X_2|X_1) + H(X_2)
$$$$
= H(X_2) - H(X_2|X_1)
$$$$
= I(X_1; X_2)
$$<p>因此：</p>
$$
I(X_1; X_2, \ldots, X_n) = I(X_1; X_2)
$$<p><strong>结论</strong>：在马尔科夫链中，$X_1$ 与序列 $(X_2, \ldots, X_n)$ 的互信息等于 $X_1$ 与 $X_2$ 的互信息，这体现了马尔科夫性质。</p>
<hr>
<h2 id="习题-7kl-散度与最大似然估计">习题 7：KL 散度与最大似然估计<a hidden class="anchor" aria-hidden="true" href="#习题-7kl-散度与最大似然估计">#</a></h2>
<p><strong>题目</strong>：（通过 KL 散度理解 MLE）假设 $x_1, \ldots, x_n$ 来自密度为 $p(x)$ 的分布 $P$，试说明如果采用具有密度函数 $q_\theta(x)$ 的分布族 $Q_\theta$ 来计算 MLE，那么 MLE 将试图找到在 KL 散度意义上最接近真实分布 $P$ 的分布 $Q_\theta$。</p>
<p>即证明：</p>
$$
\arg\max_\theta \prod_{i=1}^n q_\theta(x_i) \Leftrightarrow \arg\min_\theta D_{KL}(P \| Q_\theta)
$$<p><strong>证明</strong>：</p>
<p>从最大似然估计出发：</p>
$$
\arg\max_\theta \prod_{i=1}^n q_\theta(x_i) \Leftrightarrow \arg\max_\theta \sum_{i=1}^n \log q_\theta(x_i)
$$$$
\Leftrightarrow \arg\min_\theta -\frac{1}{n}\sum_{i=1}^n \log q_\theta(x_i)
$$<p>当样本量 $n \to \infty$ 时，根据大数定律：</p>
$$
-\frac{1}{n}\sum_{i=1}^n \log q_\theta(x_i) \xrightarrow{P} -\mathbb{E}_P[\log q_\theta(x)]
$$$$
= -\int p(x)\log q_\theta(x)dx
$$<p>这正是<strong>交叉熵</strong> $H(P, Q_\theta)$ 的定义。因此：</p>
$$
\arg\min_\theta -\mathbb{E}_P[\log q_\theta(x)] \Leftrightarrow \arg\min_\theta H(P, Q_\theta)
$$<p>由于真实分布 $P$ 的熵 $H(P)$ 是常数（不依赖于 $\theta$）：</p>
$$
\arg\min_\theta H(P, Q_\theta) \Leftrightarrow \arg\min_\theta [H(P, Q_\theta) - H(P)]
$$<p>而 KL 散度定义为：</p>
$$
D_{KL}(P \| Q_\theta) = \int p(x)\log \frac{p(x)}{q_\theta(x)}dx
$$$$
= \int p(x)\log p(x)dx - \int p(x)\log q_\theta(x)dx
$$$$
= H(P) + H(P, Q_\theta)
$$<p>等价于：</p>
$$
H(P, Q_\theta) - H(P) = -\int p(x)\log q_\theta(x)dx + \int p(x)\log p(x)dx = D_{KL}(P \| Q_\theta)
$$<p>因此：</p>
$$
\arg\max_\theta \prod_{i=1}^n q_\theta(x_i) \Leftrightarrow \arg\min_\theta D_{KL}(P \| Q_\theta)
$$<p><strong>结论</strong>：从优化模型参数的角度来说，最小化负对数似然、交叉熵（多分类问题）和 KL 散度这三种方式是等价的。MLE 实际上是在寻找与真实分布 KL 散度最小的模型分布。</p>
<h1 id="作业六">作业六<a hidden class="anchor" aria-hidden="true" href="#作业六">#</a></h1>
<hr>
<h2 id="习题-1贝叶斯推断求后验分布">习题 1：贝叶斯推断求后验分布<a hidden class="anchor" aria-hidden="true" href="#习题-1贝叶斯推断求后验分布">#</a></h2>
<p><strong>题目</strong>：假设总体 $X \sim N(\mu, \sigma^2)$（$\sigma^2$ 已知），$X_1, X_2, \ldots, X_n$ 为来自总体 $X$ 的样本，由过去的经验和知识，我们可以确定 $\mu$ 的取值比较集中在 $\mu_0$ 附近，离 $\mu_0$ 越远，$\mu$ 取值的可能性越小，于是我们假定 $\mu$ 的先验分布为正态分布</p>
$$
\pi(\mu) = \frac{1}{\sqrt{2\pi\sigma_\mu^2}} \exp\left[-\frac{1}{2\sigma_\mu^2}(\mu - \mu_0)^2\right] \quad (\mu_0, \sigma_\mu \text{ 已知})
$$<p>求 $\mu$ 的后验概率分布。</p>
<p><strong>解</strong>：</p>
<p>根据贝叶斯定理，后验分布正比于似然函数与先验分布的乘积。</p>
<p><strong>似然函数：</strong></p>
<p>给定 $\mu$，样本 $x_1, \ldots, x_n$ 的联合密度函数为：</p>
$$
q(x | \mu) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[-\frac{1}{2\sigma^2}(x_i - \mu)^2\right]= \frac{1}{\sigma^n(2\pi)^{n/2}} \exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2\right]
$$<p><strong>后验密度函数：</strong></p>
$$
h(\mu | x) = \frac{q(x | \mu) \cdot \pi(\mu)}{f_x(x)} \propto q(x | \mu) \cdot \pi(\mu)
$$$$
\propto \exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2\right] \cdot \exp\left[-\frac{1}{2\sigma_\mu^2}(\mu - \mu_0)^2\right]
$$<p>合并指数项：</p>
$$
h(\mu | x) \propto \exp\left[-\frac{1}{2}\left(\frac{\sum_{i=1}^n(x_i - \mu)^2}{\sigma^2} + \frac{(\mu - \mu_0)^2}{\sigma_\mu^2}\right)\right]
$$<p>展开平方项：</p>
$$
\sum_{i=1}^n(x_i - \mu)^2 = \sum_{i=1}^n x_i^2 - 2\mu\sum_{i=1}^n x_i + n\mu^2 = n(\mu - \bar{x})^2 + \text{常数}
$$<p>因此指数项中关于 $\mu$ 的部分为：</p>
$$
-\frac{1}{2}\left[\frac{n}{\sigma^2}(\mu - \bar{x})^2 + \frac{1}{\sigma_\mu^2}(\mu - \mu_0)^2\right]
$$$$
= -\frac{1}{2}\left[\left(\frac{n}{\sigma^2} + \frac{1}{\sigma_\mu^2}\right)\mu^2 - 2\mu\left(\frac{n\bar{x}}{\sigma^2} + \frac{\mu_0}{\sigma_\mu^2}\right) + \text{常数}\right]
$$<p>配方得：</p>
$$
h(\mu | x) \propto \exp\left[-\frac{(\mu - t)^2}{2\eta^2}\right]
$$<p>其中：</p>
$$t = \frac{\frac{n}{\sigma^2}\bar{x} + \frac{1}{\sigma_\mu^2}\mu_0}{\frac{n}{\sigma^2} + \frac{1}{\sigma_\mu^2}}, \quad \eta^2 = \frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_\mu^2}}$$<p>因此，后验分布为：</p>
$$
\mu | x \sim N\left(\frac{\frac{n}{\sigma^2}\bar{x} + \frac{1}{\sigma_\mu^2}\mu_0}{\frac{n}{\sigma^2} + \frac{1}{\sigma_\mu^2}}, \frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_\mu^2}}\right)
$$<p><strong>解释</strong>：后验均值是样本均值和先验均值的加权平均，权重由各自的精度（方差的倒数）决定。</p>
<hr>
<h2 id="习题-2gauss-累积分布函数的对数凹性">习题 2：Gauss 累积分布函数的对数凹性<a hidden class="anchor" aria-hidden="true" href="#习题-2gauss-累积分布函数的对数凹性">#</a></h2>
<p><strong>题目</strong>：证明：Gauss 概率密度函数的累积分布函数</p>
$$
\Phi(x) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^x e^{-u^2/2}du
$$<p>是对数-凹函数，即 $\log(\Phi(x))$ 是凹函数。</p>
<p><strong>证明</strong>：</p>
<p>要证明 $\log(\Phi(x))$ 是凹函数，需要证明其二阶导数非正，即：</p>
$$
\frac{d^2}{dx^2}\log(\Phi(x)) \leq 0
$$<p>等价于证明：</p>
$$
\Phi(x)\Phi''(x) \leq [\Phi'(x)]^2
$$<p><strong>计算导数：</strong></p>
$$
\Phi'(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}
$$$$
\Phi''(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}(-x) = -x\Phi'(x)
$$$$
[\Phi'(x)]^2 = \frac{1}{2\pi}e^{-x^2}
$$<p><strong>情况 1：$x \geq 0$</strong></p>
<p>当 $x \geq 0$ 时，$\Phi''(x) = -x\Phi'(x) \leq 0$，而 $\Phi(x) > 0$，$[\Phi'(x)]^2 \geq 0$，因此：</p>
$$
\Phi(x)\Phi''(x) \leq 0 \leq [\Phi'(x)]^2
$$<p><strong>情况 2：$x < 0$</strong></p>
<p>当 $x < 0$ 时，需要证明：</p>
$$
\Phi(x) \cdot (-x) \leq \frac{1}{\sqrt{2\pi}}e^{-x^2/2}
$$<p>即：</p>
$$
\int_{-\infty}^x e^{-u^2/2}du \leq \frac{e^{-x^2/2}}{-x}
$$<p>由于 $\frac{u^2}{2}$ 是凸函数，对任意 $u < x < 0$，有：</p>
$$
\frac{u^2}{2} \geq \frac{x^2}{2} + (u-x)x = xu - \frac{x^2}{2}
$$<p>因此：</p>
$$
e^{-u^2/2} \leq e^{-xu + x^2/2}
$$<p>积分得：</p>
$$
\int_{-\infty}^x e^{-u^2/2}du \leq \int_{-\infty}^x e^{x^2/2-xu}du
$$$$
= e^{x^2/2} \int_{-\infty}^x e^{-xu}du = e^{x^2/2} \cdot \frac{e^{-xu}}{-x}\bigg|_{u=-\infty}^x
$$$$
= e^{x^2/2} \cdot \frac{e^{-x^2}}{-x} = \frac{e^{-x^2/2}}{-x}
$$<p>因此 $\Phi(x)\Phi''(x) \leq [\Phi'(x)]^2$ 对 $x < 0$ 也成立。</p>
<p>综上所述，$\Phi(x)$ 是对数凹函数。</p>
<hr>
<h2 id="习题-3共轭函数的计算">习题 3：共轭函数的计算<a hidden class="anchor" aria-hidden="true" href="#习题-3共轭函数的计算">#</a></h2>
<p><strong>题目</strong>：计算函数 $f(x)$ 的共轭函数，以及共轭函数的定义域。</p>
<p><strong>(1)</strong> $f(x) = -\log x$</p>
<p><strong>(2)</strong> $f(x) = e^x$</p>
<p><strong>解</strong>：</p>
<p>共轭函数定义为：</p>
$$
f^*(y) = \sup_x (xy - f(x))
$$<h3 id="1">(1) $f(x) = -\log x$<a hidden class="anchor" aria-hidden="true" href="#1">#</a></h3>
<p>定义域 $\text{dom}(f) = \{x|x > 0\}$。</p>
<p>对于给定的 $y$，求 $g(x) = xy + \log x$ 的上确界。</p>
<p>求导：$g'(x) = y + \frac{1}{x}$</p>
<ul>
<li>当 $y \geq 0$ 时，$g'(x) > 0$ 恒成立，函数单调递增，无上界</li>
<li>当 $y < 0$ 时，令 $g'(x) = 0$ 得 $x = -\frac{1}{y}$</li>
</ul>
<p>此时：</p>
$$
g\left(-\frac{1}{y}\right) = -\frac{1}{y} \cdot y + \log\left(-\frac{1}{y}\right) = -1 - \log(-y)
$$<p>因此：</p>
$$
f^*(y) = \begin{cases} -\log(-y) - 1, & y < 0 \\ +\infty, & y \geq 0 \end{cases}
$$<p>定义域：$\text{dom}(f^*) = \{y | y < 0\}$</p>
<h3 id="2">(2) $f(x) = e^x$<a hidden class="anchor" aria-hidden="true" href="#2">#</a></h3>
<p>定义域 $\text{dom}(f) = \mathbb{R}$。</p>
<p>对于给定的 $y$，求 $g(x) = xy - e^x$ 的上确界。</p>
<p>求导：$g'(x) = y - e^x$</p>
<ul>
<li>当 $y \leq 0$ 时，$g'(x) < 0$ 恒成立，函数单调递减，无上界（趋于 $-\infty$ 时）</li>
<li>当 $y > 0$ 时，令 $g'(x) = 0$ 得 $x = \log y$</li>
</ul>
<p>此时：</p>
$$
g(\log y) = y\log y - e^{\log y} = y\log y - y
$$<ul>
<li>当 $y = 0$ 时：$f^*(0) = \sup_x(-e^x) = 0$（当 $x \to -\infty$ 时）</li>
</ul>
<p>因此：</p>
$$
f^*(y) = \begin{cases} y\log y - y, & y > 0 \\ 0, & y = 0 \\ +\infty, & y < 0 \end{cases}
$$<p>定义域：$\text{dom}(f^*) = \{y | y \geq 0\}$（规定 $0\log 0 = 0$）</p>
<hr>
<h2 id="习题-4kkt-条件的应用">习题 4：KKT 条件的应用<a hidden class="anchor" aria-hidden="true" href="#习题-4kkt-条件的应用">#</a></h2>
<p><strong>题目</strong>：写出下述非线性规划的 KKT 条件并求解</p>
<p><strong>(1)</strong> $\max f(x) = (x - 3)^2$ subject to $1 \leq x \leq 5$</p>
<p><strong>(2)</strong> $\min f(x) = (x - 3)^2$ subject to $1 \leq x \leq 5$</p>
<p><strong>解</strong>：</p>
<h3 id="1-最大化问题">(1) 最大化问题<a hidden class="anchor" aria-hidden="true" href="#1-最大化问题">#</a></h3>
<p>将最大化问题转化为最小化问题：</p>
$$
\begin{cases} 
\text{minimize} \quad -f(x) = -(x-3)^2 \\ 
g_1(x) = 1 - x \leq 0 \\ 
g_2(x) = x - 5 \leq 0 
\end{cases}
$$<p><strong>梯度：</strong></p>
$$
\nabla_x[-f(x)] = -2(x-3), \quad \nabla_x g_1(x) = -1, \quad \nabla_x g_2(x) = 1
$$<p><strong>KKT 条件：</strong></p>
$$
\begin{cases} 
-2(x^* - 3) - v_1^* + v_2^* = 0 & \text{(稳定性)} \\ 
v_1^*(1 - x^*) = 0 & \text{(互补松弛性)} \\ 
v_2^*(x^* - 5) = 0 & \text{(互补松弛性)} \\ 
v_1^* \geq 0, \quad v_2^* \geq 0 & \text{(对偶可行性)} \\ 
1 \leq x^* \leq 5 & \text{(原始可行性)} 
\end{cases}
$$<p><strong>情况分析：</strong></p>
<p><strong>情况 i：</strong> $v_1^* = 0, v_2^* = 0$</p>
<p>由稳定性条件：$-2(x^* - 3) = 0$，得 $x^* = 3$</p>
<p>此时 $f(x^*) = 0$</p>
<p><strong>情况 ii：</strong> $v_1^* > 0, v_2^* = 0$</p>
<p>由互补松弛性：$x^* = 1$</p>
<p>由稳定性条件：$-2(1-3) - v_1^* = 0$，得 $v_1^* = 4 > 0$ ✓</p>
<p>此时 $f(x^*) = 4$</p>
<p><strong>情况 iii：</strong> $v_1^* = 0, v_2^* > 0$</p>
<p>由互补松弛性：$x^* = 5$</p>
<p>由稳定性条件：$-2(5-3) + v_2^* = 0$，得 $v_2^* = 4 > 0$ ✓</p>
<p>此时 $f(x^*) = 4$</p>
<p><strong>情况 iv：</strong> $v_1^* > 0, v_2^* > 0$</p>
<p>由互补松弛性：$x^* = 1$ 且 $x^* = 5$，矛盾</p>
<p><strong>结论：</strong></p>
$$
x^* = 1 \text{ 或 } x^* = 5, \quad \max f(x) = 4
$$<h3 id="2-最小化问题">(2) 最小化问题<a hidden class="anchor" aria-hidden="true" href="#2-最小化问题">#</a></h3>
$$
\begin{cases} 
\text{minimize} \quad f(x) = (x-3)^2 \\ 
g_1(x) = 1 - x \leq 0 \\ 
g_2(x) = x - 5 \leq 0 
\end{cases}
$$<p><strong>梯度：</strong></p>
$$
\nabla_x f(x) = 2(x-3)
$$<p><strong>KKT 条件：</strong></p>
$$
\begin{cases} 
2(x^* - 3) - v_1^* + v_2^* = 0 \\ 
v_1^*(1 - x^*) = 0 \\ 
v_2^*(x^* - 5) = 0 \\ 
v_1^* \geq 0, \quad v_2^* \geq 0 \\ 
1 \leq x^* \leq 5 
\end{cases}
$$<p><strong>情况分析：</strong></p>
<p><strong>情况 i：</strong> $v_1^* = 0, v_2^* = 0$</p>
<p>由稳定性条件：$2(x^* - 3) = 0$，得 $x^* = 3$</p>
<p>此时 $f(x^*) = 0$ ✓</p>
<p><strong>情况 ii：</strong> $v_1^* > 0, v_2^* = 0$</p>
<p>$x^* = 1$，$2(1-3) - v_1^* = 0$，得 $v_1^* = -4 < 0$ ✗</p>
<p><strong>情况 iii：</strong> $v_1^* = 0, v_2^* > 0$</p>
<p>$x^* = 5$，$2(5-3) + v_2^* = 0$，得 $v_2^* = -4 < 0$ ✗</p>
<p><strong>结论：</strong></p>
$$
x^* = 3, \quad \min f(x) = 0
$$<hr>
<h2 id="习题-5lagrange-乘子法证明矩阵-2-范数">习题 5：Lagrange 乘子法证明矩阵 2-范数<a hidden class="anchor" aria-hidden="true" href="#习题-5lagrange-乘子法证明矩阵-2-范数">#</a></h2>
<p><strong>题目</strong>：用 Lagrange 乘子法证明：矩阵 $A \in \mathbb{R}^{m\times n}$ 的 2-范数</p>
$$
\|A\|_2 = \max_{\|x\|_2 = 1, x \in \mathbb{R}^n} \|Ax\|_2
$$<p>的平方是 $A^TA$ 的最大特征值。</p>
<p><strong>证明</strong>：</p>
<p>优化问题为：</p>
$$
\text{maximize} \quad f(x) = \|Ax\|_2^2 = x^TA^TAx \quad \text{subject to} \quad x^Tx = 1
$$<p><strong>Lagrange 函数：</strong></p>
$$
L(x, \lambda) = x^TA^TAx - \lambda(x^Tx - 1)
$$<p><strong>求梯度并令其为零：</strong></p>
$$
\frac{\partial L}{\partial x} = 2A^TAx - 2\lambda x = 0
$$<p>因此：</p>
$$
A^TAx = \lambda x
$$<p>这说明在极值点 $x^*$ 处，$x^*$ 是 $A^TA$ 的特征向量，$\lambda$ 是对应的特征值。</p>
<p><strong>目标函数值：</strong></p>
$$
f(x^*) = (x^*)^TA^TAx^* = (x^*)^T\lambda x^* = \lambda(x^*)^Tx^* = \lambda
$$<p>由于我们求的是最大值，因此：</p>
$$
\|A\|_2^2 = \max_{\|x\|_2=1} x^TA^TAx = \lambda_{\max}(A^TA)
$$<p>即：</p>
$$
\|A\|_2 = \sqrt{\lambda_{\max}(A^TA)}
$$<p>$\square$</p>
<hr>
<h2 id="习题-6欠定方程的最小二范数解">习题 6：欠定方程的最小二范数解<a hidden class="anchor" aria-hidden="true" href="#习题-6欠定方程的最小二范数解">#</a></h2>
<p><strong>题目</strong>：用 Lagrange 乘子法求欠定方程 $Ax = b$ 的最小二范数解，其中 $A \in \mathbb{R}^{m\times n}$，$m \leq n$，$\text{rank}(A) = m$</p>
<p><strong>解</strong>：</p>
<p>优化问题为：</p>
$$
\text{minimize} \quad f(x) = \frac{1}{2}\|x\|_2^2 = \frac{1}{2}x^Tx \quad \text{subject to} \quad Ax = b
$$<p><strong>Lagrange 函数：</strong></p>
$$
L(x, \lambda) = \frac{1}{2}x^Tx - \lambda^T(Ax - b)
$$<p><strong>求梯度并令其为零：</strong></p>
$$
\frac{\partial L}{\partial x} = x - A^T\lambda = 0
$$<p>因此：</p>
$$
x = A^T\lambda
$$<p><strong>代入约束条件：</strong></p>
$$
Ax = b \Rightarrow A(A^T\lambda) = b
$$$$
AA^T\lambda = b
$$<p>由于 $\text{rank}(A) = m$，矩阵 $AA^T \in \mathbb{R}^{m \times m}$ 是满秩的，因此可逆：</p>
$$
\lambda = (AA^T)^{-1}b
$$<p><strong>最小二范数解：</strong></p>
$$
x^* = A^T(AA^T)^{-1}b
$$<p><strong>验证：</strong></p>
<ul>
<li>$Ax^* = AA^T(AA^T)^{-1}b = b$ ✓（满足约束）</li>
<li>可以证明这是所有满足 $Ax = b$ 的解中范数最小的</li>
</ul>
<hr>
<h2 id="习题-7最速下降法">习题 7：最速下降法<a hidden class="anchor" aria-hidden="true" href="#习题-7最速下降法">#</a></h2>
<p><strong>题目</strong>：用最速下降法和精确线搜索计算</p>
$$
\min f(x) = x_1^2 + x_2^2 + x_3^2
$$<p>初始点 $x^{(0)} = (2, 2, 1)^T$。当 $|f(x^{(n+1)}) - f(x^{(n)})| < 0.001$ 时迭代终止。</p>
<p><strong>解</strong>：</p>
<p>目标函数 $f(x) = x^Tx$，梯度 $\nabla f(x) = 2x$。</p>
<p><strong>精确线搜索：</strong></p>
<p>最速下降方向为 $d^{(k)} = -\nabla f(x^{(k)}) = -2x^{(k)}$</p>
<p>在该方向上最小化 $f(x^{(k)} + \lambda d^{(k)})$：</p>
$$
f(x^{(k)} + \lambda d^{(k)}) = (x^{(k)} - 2\lambda x^{(k)})^T(x^{(k)} - 2\lambda x^{(k)})
$$$$
= (1 - 2\lambda)^2 (x^{(k)})^Tx^{(k)}
$$<p>对 $\lambda$ 求导并令其为零：</p>
$$
\frac{d}{d\lambda}[(1-2\lambda)^2 (x^{(k)})^Tx^{(k)}] = 2(1-2\lambda)(-2)(x^{(k)})^Tx^{(k)} = 0
$$<p>得 $\lambda^* = \frac{1}{2}$</p>
<p><strong>迭代过程：</strong></p>
$$
x^{(1)} = x^{(0)} + \frac{1}{2}(-2x^{(0)}) = x^{(0)} - x^{(0)} = 0
$$$$
f(x^{(1)}) = 0
$$$$
x^{(2)} = x^{(1)} - x^{(1)} = 0
$$$$
|f(x^{(1)}) - f(x^{(0)})| = |0 - 9| = 9 > 0.001
$$$$
|f(x^{(2)}) - f(x^{(1)})| = |0 - 0| = 0 < 0.001
$$<p>迭代终止。</p>
<p><strong>结论：</strong></p>
$$
x^* = (0, 0, 0)^T, \quad f_{\min} = 0
$$<p>算法一步即收敛到最优解，这是因为目标函数是简单的二次型，且 Hessian 矩阵为单位矩阵的倍数。</p>
<hr>
<h2 id="习题-8dfp-法求二次函数极小点">习题 8：DFP 法求二次函数极小点<a hidden class="anchor" aria-hidden="true" href="#习题-8dfp-法求二次函数极小点">#</a></h2>
<p><strong>题目</strong>：试用 DFP 法计算下述二次函数的极小点</p>
$$
\min f(x) = 3x_1^2 + x_2^2 - 2x_1x_2 - 4x_1
$$<p><strong>解</strong>：</p>
<p>选择初始点 $x^{(0)} = (-2, 4)^T$，初始 Hessian 逆近似 $H^{(0)} = I$。</p>
<p><strong>梯度：</strong></p>
$$
\nabla f(x) = \begin{pmatrix} 6x_1 - 2x_2 - 4 \\ 2x_2 - 2x_1 \end{pmatrix}
$$<h3 id="第一次迭代">第一次迭代<a hidden class="anchor" aria-hidden="true" href="#第一次迭代">#</a></h3>
$$
\nabla f(x^{(0)}) = \begin{pmatrix} 6(-2) - 2(4) - 4 \\ 2(4) - 2(-2) \end{pmatrix} = \begin{pmatrix} -24 \\ 12 \end{pmatrix}
$$<p><strong>搜索方向：</strong></p>
$$
p^{(0)} = -H^{(0)}\nabla f(x^{(0)}) = -I \begin{pmatrix} -24 \\ 12 \end{pmatrix} = \begin{pmatrix} 24 \\ -12 \end{pmatrix}
$$<p><strong>精确线搜索：</strong> 求 $\lambda_0 = \arg\min_\lambda f(x^{(0)} + \lambda p^{(0)})$</p>
$$
f(x^{(0)} + \lambda p^{(0)}) = 3(-2+24\lambda)^2 + (4-12\lambda)^2 - 2(-2+24\lambda)(4-12\lambda) - 4(-2+24\lambda)
$$<p>对 $\lambda$ 求导并令其为零，得：</p>
$$
\lambda_0 = \frac{5}{34}
$$<p><strong>更新：</strong></p>
$$
x^{(1)} = x^{(0)} + \lambda_0 p^{(0)} = \begin{pmatrix} -2 \\ 4 \end{pmatrix} + \frac{5}{34}\begin{pmatrix} 24 \\ -12 \end{pmatrix} = \begin{pmatrix} \frac{26}{17} \\ \frac{38}{17} \end{pmatrix}
$$$$
\nabla f(x^{(1)}) = \begin{pmatrix} \frac{12}{17} \\ \frac{24}{17} \end{pmatrix}
$$<p><strong>DFP 更新公式：</strong></p>
$$
\Delta x^{(0)} = x^{(1)} - x^{(0)} = \begin{pmatrix} \frac{60}{17} \\ -\frac{30}{17} \end{pmatrix}
$$$$
\Delta g^{(0)} = \nabla f(x^{(1)}) - \nabla f(x^{(0)}) = \begin{pmatrix} \frac{420}{17} \\ -\frac{180}{17} \end{pmatrix}
$$$$
H^{(1)} = H^{(0)} + \frac{\Delta x^{(0)}(\Delta x^{(0)})^T}{(\Delta g^{(0)})^T\Delta x^{(0)}} - \frac{H^{(0)}\Delta g^{(0)}(\Delta g^{(0)})^TH^{(0)}}{(\Delta g^{(0)})^TH^{(0)}\Delta g^{(0)}}
$$<p>计算后得：</p>
$$
H^{(1)} = I + \frac{1}{1800}\begin{pmatrix} 3600 & -1800 \\ -1800 & 900 \end{pmatrix} - \frac{1}{226800}\begin{pmatrix} 176400 & -75600 \\ -75600 & 32400 \end{pmatrix}
$$<h3 id="第二次迭代">第二次迭代<a hidden class="anchor" aria-hidden="true" href="#第二次迭代">#</a></h3>
$$
p^{(1)} = -H^{(1)}\nabla f(x^{(1)}) = -\begin{pmatrix} \frac{18}{29} \\ \frac{42}{29} \end{pmatrix}
$$<p>精确线搜索得 $\lambda_1 = \frac{29}{34}$</p>
$$
x^{(2)} = x^{(1)} + \lambda_1 p^{(1)} = \begin{pmatrix} 1 \\ 1 \end{pmatrix}
$$$$
\nabla f(x^{(2)}) = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
$$<p><strong>结论：</strong></p>
$$
x^* = (1, 1)^T \text{ 为极小点}
$$<p>DFP 法对于 $n$ 维二次函数，最多需要 $n$ 步即可收敛到精确解（具有二次终止性）。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></li>
      <li><a href="http://localhost:1313/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/">矩阵分解</a></li>
      <li><a href="http://localhost:1313/tags/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">数值分析</a></li>
      <li><a href="http://localhost:1313/tags/%E6%95%B0%E5%AD%A6%E8%AF%81%E6%98%8E/">数学证明</a></li>
    </ul>
  </footer><div id="tw-comment"></div>
<script>
    
    const getStoredTheme = () => localStorage.getItem("pref-theme") === "light" ? "nord_light" : "dark_dimmed";
    const setGiscusTheme = () => {
        const sendMessage = (message) => {
            const iframe = document.querySelector('iframe.giscus-frame');
            if (iframe) {
                iframe.contentWindow.postMessage({giscus: message}, 'https://giscus.app');
            }
        }
        sendMessage({setConfig: {theme: getStoredTheme()}})
    }

    document.addEventListener("DOMContentLoaded", () => {
        const giscusAttributes = {
            "src": "https://giscus.app/client.js",
            "data-repo": "minjieblog\/minjieblog.github.io",
            "data-repo-id": "R_kgDOQjMm6A",
            "data-category": "Announcements",
            "data-category-id": "DIC_kwDOQjMm6M4Czb4B",
            "data-mapping": "pathname",
            "data-strict": "0",
            "data-reactions-enabled": "1",
            "data-emit-metadata": "0",
            "data-input-position": "bottom",
            "data-theme": getStoredTheme(),
            "data-lang": "zh-CN",
            "data-loading": "lazy",
            "crossorigin": "anonymous",
        };

        
        const giscusScript = document.createElement("script");
        Object.entries(giscusAttributes).forEach(
                ([key, value]) => giscusScript.setAttribute(key, value));
        document.querySelector("#tw-comment").appendChild(giscusScript);

        
        const themeSwitcher = document.querySelector("#theme-toggle");
        if (themeSwitcher) {
            themeSwitcher.addEventListener("click", setGiscusTheme);
        }
        const themeFloatSwitcher = document.querySelector("#theme-toggle-float");
        if (themeFloatSwitcher) {
            themeFloatSwitcher.addEventListener("click", setGiscusTheme);
        }
    });
</script>
</article>
    </main>
    
<footer class="footer">
        <span><a href="https://minjieblog.github.io/">©2025 Minjie&rsquo;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
