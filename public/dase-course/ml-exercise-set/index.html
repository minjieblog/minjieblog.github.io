<!DOCTYPE html>
<html lang="zh" dir="auto" data-theme="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>机器学习习题集 | Minjie&#39;s Blog</title>
<meta name="keywords" content="机器学习, 数学推导, 算法">
<meta name="description" content="这是胡老师出的考题集，涵盖机器学习课程的28道经典问题详解，包括：
基础理论（梯度下降、交叉熵损失、最大似然估计）、
判别模型（Logistic回归、GDA、SVM对偶优化）、
深度学习（Transformer架构、RoPE、KV Cache、门控注意力）、
强化学习（多臂老虎机、MDP Bellman方程、最优策略）、
大模型优化（XGBoost二阶泰勒展开、Roofline模型、AI Agent特性）。
每道题配有完整数学证明和算法原理解析。 参考资料：[机器学习](https://dasellmg.yuque.com/org-wiki-dasellmg-vsl5wg/ml2025)
">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/dase-course/ml-exercise-set/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/code.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/code.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/code.png">
<link rel="apple-touch-icon" href="http://localhost:1313/code.png">
<link rel="mask-icon" href="http://localhost:1313/code.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="http://localhost:1313/dase-course/ml-exercise-set/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel="stylesheet">
<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Minjie&#39;s Blog (Alt + H)">Minjie&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="Minjie&#39;s Blog">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="关于我">
                    <span>关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      机器学习习题集
    </h1>
    <div class="post-description">
      这是胡老师出的考题集，涵盖机器学习课程的28道经典问题详解，包括：
基础理论（梯度下降、交叉熵损失、最大似然估计）、
判别模型（Logistic回归、GDA、SVM对偶优化）、
深度学习（Transformer架构、RoPE、KV Cache、门控注意力）、
强化学习（多臂老虎机、MDP Bellman方程、最优策略）、
大模型优化（XGBoost二阶泰勒展开、Roofline模型、AI Agent特性）。
每道题配有完整数学证明和算法原理解析。 参考资料：[机器学习](https://dasellmg.yuque.com/org-wiki-dasellmg-vsl5wg/ml2025)

    </div>
    <div class="post-meta"><span title='2025-12-13 20:26:19 +0800 CST'>2025年12月13日</span>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e7%ac%ac%e4%b8%80%e9%a2%98%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d" aria-label="第一题：线性回归梯度下降">第一题：线性回归梯度下降</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e9%a2%98%e4%ba%a4%e5%8f%89%e7%86%b5%e6%8d%9f%e5%a4%b1%e6%a2%af%e5%ba%a6" aria-label="第二题：交叉熵损失梯度">第二题：交叉熵损失梯度</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%b8%89%e9%a2%98%e9%ab%98%e6%96%af%e5%81%87%e8%ae%be%e4%b8%8b%e7%9a%84%e6%9c%80%e5%a4%a7%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1" aria-label="第三题：高斯假设下的最大似然估计">第三题：高斯假设下的最大似然估计</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%9b%9b%e9%a2%98logistic%e5%9b%9e%e5%bd%92%e7%9a%84nll%e6%8d%9f%e5%a4%b1" aria-label="第四题：Logistic回归的NLL损失">第四题：Logistic回归的NLL损失</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%94%e9%a2%98poisson%e5%88%86%e5%b8%83%e7%9a%84%e6%8c%87%e6%95%b0%e6%97%8f%e5%bd%a2%e5%bc%8f" aria-label="第五题：Poisson分布的指数族形式">第五题：Poisson分布的指数族形式</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%85%ad%e9%a2%98shapley%e5%80%bc%e8%ae%a1%e7%ae%97" aria-label="第六题：Shapley值计算">第六题：Shapley值计算</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%b8%83%e9%a2%98%e5%8d%8f%e6%96%b9%e5%b7%ae%e7%9f%a9%e9%98%b5%e6%80%a7%e8%b4%a8" aria-label="第七题：协方差矩阵性质">第七题：协方差矩阵性质</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%85%ab%e9%a2%98%e9%ab%98%e6%96%af%e5%88%a4%e5%88%ab%e5%88%86%e6%9e%90%e7%9a%84mle" aria-label="第八题：高斯判别分析的MLE">第八题：高斯判别分析的MLE</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%b9%9d%e9%a2%98gda%e5%8f%af%e8%bd%ac%e5%8c%96%e4%b8%balogistic%e5%9b%9e%e5%bd%92" aria-label="第九题：GDA可转化为Logistic回归">第九题：GDA可转化为Logistic回归</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e9%a2%98kernel-method%e5%88%86%e6%9e%90" aria-label="第十题：Kernel Method分析">第十题：Kernel Method分析</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%b8%80%e9%a2%98%e8%b6%85%e5%b9%b3%e9%9d%a2%e7%9a%84%e5%87%bd%e6%95%b0%e9%97%b4%e9%9a%94%e5%92%8c%e5%87%a0%e4%bd%95%e9%97%b4%e9%9a%94" aria-label="第十一题：超平面的函数间隔和几何间隔">第十一题：超平面的函数间隔和几何间隔</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%ba%8c%e9%a2%98svm%e7%9a%84lagrange%e5%87%bd%e6%95%b0%e5%92%8c%e5%af%b9%e5%81%b6%e5%bd%a2%e5%bc%8f" aria-label="第十二题：SVM的Lagrange函数和对偶形式">第十二题：SVM的Lagrange函数和对偶形式</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%b8%89%e9%a2%98%e7%ba%bf%e6%80%a7%e4%b8%8d%e5%8f%af%e5%88%86%e7%9a%84svm%e4%b8%8el1%e6%ad%a3%e5%88%99" aria-label="第十三题：线性不可分的SVM与L1正则">第十三题：线性不可分的SVM与L1正则</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e5%9b%9b%e9%a2%98svm%e6%9c%80%e4%bc%98%e5%8c%96%e9%97%ae%e9%a2%98%e5%88%86%e6%9e%90" aria-label="第十四题：SVM最优化问题分析">第十四题：SVM最优化问题分析</a></li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%ba%94%e9%a2%98%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e6%af%94%e8%ae%a1%e7%ae%97" aria-label="第十五题：信息增益比计算">第十五题：信息增益比计算</a><ul>
                        
                <li>
                    <a href="#%e7%89%b9%e5%be%811%e5%b9%b4%e9%be%84" aria-label="特征1：年龄">特征1：年龄</a></li>
                <li>
                    <a href="#%e7%89%b9%e5%be%812%e6%9c%89%e5%b7%a5%e4%bd%9c" aria-label="特征2：有工作">特征2：有工作</a></li>
                <li>
                    <a href="#%e7%89%b9%e5%be%813%e6%9c%89%e8%87%aa%e5%b7%b1%e7%9a%84%e6%88%bf%e5%ad%90" aria-label="特征3：有自己的房子">特征3：有自己的房子</a></li>
                <li>
                    <a href="#%e7%89%b9%e5%be%814%e4%bf%a1%e8%b4%b7%e6%83%85%e5%86%b5" aria-label="特征4：信贷情况">特征4：信贷情况</a></li>
                <li>
                    <a href="#%e6%80%bb%e7%bb%93%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e6%af%94%e6%8e%92%e5%ba%8f" aria-label="总结（信息增益比排序）">总结（信息增益比排序）</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e5%85%ad%e9%a2%98xgboost%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e4%ba%8c%e9%98%b6%e6%b3%b0%e5%8b%92%e5%b1%95%e5%bc%80" aria-label="第十六题：XGBoost损失函数二阶泰勒展开">第十六题：XGBoost损失函数二阶泰勒展开</a><ul>
                        
                <li>
                    <a href="#%e4%ba%8c%e9%98%b6%e6%b3%b0%e5%8b%92%e5%b1%95%e5%bc%80" aria-label="二阶泰勒展开">二阶泰勒展开</a></li>
                <li>
                    <a href="#%e6%8e%a8%e5%af%bc%e5%8f%b6%e5%ad%90%e6%9d%83%e9%87%8d" aria-label="推导叶子权重 $w_j^*$">推导叶子权重 $w_j^*$</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%b8%83%e9%a2%98-kv-cache-%e8%ae%a1%e7%ae%97" aria-label="第十七题 KV Cache 计算">第十七题 KV Cache 计算</a><ul>
                        
                <li>
                    <a href="#1-kv-cache-%e6%96%b0%e5%a2%9e%e5%ad%98%e5%82%a8%e8%ae%a1%e7%ae%97%e5%85%ac%e5%bc%8f" aria-label="1. KV Cache 新增存储计算公式">1. KV Cache 新增存储计算公式</a></li>
                <li>
                    <a href="#2-%e5%ba%8f%e5%88%97%e9%95%bf%e5%ba%a6-n1024-%e6%97%b6%e7%9a%84%e6%80%bb-kv-cache" aria-label="2. 序列长度 N=1024 时的总 KV Cache">2. 序列长度 N=1024 时的总 KV Cache</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e5%85%ab%e9%a2%98-rope-%e6%97%8b%e8%bd%ac%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81" aria-label="第十八题 RoPE 旋转位置编码">第十八题 RoPE 旋转位置编码</a><ul>
                        
                <li>
                    <a href="#1-%e8%af%81%e6%98%8e%e7%82%b9%e7%a7%af%e4%bb%85%e4%b8%8e%e7%9b%b8%e5%af%b9%e4%bd%8d%e7%bd%ae%e7%9b%b8%e5%85%b3" aria-label="1. 证明点积仅与相对位置相关">1. 证明点积仅与相对位置相关</a></li>
                <li>
                    <a href="#2-rope-%e5%af%b9%e5%93%aa%e4%ba%9b%e5%90%91%e9%87%8f%e6%b3%a8%e5%85%a5%e4%bd%8d%e7%bd%ae%e4%bf%a1%e6%81%af" aria-label="2. RoPE 对哪些向量注入位置信息">2. RoPE 对哪些向量注入位置信息</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e5%8d%81%e4%b9%9d%e9%a2%98-transformer-block-%e7%9a%84-post-norm-%e5%92%8c-pre-norm" aria-label="第十九题 Transformer Block 的 Post-norm 和 Pre-norm">第十九题 Transformer Block 的 Post-norm 和 Pre-norm</a><ul>
                        
                <li>
                    <a href="#1-pre-norm-%e8%ae%a1%e7%ae%97%e5%85%ac%e5%bc%8f" aria-label="1. Pre-norm 计算公式">1. Pre-norm 计算公式</a></li>
                <li>
                    <a href="#2-%e6%a2%af%e5%ba%a6%e5%88%86%e6%9e%90" aria-label="2. 梯度分析">2. 梯度分析</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e9%a2%98-gated-attention-%e7%9a%84-output-%e8%ae%a1%e7%ae%97" aria-label="第二十题 Gated Attention 的 Output 计算">第二十题 Gated Attention 的 Output 计算</a></li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e4%b8%80%e9%a2%98-gpt-oss-20b-%e6%9e%b6%e6%9e%84%e5%88%86%e6%9e%90" aria-label="第二十一题 GPT-OSS 20B 架构分析">第二十一题 GPT-OSS 20B 架构分析</a><ul>
                        
                <li>
                    <a href="#1-roperotary-position-embedding" aria-label="1. RoPE（Rotary Position Embedding）">1. RoPE（Rotary Position Embedding）</a></li>
                <li>
                    <a href="#2-rmsnormroot-mean-square-normalization" aria-label="2. RMSNorm（Root Mean Square Normalization）">2. RMSNorm（Root Mean Square Normalization）</a></li>
                <li>
                    <a href="#3-gqagrouped-query-attention" aria-label="3. GQA（Grouped Query Attention）">3. GQA（Grouped Query Attention）</a></li>
                <li>
                    <a href="#4-moemixture-of-experts" aria-label="4. MoE（Mixture of Experts）">4. MoE（Mixture of Experts）</a></li>
                <li>
                    <a href="#5-swigluswish-gated-linear-unit" aria-label="5. SwiGLU（Swish-Gated Linear Unit）">5. SwiGLU（Swish-Gated Linear Unit）</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e4%ba%8c%e9%a2%98-roofline-model-%e5%88%86%e6%9e%90" aria-label="第二十二题 Roofline Model 分析">第二十二题 Roofline Model 分析</a><ul>
                        
                <li>
                    <a href="#%e5%88%86%e6%9e%90" aria-label="分析">分析</a></li>
                <li>
                    <a href="#1-repeat16-%e6%97%b6" aria-label="1. repeat=16 时">1. repeat=16 时</a></li>
                <li>
                    <a href="#2-repeat64-%e6%97%b6" aria-label="2. repeat=64 时">2. repeat=64 时</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e4%b8%89%e9%a2%98-operation-intensity-%e8%ae%a1%e7%ae%97" aria-label="第二十三题 Operation Intensity 计算">第二十三题 Operation Intensity 计算</a><ul>
                        
                <li>
                    <a href="#layernorm" aria-label="LayerNorm">LayerNorm</a></li>
                <li>
                    <a href="#rmsnorm" aria-label="RMSNorm">RMSNorm</a></li>
                <li>
                    <a href="#%e5%af%b9%e6%af%94" aria-label="对比">对比</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e5%9b%9b%e9%a2%98-a100-operation-intensity-%e5%88%86%e6%9e%90" aria-label="第二十四题 A100 Operation Intensity 分析">第二十四题 A100 Operation Intensity 分析</a><ul>
                        
                <li>
                    <a href="#compute-bounded-%e4%b8%b4%e7%95%8c%e7%82%b9" aria-label="Compute-bounded 临界点">Compute-bounded 临界点</a></li>
                <li>
                    <a href="#fp32" aria-label="FP32">FP32</a></li>
                <li>
                    <a href="#bf16-tensorcore" aria-label="BF16 TensorCore">BF16 TensorCore</a></li>
                <li>
                    <a href="#%e7%bb%93%e8%ae%ba" aria-label="结论">结论</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e4%ba%94%e9%a2%98-%ce%b5-greedy-%e5%a4%9a%e8%87%82%e8%80%81%e8%99%8e%e6%9c%ba%e9%97%ae%e9%a2%98" aria-label="第二十五题 ε-greedy 多臂老虎机问题">第二十五题 ε-greedy 多臂老虎机问题</a><ul>
                        
                <li>
                    <a href="#1-%e5%90%8e%e6%9c%9f%e8%a1%a8%e7%8e%b0" aria-label="1. 后期表现">1. 后期表现</a></li>
                <li>
                    <a href="#2-%e6%9c%9f%e6%9c%9b%e5%88%86%e6%9e%90" aria-label="2. 期望分析">2. 期望分析</a></li>
                <li>
                    <a href="#%e6%80%bb%e7%bb%93" aria-label="总结">总结</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e5%85%ad%e9%a2%98-mdp-bellman-%e6%96%b9%e7%a8%8b" aria-label="第二十六题 MDP Bellman 方程">第二十六题 MDP Bellman 方程</a><ul>
                        
                <li>
                    <a href="#%e5%9d%90%e6%a0%87%e7%b3%bb%e7%bb%9f" aria-label="坐标系统">坐标系统</a></li>
                <li>
                    <a href="#2-5---value--88" aria-label="(2, 5) - value = 8.8">(2, 5) - value = 8.8</a></li>
                <li>
                    <a href="#3-3---value--07" aria-label="(3, 3) - value = 0.7">(3, 3) - value = 0.7</a></li>
                <li>
                    <a href="#4-5---value--53" aria-label="(4, 5) - value = 5.3">(4, 5) - value = 5.3</a></li>
                <li>
                    <a href="#5-1---value---20" aria-label="(5, 1) - value = -2.0">(5, 1) - value = -2.0</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e4%b8%83%e9%a2%98-mdp-%e6%9c%80%e4%bc%98%e7%ad%96%e7%95%a5" aria-label="第二十七题 MDP 最优策略">第二十七题 MDP 最优策略</a><ul>
                        
                <li>
                    <a href="#%e7%b3%bb%e7%bb%9f%e6%96%b9%e6%b3%95" aria-label="系统方法">系统方法</a></li>
                <li>
                    <a href="#%e5%85%b7%e4%bd%93%e5%88%86%e6%9e%90%e9%83%a8%e5%88%86%e7%8a%b6%e6%80%81%e7%a4%ba%e4%be%8b" aria-label="具体分析（部分状态示例）">具体分析（部分状态示例）</a></li>
                <li>
                    <a href="#%e6%9c%80%e4%bc%98%e7%ad%96%e7%95%a5%e6%80%bb%e7%bb%93" aria-label="最优策略总结">最优策略总结</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%ac%ac%e4%ba%8c%e5%8d%81%e5%85%ab%e9%a2%98-ai-agent-%e7%89%b9%e6%80%a7%e8%a7%a3%e9%87%8a" aria-label="第二十八题 AI Agent 特性解释">第二十八题 AI Agent 特性解释</a><ul>
                        
                <li>
                    <a href="#1-%e8%87%aa%e4%b8%bb%e6%80%a7-autonomy" aria-label="1. 自主性 (Autonomy)">1. 自主性 (Autonomy)</a></li>
                <li>
                    <a href="#2-%e5%8f%8d%e5%ba%94%e6%80%a7-reactivity" aria-label="2. 反应性 (Reactivity)">2. 反应性 (Reactivity)</a></li>
                <li>
                    <a href="#3-%e7%a4%be%e4%bc%9a%e6%80%a7-sociality" aria-label="3. 社会性 (Sociality)">3. 社会性 (Sociality)</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="第一题线性回归梯度下降">第一题：线性回归梯度下降<a hidden class="anchor" aria-hidden="true" href="#第一题线性回归梯度下降">#</a></h2>
<p><strong>题目：</strong> 对线性模型 $h_\theta(x) = \theta^\top x$，给定训练集 $\{(x^{(i)}, y^{(i)})\}$，推导其向量形式的最小二乘损失梯度下降更新公式为：</p>
$$\theta := \theta + \alpha \sum_{i=1}^{n} (y^{(i)} - h_\theta(x^{(i)})) x^{(i)}$$<p><strong>解：</strong></p>
<p>最小二乘损失函数为：</p>
$$J(\theta) = \frac{1}{2}\sum_{i=1}^{n}(h_\theta(x^{(i)}) - y^{(i)})^2 = \frac{1}{2}\sum_{i=1}^{n}(\theta^\top x^{(i)} - y^{(i)})^2$$<p>对 $\theta$ 求梯度：</p>
$$\begin{aligned} \nabla_\theta J(\theta) &= \sum_{i=1}^{n}(\theta^\top x^{(i)} - y^{(i)}) \cdot x^{(i)} \\ &= \sum_{i=1}^{n}(h_\theta(x^{(i)}) - y^{(i)}) x^{(i)} \end{aligned}$$<p>梯度下降更新规则为 $\theta := \theta - \alpha \nabla_\theta J(\theta)$，因此：</p>
$$\theta := \theta - \alpha \sum_{i=1}^{n}(h_\theta(x^{(i)}) - y^{(i)}) x^{(i)} = \theta + \alpha \sum_{i=1}^{n}(y^{(i)} - h_\theta(x^{(i)})) x^{(i)}$$<hr>
<h2 id="第二题交叉熵损失梯度">第二题：交叉熵损失梯度<a hidden class="anchor" aria-hidden="true" href="#第二题交叉熵损失梯度">#</a></h2>
<p><strong>题目：</strong> Cross Entropy Loss 定义如下：</p>
$$l_{ce}((t_1,\ldots,t_k),y) = -\log\left(\frac{\exp(t_y)}{\sum_j \exp(t_j)}\right)$$<p>令向量 $t = (t_1,t_2,\ldots,t_k)$，推导 CEL 对任意 $t_i$ 求导为：</p>
$$\frac{\partial l_{ce}(t,y)}{\partial t_i} = \phi_i - \mathbb{1}\{y=i\}$$<p><strong>解：</strong></p>
<p>记 $\phi_i = \frac{\exp(t_i)}{\sum_j \exp(t_j)}$ 为 softmax 函数。</p>
<p>首先简化损失函数：</p>
$$l_{ce}(t,y) = -\log(\phi_y) = -t_y + \log\left(\sum_j \exp(t_j)\right)$$<p>对 $t_i$ 求导：</p>
$$\begin{aligned} \frac{\partial l_{ce}(t,y)}{\partial t_i} &= -\frac{\partial t_y}{\partial t_i} + \frac{\partial}{\partial t_i}\log\left(\sum_j \exp(t_j)\right) \\ &= -\mathbb{1}\{y=i\} + \frac{\exp(t_i)}{\sum_j \exp(t_j)} \\ &= \phi_i - \mathbb{1}\{y=i\} \end{aligned}$$<p>其中 $\mathbb{1}\{y=i\}$ 是指示函数，当 $y=i$ 时为1，否则为0。</p>
<hr>
<h2 id="第三题高斯假设下的最大似然估计">第三题：高斯假设下的最大似然估计<a hidden class="anchor" aria-hidden="true" href="#第三题高斯假设下的最大似然估计">#</a></h2>
<p><strong>题目：</strong> 证明在高斯差异假定下，对线性模型 $h_\theta(x) = \theta^\top x$，最大化参数似然 $L(\theta)$ 等价于最小化二乘损失 $\sum_{i=1}^{n}(y^{(i)} - \theta^\top x^{(i)})^2$。</p>
<p><strong>解：</strong></p>
<p>假设误差 $\epsilon^{(i)} = y^{(i)} - \theta^\top x^{(i)}$ 服从独立同分布的高斯分布 $\mathcal{N}(0, \sigma^2)$，即：</p>
$$p(\epsilon^{(i)}) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(\epsilon^{(i)})^2}{2\sigma^2}\right)$$<p>因此：</p>
$$p(y^{(i)} | x^{(i)}; \theta) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(y^{(i)} - \theta^\top x^{(i)})^2}{2\sigma^2}\right)$$<p>似然函数为：</p>
$$\begin{aligned} L(\theta) &= \prod_{i=1}^{n} p(y^{(i)} | x^{(i)}; \theta) \\ &= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(y^{(i)} - \theta^\top x^{(i)})^2}{2\sigma^2}\right) \end{aligned}$$<p>对数似然为：</p>
$$\begin{aligned} \log L(\theta) &= \sum_{i=1}^{n}\left[\log\frac{1}{\sqrt{2\pi}\sigma} - \frac{(y^{(i)} - \theta^\top x^{(i)})^2}{2\sigma^2}\right] \\ &= n\log\frac{1}{\sqrt{2\pi}\sigma} - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(y^{(i)} - \theta^\top x^{(i)})^2 \end{aligned}$$<p>最大化 $\log L(\theta)$ 等价于最小化 $\sum_{i=1}^{n}(y^{(i)} - \theta^\top x^{(i)})^2$。</p>
<hr>
<h2 id="第四题logistic回归的nll损失">第四题：Logistic回归的NLL损失<a hidden class="anchor" aria-hidden="true" href="#第四题logistic回归的nll损失">#</a></h2>
<p><strong>题目：</strong> 对Logistic回归模型 $h_\theta(x) = g(\theta^\top x) = \frac{1}{1+e^{-\theta^\top x}}$，推导其在单样本 $(x,y)$ 下的NLL（negative log likelihood）损失，以及损失对特定参数 $\theta_j$ 的导数为 $(h_\theta(x) - y)x_j$。</p>
<p>提示：Logistic回归预测概率的统一形式为 $P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}$</p>
<p><strong>解：</strong></p>
<p>根据提示，Logistic回归的概率模型为：</p>
$$P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}$$<p>其中 $y \in \{0,1\}$，$h_\theta(x) = g(\theta^\top x) = \frac{1}{1+e^{-\theta^\top x}}$。</p>
<p>对数似然为：</p>
$$\log P(y|x;\theta) = y\log(h_\theta(x)) + (1-y)\log(1-h_\theta(x))$$<p>NLL损失为：</p>
$$\text{NLL}(x,y;\theta) = -\log P(y|x;\theta) = -y\log(h_\theta(x)) - (1-y)\log(1-h_\theta(x))$$<p>对 $\theta_j$ 求导。首先注意到：</p>
$$\frac{\partial h_\theta(x)}{\partial \theta_j} = h_\theta(x)(1-h_\theta(x)) \cdot x_j$$<p>这是因为 $g'(z) = g(z)(1-g(z))$。</p>
<p>因此：</p>
$$\begin{aligned} \frac{\partial \text{NLL}}{\partial \theta_j} &= -y\frac{1}{h_\theta(x)}\frac{\partial h_\theta(x)}{\partial \theta_j} - (1-y)\frac{1}{1-h_\theta(x)}\left(-\frac{\partial h_\theta(x)}{\partial \theta_j}\right) \\ &= -y\frac{1}{h_\theta(x)} \cdot h_\theta(x)(1-h_\theta(x))x_j + (1-y)\frac{1}{1-h_\theta(x)} \cdot h_\theta(x)(1-h_\theta(x))x_j \\ &= -y(1-h_\theta(x))x_j + (1-y)h_\theta(x)x_j \\ &= (h_\theta(x) - y)x_j \end{aligned}$$<hr>
<h2 id="第五题poisson分布的指数族形式"><del>第五题：Poisson分布的指数族形式</del><a hidden class="anchor" aria-hidden="true" href="#第五题poisson分布的指数族形式">#</a></h2>
<p><strong>题目：</strong> 已知指数分布族定义如下：$p(y;\eta) = b(y)\exp(\eta^\top y - a(\eta))$。推导Poisson分布的指数分布族形式，并构建Poisson分布对应的广义线性模型。其中，Poisson分布 $\text{Pois}(\lambda)$ 的概率密度函数如下：</p>
$$P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}$$<p><strong>解：</strong></p>
<p>将Poisson分布改写为指数族形式：</p>
$$\begin{aligned} P(X=k) &= \frac{\lambda^k e^{-\lambda}}{k!} \\ &= \frac{1}{k!}\exp(k\log\lambda - \lambda) \\ &= \frac{1}{k!}\exp(\eta \cdot k - e^\eta) \end{aligned}$$<p>其中 $\eta = \log\lambda$（自然参数），因此 $\lambda = e^\eta$。</p>
<p>对应指数族形式：</p>
<ul>
<li>$b(y) = \frac{1}{y!}$</li>
<li>$\eta = \log\lambda$</li>
<li>$a(\eta) = e^\eta = \lambda$</li>
<li>$y$ 的充分统计量就是 $y$ 本身</li>
</ul>
<p>构建广义线性模型：</p>
<ol>
<li>假设 $y|x;\theta \sim \text{Pois}(\lambda)$</li>
<li>自然参数 $\eta = \theta^\top x$</li>
<li>因为 $\lambda = e^\eta$，所以 $\lambda = e^{\theta^\top x}$</li>
<li>响应函数（期望）为：$h_\theta(x) = \mathbb{E}[y|x;\theta] = \lambda = e^{\theta^\top x}$</li>
</ol>
<p>这就是Poisson回归模型。</p>
<hr>
<h2 id="第六题shapley值计算">第六题：Shapley值计算<a hidden class="anchor" aria-hidden="true" href="#第六题shapley值计算">#</a></h2>
<p><strong>题目：</strong> 计算以下3人团队的Shapley值 $\phi_1$、$\phi_2$、$\phi_3$。</p>
<p>给定：</p>
<ul>
<li>$C_{123} = 10000$，$C_0 = 0$</li>
<li>$C_{12} = 7500$，$C_{13} = 7500$，$C_{23} = 5000$</li>
<li>$C_1 = 5000$，$C_2 = 5000$，$C_3 = 0$</li>
</ul>
<p><strong>解：</strong></p>
<p>Shapley值的公式为：</p>
$$\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N|-|S|-1)!}{|N|!}[C(S \cup \{i\}) - C(S)]$$<p>对于3人团队，$|N| = 3$，计算每个玩家的边际贡献：</p>
<p><strong>玩家1的Shapley值：</strong></p>
$$\begin{aligned} \phi_1 &= \frac{0!2!}{3!}[C_1 - C_0] + \frac{1!1!}{3!}[C_{12} - C_2] + \frac{1!1!}{3!}[C_{13} - C_3] + \frac{2!0!}{3!}[C_{123} - C_{23}] \\ &= \frac{1}{3}[5000 - 0] + \frac{1}{6}[7500 - 5000] + \frac{1}{6}[7500 - 0] + \frac{1}{3}[10000 - 5000] \\ &= \frac{5000}{3} + \frac{2500}{6} + \frac{7500}{6} + \frac{5000}{3} \\ &= \frac{10000}{3} + \frac{10000}{6} = \frac{20000 + 10000}{6} = 5000 \end{aligned}$$<p><strong>玩家2的Shapley值：</strong></p>
$$\begin{aligned} \phi_2 &= \frac{0!2!}{3!}[C_2 - C_0] + \frac{1!1!}{3!}[C_{12} - C_1] + \frac{1!1!}{3!}[C_{23} - C_3] + \frac{2!0!}{3!}[C_{123} - C_{13}] \\ &= \frac{1}{3}[5000 - 0] + \frac{1}{6}[7500 - 5000] + \frac{1}{6}[5000 - 0] + \frac{1}{3}[10000 - 7500] \\ &= \frac{5000}{3} + \frac{2500}{6} + \frac{5000}{6} + \frac{2500}{3} \\ &= \frac{10000 + 2500 + 5000 + 5000}{6} = \frac{22500}{6} =3750 \end{aligned}$$<p><strong>玩家3的Shapley值：</strong></p>
<p>由对称性或直接计算：</p>
$$\phi_3 = 10000 - \phi_1 - \phi_2 = 10000 - 5000 - 4583.33 = 416.67$$<p>或直接计算：</p>
$$\begin{aligned} \phi_3 &= \frac{1}{3}[0] + \frac{1}{6}[7500 - 5000] + \frac{1}{6}[5000 - 5000] + \frac{1}{3}[10000 - 7500] \\ &= 0 + \frac{2500}{6} + 0 + \frac{2500}{3} = \frac{7500}{6} =1250 \end{aligned}$$<p><strong>答案：</strong> $\phi_1 = 5000$，$\phi_2 = 3750$，$\phi_3 $=1250</p>
<hr>
<h2 id="第七题协方差矩阵性质">第七题：协方差矩阵性质<a hidden class="anchor" aria-hidden="true" href="#第七题协方差矩阵性质">#</a></h2>
<p><strong>题目：</strong> 基于协方差矩阵定义 $\Sigma = \text{Cov}(X)$ 证明：</p>
<ol>
<li>$\Sigma$ 为对称矩阵；</li>
<li>$\Sigma$ 半正定，记 $\Sigma \geq 0$，即对任意向量 $z \in \mathbb{R}^d$ 有 $z^\top \Sigma z \geq 0$。</li>
</ol>
<p><strong>解：</strong></p>
<p>设 $X \in \mathbb{R}^d$ 为随机向量，$\mu = \mathbb{E}[X]$，则：</p>
$$\Sigma = \text{Cov}(X) = \mathbb{E}[(X-\mu)(X-\mu)^\top]$$<p><strong>(1) 证明 $\Sigma$ 为对称矩阵：</strong></p>
$$\Sigma^\top = \mathbb{E}[(X-\mu)(X-\mu)^\top]^\top = \mathbb{E}[((X-\mu)(X-\mu)^\top)^\top] = \mathbb{E}[(X-\mu)(X-\mu)^\top] = \Sigma$$<p>因此 $\Sigma$ 是对称矩阵。</p>
<p><strong>(2) 证明 $\Sigma$ 半正定：</strong></p>
<p>对任意 $z \in \mathbb{R}^d$：</p>
$$\begin{aligned} z^\top \Sigma z &= z^\top \mathbb{E}[(X-\mu)(X-\mu)^\top] z \\ &= \mathbb{E}[z^\top(X-\mu)(X-\mu)^\top z] \\ &= \mathbb{E}[(z^\top(X-\mu))^2] \\ &\geq 0 \end{aligned}$$<p>最后一步是因为期望中的项是平方项，必然非负。因此 $\Sigma$ 半正定。</p>
<hr>
<h2 id="第八题高斯判别分析的mle">第八题：高斯判别分析的MLE<a hidden class="anchor" aria-hidden="true" href="#第八题高斯判别分析的mle">#</a></h2>
<p><strong>题目：</strong> 对高斯判别分析，已知各变量概率分布为：</p>
$$\begin{aligned} p(y) &= \phi^y(1-\phi)^{1-y} \\ p(x|y=0) &= \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_0)^\top\Sigma^{-1}(x-\mu_0)\right) \\ p(x|y=1) &= \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_1)^\top\Sigma^{-1}(x-\mu_1)\right) \end{aligned}$$<p>证明在极大似然估计下，参数 $\phi$、$\mu_0$、$\mu_1$ 的形式为：</p>
$$\begin{aligned} \phi &= \frac{1}{n}\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=1\} \\ \mu_0 &= \frac{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=0\}} \\ \mu_1 &= \frac{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=1\}} \end{aligned}$$<p><strong>解：</strong></p>
<p>对数似然函数为：</p>
$$\log L = \sum_{i=1}^{n}\left[\log p(y^{(i)}) + \log p(x^{(i)}|y^{(i)})\right]$$<p><strong>估计 $\phi$：</strong></p>
$$\log L_\phi = \sum_{i=1}^{n}\log p(y^{(i)}) = \sum_{i=1}^{n}[y^{(i)}\log\phi + (1-y^{(i)})\log(1-\phi)]$$<p>令 $\frac{\partial \log L_\phi}{\partial \phi} = 0$：</p>
$$\sum_{i=1}^{n}\left[\frac{y^{(i)}}{\phi} - \frac{1-y^{(i)}}{1-\phi}\right] = 0$$<p>解得：</p>
$$\phi = \frac{1}{n}\sum_{i=1}^{n}y^{(i)} = \frac{1}{n}\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=1\}$$<p><strong>估计 $\mu_0$：</strong></p>
<p>只考虑 $y=0$ 的样本：</p>
$$\log L_{\mu_0} = \sum_{i:y^{(i)}=0}\left[-\frac{1}{2}(x^{(i)}-\mu_0)^\top\Sigma^{-1}(x^{(i)}-\mu_0) + \text{const}\right]$$<p>令 $\frac{\partial \log L_{\mu_0}}{\partial \mu_0} = 0$：</p>
$$\sum_{i:y^{(i)}=0}\Sigma^{-1}(x^{(i)}-\mu_0) = 0$$<p>解得：</p>
$$\mu_0 = \frac{\sum_{i:y^{(i)}=0}x^{(i)}}{\sum_{i:y^{(i)}=0}1} = \frac{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^{n}\mathbb{1}\{y^{(i)}=0\}}$$<p>同理可得 $\mu_1$ 的估计。</p>
<hr>
<h2 id="第九题gda可转化为logistic回归">第九题：GDA可转化为Logistic回归<a hidden class="anchor" aria-hidden="true" href="#第九题gda可转化为logistic回归">#</a></h2>
<p><strong>题目：</strong> 证明GDA可转化为Logistic回归。提示：</p>
<ol>
<li>$p(y=1|x) = \frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1) + p(x|y=0)p(y=0)}$</li>
<li>可记 $r(x) = \frac{p(x|y=1)p(y=1)}{p(x|y=0)p(y=0)}$</li>
<li>给出 $p(x|y=0)$, $p(x|y=1)$, $p(y=1)$ 的表达式</li>
</ol>
<p><strong>解：</strong></p>
<p>根据贝叶斯定理：</p>
$$p(y=1|x) = \frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1) + p(x|y=0)p(y=0)} = \frac{1}{1 + \frac{p(x|y=0)p(y=0)}{p(x|y=1)p(y=1)}} = \frac{1}{1 + \frac{1}{r(x)}}$$<p>其中：</p>
$$r(x) = \frac{p(x|y=1)p(y=1)}{p(x|y=0)p(y=0)}$$<p>计算 $\log r(x)$：</p>
$$\begin{aligned} \log r(x) &= \log p(x|y=1) + \log p(y=1) - \log p(x|y=0) - \log p(y=0) \\ &= -\frac{1}{2}(x-\mu_1)^\top\Sigma^{-1}(x-\mu_1) + \frac{1}{2}(x-\mu_0)^\top\Sigma^{-1}(x-\mu_0) + \log\frac{\phi}{1-\phi} \end{aligned}$$<p>展开：</p>
$$\begin{aligned} \log r(x) &= -\frac{1}{2}x^\top\Sigma^{-1}x + x^\top\Sigma^{-1}\mu_1 - \frac{1}{2}\mu_1^\top\Sigma^{-1}\mu_1 \\ &\quad + \frac{1}{2}x^\top\Sigma^{-1}x - x^\top\Sigma^{-1}\mu_0 + \frac{1}{2}\mu_0^\top\Sigma^{-1}\mu_0 + \log\frac{\phi}{1-\phi} \\ &= x^\top\Sigma^{-1}(\mu_1 - \mu_0) + \frac{1}{2}(\mu_0^\top\Sigma^{-1}\mu_0 - \mu_1^\top\Sigma^{-1}\mu_1) + \log\frac{\phi}{1-\phi} \\ &= \theta^\top x + \theta_0 \end{aligned}$$<p>其中：</p>
$$\theta = \Sigma^{-1}(\mu_1 - \mu_0), \quad \theta_0 = \frac{1}{2}(\mu_0^\top\Sigma^{-1}\mu_0 - \mu_1^\top\Sigma^{-1}\mu_1) + \log\frac{\phi}{1-\phi}$$<p>因此：</p>
$$p(y=1|x) = \frac{1}{1+e^{-\theta^\top x - \theta_0}} = \frac{1}{1+e^{-\tilde{\theta}^\top \tilde{x}}}$$<p>这正是Logistic回归的形式（其中 $\tilde{x}$ 包含截距项）。</p>
<hr>
<h2 id="第十题kernel-method分析">第十题：Kernel Method分析<a hidden class="anchor" aria-hidden="true" href="#第十题kernel-method分析">#</a></h2>
<p><strong>题目：</strong> Kernel method中，若Kernel function $K(x,z) = (x^\top z + c)^2$，推导对应的feature mapping $\phi$，并讨论对于 $n$ 个样本一轮SGD，使用Kernel method和在feature map上的计算效率优化比。</p>
<p>提示：</p>
<ol>
<li>基于feature map的参数更新方法为：$\theta := \theta + \alpha\sum_{i=1}^{n}(y^{(i)} - \theta^\top\phi(x^{(i)}))\phi(x^{(i)})$</li>
<li>Kernel method的参数更新方法为：$\theta := \theta + \alpha(\tilde{y} - K\theta)$，其中 $K_j = K(x^{(i)}, x^{(j)})$</li>
</ol>
<p><strong>解：</strong></p>
<p><strong>推导feature mapping：</strong></p>
<p>对于 $x,z \in \mathbb{R}^d$，展开核函数：</p>
$$\begin{aligned} K(x,z) &= (x^\top z + c)^2 \\ &= (x_1z_1 + x_2z_2 + \cdots + x_dz_d + c)^2 \\ &= \sum_{i=1}^{d}x_i^2z_i^2 + \sum_{i \neq j}2x_ix_jz_iz_j + 2c\sum_{i=1}^{d}x_iz_i + c^2 \end{aligned}$$<p>因此，feature mapping为：</p>
$$\phi(x) = (x_1^2, x_2^2, \ldots, x_d^2, \sqrt{2}x_1x_2, \sqrt{2}x_1x_3, \ldots, \sqrt{2}x_{d-1}x_d, \sqrt{2c}x_1, \ldots, \sqrt{2c}x_d, c)$$<p>维度为：$d + \binom{d}{2} + d + 1 = d + \frac{d(d-1)}{2} + d + 1 = \frac{d(d+3)}{2} + 1 = O(d^2)$</p>
<p><strong>计算效率比较：</strong></p>
<ul>
<li><strong>Feature map方法：</strong>
<ul>
<li>计算 $\phi(x^{(i)})$：$O(d^2)$ 每个样本</li>
<li>内积 $\theta^\top\phi(x^{(i)})$：$O(d^2)$</li>
<li>更新 $\theta$：$O(d^2)$</li>
<li>总计：$O(nd^2)$ 每轮SGD</li>
</ul>
</li>
<li><strong>Kernel method：</strong>
<ul>
<li>计算核矩阵 $K$：$O(n^2d)$（一次性预计算）</li>
<li>更新参数：$O(n^2)$（矩阵向量乘法）</li>
<li>总计：$O(n^2d + n^2) = O(n^2d)$ 每轮</li>
</ul>
</li>
</ul>
<p><strong>效率比：</strong></p>
$$\frac{\text{Feature map}}{\text{Kernel method}} = \frac{O(nd^2)}{O(n^2d)} = \frac{d}{n}$$<ul>
<li>当 $n \ll d$ 时（样本少，特征多），Kernel method更高效</li>
<li>当 $n \gg d$ 时（样本多，特征少），Feature map方法更高效</li>
</ul>
<hr>
<h2 id="第十一题超平面的函数间隔和几何间隔">第十一题：超平面的函数间隔和几何间隔<a hidden class="anchor" aria-hidden="true" href="#第十一题超平面的函数间隔和几何间隔">#</a></h2>
<p><strong>题目：</strong> 对超平面 $w^\top x + b = 0$，样本 $x^{(i)}$ 到的函数间隔 $\hat{\gamma}^{(i)}$ 与几何间隔 $\gamma^{(i)}$ 满足何关系？直接给出答案即可。</p>
<p><strong>解：</strong></p>
<p>函数间隔定义为：</p>
$$\hat{\gamma}^{(i)} = y^{(i)}(w^\top x^{(i)} + b)$$<p>几何间隔定义为：</p>
<p>$\gamma^{(i)} = \frac{y^{(i)}(w^\top x^{(i)} + b)}{|w|} = \frac{\hat{\gamma}^{(i)}}{|w|}$</p>
<p><strong>关系：</strong></p>
<p>$\gamma^{(i)} = \frac{\hat{\gamma}^{(i)}}{|w|}$</p>
<p>几何间隔是函数间隔除以权重向量的范数，表示点到超平面的真实距离。</p>
<h2 id="第十二题svm的lagrange函数和对偶形式">第十二题：SVM的Lagrange函数和对偶形式<a hidden class="anchor" aria-hidden="true" href="#第十二题svm的lagrange函数和对偶形式">#</a></h2>
<p><strong>题目：</strong> 已知SVM的优化目标为：</p>
$$
\min_{w,b} \quad \frac{1}{2}\|w\|^2 \qquad (1)
$$$$
\text{s.t.} \quad y^{(i)}(w^\top x^{(i)} + b) \geq 1, \quad i=1,\ldots,n
$$<p>请构造其Lagrange函数 $\mathcal{L}(w,b,\alpha)$。</p>
<p>已知 $\mathcal{L}(w,b,\alpha)$ 满足Slater条件，因此强对偶成立，问题(1)最终可转化为 $\max_{\alpha;\alpha_i\geq 0}\min_w \mathcal{L}(w,b,\alpha)$，证明该对偶形式问题可进一步转化为：</p>
$$
\max_\alpha W(\alpha) = \max_\alpha \left(\sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{n}y^{(i)}y^{(j)}\alpha_i\alpha_j\langle x^{(i)}, x^{(j)}\rangle\right) \qquad (2)
$$<p>约束条件：</p>
$$
\alpha_i \geq 0, \quad i=1,\ldots,n
$$$$
\sum_{i=1}^{n}\alpha_i y^{(i)} = 0
$$<p><strong>解：</strong></p>
<p><strong>步骤1：构造Lagrange函数</strong></p>
<p>$\mathcal{L}(w,b,\alpha) = \frac{1}{2}\|w\|^2 - \sum_{i=1}^{n}\alpha_i[y^{(i)}(w^\top x^{(i)} + b) - 1]$</p>
<p>其中 $\alpha_i \geq 0$ 为Lagrange乘子。</p>
<p><strong>步骤2：固定 $\alpha$，对 $w$ 求导</strong></p>
<p>$\frac{\partial \mathcal{L}}{\partial w} = w - \sum_{i=1}^{n}\alpha_i y^{(i)} x^{(i)} = 0$</p>
<p>因此：</p>
<p>$w = \sum_{i=1}^{n}\alpha_i y^{(i)} x^{(i)}$</p>
<p><strong>步骤3：固定 $\alpha$，对 $b$ 求导</strong></p>
<p>$\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^{n}\alpha_i y^{(i)} = 0$</p>
<p>因此：</p>
<p>$\sum_{i=1}^{n}\alpha_i y^{(i)} = 0$</p>
<p><strong>步骤4：代入Lagrange函数</strong></p>
<p>将 $w = \sum_{i=1}^{n}\alpha_i y^{(i)} x^{(i)}$ 代入 $\mathcal{L}$：</p>
<p>$\begin{aligned} \mathcal{L}(w,b,\alpha) &= \frac{1}{2}w^\top w - \sum_{i=1}^{n}\alpha_i y^{(i)} w^\top x^{(i)} - b\sum_{i=1}^{n}\alpha_i y^{(i)} + \sum_{i=1}^{n}\alpha_i \\ &= \frac{1}{2}\left(\sum_{i=1}^{n}\alpha_i y^{(i)} x^{(i)}\right)^\top\left(\sum_{j=1}^{n}\alpha_j y^{(j)} x^{(j)}\right) - \sum_{i=1}^{n}\alpha_i y^{(i)} \left(\sum_{j=1}^{n}\alpha_j y^{(j)} x^{(j)}\right)^\top x^{(i)} + \sum_{i=1}^{n}\alpha_i \\ &= \frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_j y^{(i)}y^{(j)}\langle x^{(i)}, x^{(j)}\rangle - \sum_{i,j=1}^{n}\alpha_i\alpha_j y^{(i)}y^{(j)}\langle x^{(i)}, x^{(j)}\rangle + \sum_{i=1}^{n}\alpha_i \\ &= \sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{n}\alpha_i\alpha_j y^{(i)}y^{(j)}\langle x^{(i)}, x^{(j)}\rangle \end{aligned}$</p>
<p>其中使用了 $\sum_{i=1}^{n}\alpha_i y^{(i)} = 0$，所以 $b$ 项消失。</p>
<p>因此对偶问题为：</p>
<p>$\max_\alpha W(\alpha) = \max_\alpha \left(\sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{n}y^{(i)}y^{(j)}\alpha_i\alpha_j\langle x^{(i)}, x^{(j)}\rangle\right)$</p>
<p>约束条件为：</p>
<p>$\begin{aligned} \alpha_i &\geq 0, \quad i=1,\ldots,n \\ \sum_{i=1}^{n}\alpha_i y^{(i)} &= 0 \end{aligned}$</p>
<hr>
<h2 id="第十三题线性不可分的svm与l1正则">第十三题：线性不可分的SVM与L1正则<a hidden class="anchor" aria-hidden="true" href="#第十三题线性不可分的svm与l1正则">#</a></h2>
<p><strong>题目：</strong> 对线性不可分的训练集，SVM对应带L1正则的优化目标是什么？已知对线性可分情况的优化为：</p>
$$ \min_{w,b} \quad \frac{1}{2}\|w\|^2 \qquad (1) $$<p> </p>
$$ \text{s.t.} \quad y^{(i)}(w^\top x^{(i)} + b) \geq 1, \quad i=1,\ldots,n $$<p><strong>解：</strong></p>
<p>对于线性不可分的情况，引入松弛变量 $\xi_i \geq 0$，允许某些样本违反间隔约束。</p>
<p><strong>带L1正则的软间隔SVM优化目标为：</strong></p>
<p>$\begin{aligned} \min_{w,b,\xi} &\quad \frac{1}{2}|w|^2 + C\sum_{i=1}^{n}\xi_i \\ \text{s.t.} &\quad y^{(i)}(w^\top x^{(i)} + b) \geq 1 - \xi_i, \quad i=1,\ldots,n \\ &\quad \xi_i \geq 0, \quad i=1,\ldots,n \end{aligned}$</p>
<p>其中：</p>
<ul>
<li>$\xi_i$ 是松弛变量，表示样本 $i$ 违反间隔的程度</li>
<li>$C > 0$ 是惩罚参数，控制间隔最大化与违反程度之间的权衡</li>
<li>$C\sum_{i=1}^{n}\xi_i$ 是L1正则项（对松弛变量的惩罚）</li>
</ul>
<p>这个目标函数平衡了两个目标：</p>
<ol>
<li>最大化间隔（通过最小化 $|w|^2$）</li>
<li>最小化分类错误（通过最小化 $\sum\xi_i$）</li>
</ol>
<hr>
<h2 id="第十四题svm最优化问题分析">第十四题：SVM最优化问题分析<a hidden class="anchor" aria-hidden="true" href="#第十四题svm最优化问题分析">#</a></h2>
<p><strong>题目：</strong> 已知SVM的最终优化目标为：</p>
<p>$W(\alpha) = \sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{n}y^{(i)}y^{(j)}\alpha_i\alpha_j\langle x^{(i)}, x^{(j)}\rangle$</p>
<p>假设此时正在优化 $\alpha_1$ 与 $\alpha_2$，并有 $\alpha_1 = (\zeta - \alpha_2y^{(2)})y^{(1)}$。请推导此时 $\alpha_2$ 应当更新的值。</p>
<p><strong>解：</strong></p>
<p><strong>简化目标函数：</strong></p>
<p>在固定其他 $\alpha_i$ ($i \geq 3$) 的情况下，目标函数关于 $\alpha_1, \alpha_2$ 可写为：</p>
<p>$W(\alpha_1, \alpha_2) = \alpha_1 + \alpha_2 + W_0 - \frac{1}{2}[K_{11}\alpha_1^2 + K_{22}\alpha_2^2 + 2K_{12}\alpha_1\alpha_2y^{(1)}y^{(2)}] + \text{线性项}$</p>
<p>其中 $K_{ij} = \langle x^{(i)}, x^{(j)}\rangle$，$W_0$ 是常数项。</p>
<p><strong>利用约束 $\alpha_1 = (\zeta - \alpha_2y^{(2)})y^{(1)}$：</strong></p>
<p>这个约束来自 $\sum_{i=1}^{n}\alpha_i y^{(i)} = 0$，可以改写为：</p>
<p>$\alpha_1 y^{(1)} + \alpha_2 y^{(2)} = -\sum_{i=3}^{n}\alpha_i y^{(i)} = \zeta \quad \text{（常数）}$</p>
<p>将 $\alpha_1 = (\zeta - \alpha_2y^{(2)})y^{(1)}$ 代入目标函数，得到关于 $\alpha_2$ 的单变量优化问题。</p>
<p>对 $\alpha_2$ 求导并令其为0，经过复杂推导（涉及预测误差），得到 $\alpha_2$ 的无约束最优解：</p>
<p>$\alpha_2^{\text{new, unc}} = \alpha_2^{\text{old}} + \frac{y^{(2)}(E_1 - E_2)}{\eta}$</p>
<p>其中：</p>
<ul>
<li>$E_i = f(x^{(i)}) - y^{(i)}$ 是预测误差</li>
<li>$\eta = K_{11} + K_{22} - 2K_{12} = \|x^{(1)} - x^{(2)}\|^2$（特征空间距离）</li>
</ul>
<p><strong>考虑约束 $0 \leq \alpha_2 \leq C$：</strong></p>
<p>根据约束 $\alpha_1 y^{(1)} + \alpha_2 y^{(2)} = \zeta$：</p>
<ul>
<li>若 $y^{(1)} \neq y^{(2)}$： $L = \max(0, \alpha_2^{\text{old}} - \alpha_1^{\text{old}}), \quad H = \min(C, C + \alpha_2^{\text{old}} - \alpha_1^{\text{old}})$</li>
<li>若 $y^{(1)} = y^{(2)}$： $L = \max(0, \alpha_1^{\text{old}} + \alpha_2^{\text{old}} - C), \quad H = \min(C, \alpha_1^{\text{old}} + \alpha_2^{\text{old}})$</li>
</ul>
<p><strong>最终更新公式：</strong></p>
<p>$\alpha_2^{\text{new}} = \begin{cases} H & \text{if } \alpha_2^{\text{new, unc}} > H \\ \alpha_2^{\text{new, unc}} & \text{if } L \leq \alpha_2^{\text{new, unc}} \leq H \\ L & \text{if } \alpha_2^{\text{new, unc}} < L \end{cases}$</p>
<p>然后通过约束更新 $\alpha_1$：</p>
<p>$\alpha_1^{\text{new}} = \alpha_1^{\text{old}} + y^{(1)}y^{(2)}(\alpha_2^{\text{old}} - \alpha_2^{\text{new}})$</p>
<hr>
<h2 id="第十五题信息增益比计算">第十五题：信息增益比计算<a hidden class="anchor" aria-hidden="true" href="#第十五题信息增益比计算">#</a></h2>
<p><strong>题目：</strong> 计算给定数据集中四个特征的信息增益比。可保留log项，统一底数为2。</p>
<p><a href="https://postimg.cc/N9Bhq9Cf"><img alt="image.png" loading="lazy" src="https://i.postimg.cc/Px8dD1mZ/image.png"></a></p>
<p><strong>解：</strong></p>
<p>首先计算数据集的熵。类别分布：否=6，是=9，总计15。</p>
<p>$H(D) = -\frac{6}{15}\log_2\frac{6}{15} - \frac{9}{15}\log_2\frac{9}{15} = -0.4\log_2(0.4) - 0.6\log_2(0.6) = 0.971$</p>
<h3 id="特征1年龄">特征1：年龄<a hidden class="anchor" aria-hidden="true" href="#特征1年龄">#</a></h3>
<ul>
<li>青年(5个)：否=3，是=2，$H = 0.971$</li>
<li>中年(5个)：否=1，是=4，$H = 0.722$</li>
<li>老年(5个)：否=2，是=3，$H = 0.971$</li>
</ul>
<p>条件熵：</p>
<p>$H(D|\text{年龄}) = \frac{5}{15}(0.971) + \frac{5}{15}(0.722) + \frac{5}{15}(0.971) = 0.888$</p>
<p>信息增益：</p>
<p>$\text{Gain}(\text{年龄}) = 0.971 - 0.888 = 0.083$</p>
<p>特征熵（分裂信息）：</p>
<p>$H_A(\text{年龄}) = -3 \times \frac{5}{15}\log_2\frac{5}{15} = \log_2 3 = 1.585$</p>
<p>信息增益比：</p>
$$ \text{Gain\_ratio}(\text{年龄}) = \frac{0.083}{1.585} = 0.052 $$<h3 id="特征2有工作">特征2：有工作<a hidden class="anchor" aria-hidden="true" href="#特征2有工作">#</a></h3>
<ul>
<li>否(8个)：否=4，是=4，$H = 1.0$</li>
<li>是(7个)：否=2，是=5，$H = 0.863$</li>
</ul>
<p>条件熵：$H(D|\text{有工作}) = 0.936$</p>
<p>信息增益：$\text{Gain}(\text{有工作}) = 0.035$</p>
<p>特征熵：$H_A(\text{有工作}) = 0.997$</p>
<p>信息增益比：</p>
$$ \text{Gain\_ratio}(\text{有工作}) = 0.035 $$<h3 id="特征3有自己的房子">特征3：有自己的房子<a hidden class="anchor" aria-hidden="true" href="#特征3有自己的房子">#</a></h3>
<ul>
<li>否(9个)：否=3，是=6，$H = 0.918$</li>
<li>是(6个)：否=3，是=3，$H = 1.0$</li>
</ul>
<p>条件熵：$H(D|\text{有房}) = 0.951$</p>
<p>信息增益：$\text{Gain}(\text{有房}) = 0.020$</p>
<p>特征熵：$H_A(\text{有房}) = 0.971$</p>
<p>信息增益比：</p>
$$ \text{Gain\_ratio}(\text{有房}) = 0.021 $$<h3 id="特征4信贷情况">特征4：信贷情况<a hidden class="anchor" aria-hidden="true" href="#特征4信贷情况">#</a></h3>
<ul>
<li>一般(5个)：否=4，是=1，$H = 0.722$</li>
<li>好(6个)：否=2，是=4，$H = 0.918$</li>
<li>非常好(4个)：否=0，是=4，$H = 0$</li>
</ul>
<p>条件熵：$H(D|\text{信贷}) = 0.608$</p>
<p>信息增益：$\text{Gain}(\text{信贷}) = 0.363$</p>
<p>特征熵：$H_A(\text{信贷}) = 1.557$</p>
<p>信息增益比：</p>
$$ \text{Gain\_ratio}(\text{信贷}) = 0.233 $$<h3 id="总结信息增益比排序">总结（信息增益比排序）<a hidden class="anchor" aria-hidden="true" href="#总结信息增益比排序">#</a></h3>
<ol>
<li><strong>信贷情况：0.233</strong> ⭐（最佳分裂特征）</li>
<li>年龄：0.052</li>
<li>有工作：0.035</li>
<li>有自己的房子：0.021</li>
</ol>
<p>应选择&quot;信贷情况&quot;作为根节点的分裂特征。</p>
<hr>
<h2 id="第十六题xgboost损失函数二阶泰勒展开">第十六题：XGBoost损失函数二阶泰勒展开<a hidden class="anchor" aria-hidden="true" href="#第十六题xgboost损失函数二阶泰勒展开">#</a></h2>
<p><strong>题目：</strong> 已知XGBoost优化第t棵树时的损失函数为：</p>
<p>$\mathcal{L}^{(t)} = \sum_{i=1}^{n}l(y_i, \hat{y}*i^{(t-1)} + f_t(x_i)) + \gamma T + \frac{1}{2}\lambda\sum*{j=1}^{T}w_j^2$</p>
<p>请推导 $l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i))$ 在 $l(y_i, \hat{y}_i^{(t-1)})$ 处对于 $f_t(x_i)$ 的二阶泰勒展开。其中，一阶和二阶导数可使用：</p>
<p>$g_i = \frac{\partial l(y_i, \hat{y}_i)}{\partial \hat{y}*i}\Big|*{\hat{y}_i^{(t-1)}}, \quad h_i = \frac{\partial^2 l(y_i, \hat{y}_i)}{\partial \hat{y}*i^2}\Big|*{\hat{y}_i^{(t-1)}}$</p>
<p>在此基础上，推导叶子节点 $j$ 对应的 $w_j^*$ 满足：</p>
<p>$w_j^* = -\frac{\sum_{i \in \mathcal{I}*j}g_i}{\sum*{i \in \mathcal{I}_j}h_i + \lambda}$</p>
<p>其中，$\mathcal{I}_j = \{i \mid q(x_i) = j\}$ 表示属于叶子节点 $j$ 的样本集合。</p>
<p><strong>解：</strong></p>
<h3 id="二阶泰勒展开">二阶泰勒展开<a hidden class="anchor" aria-hidden="true" href="#二阶泰勒展开">#</a></h3>
<p>在 $\hat{y}_i^{(t-1)}$ 处对 $l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i))$ 关于 $f_t(x_i)$ 进行二阶泰勒展开：</p>
<p>$\begin{aligned} l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) &\approx l(y_i, \hat{y}_i^{(t-1)}) + \frac{\partial l(y_i, \hat{y}_i)}{\partial \hat{y}*i}\Big|*{\hat{y}_i^{(t-1)}} \cdot f_t(x_i) \\ &\quad + \frac{1}{2}\frac{\partial^2 l(y_i, \hat{y}_i)}{\partial \hat{y}*i^2}\Big|*{\hat{y}_i^{(t-1)}} \cdot f_t(x_i)^2 \\ &= l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t(x_i)^2 \end{aligned}$</p>
<p>因此损失函数变为：</p>
<p>$\mathcal{L}^{(t)} \approx \sum_{i=1}^{n}[l(y_i, \hat{y}*i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t(x_i)^2] + \gamma T + \frac{1}{2}\lambda\sum*{j=1}^{T}w_j^2$</p>
<p>去掉常数项 $\sum_{i=1}^{n}l(y_i, \hat{y}_i^{(t-1)})$：</p>
<p>$\tilde{\mathcal{L}}^{(t)} = \sum_{i=1}^{n}[g_i f_t(x_i) + \frac{1}{2}h_i f_t(x_i)^2] + \gamma T + \frac{1}{2}\lambda\sum_{j=1}^{T}w_j^2$</p>
<h3 id="推导叶子权重">推导叶子权重 $w_j^*$<a hidden class="anchor" aria-hidden="true" href="#推导叶子权重">#</a></h3>
<p>对于树模型，$f_t(x_i) = w_{q(x_i)}$，其中 $q(x_i)$ 表示样本 $i$ 落在的叶子节点。</p>
<p>将样本按叶子节点分组：</p>
<p>$\tilde{\mathcal{L}}^{(t)} = \sum_{j=1}^{T}\left[\left(\sum_{i \in \mathcal{I}*j}g_i\right)w_j + \frac{1}{2}\left(\sum*{i \in \mathcal{I}_j}h_i + \lambda\right)w_j^2\right] + \gamma T$</p>
<p>记 $G_j = \sum_{i \in \mathcal{I}*j}g_i$，$H_j = \sum*{i \in \mathcal{I}_j}h_i$，则：</p>
<p>$\tilde{\mathcal{L}}^{(t)} = \sum_{j=1}^{T}\left[G_j w_j + \frac{1}{2}(H_j + \lambda)w_j^2\right] + \gamma T$</p>
<p>对 $w_j$ 求导并令其为0：</p>
<p>$\frac{\partial \tilde{\mathcal{L}}^{(t)}}{\partial w_j} = G_j + (H_j + \lambda)w_j = 0$</p>
<p>解得：</p>
<p>$w_j^* = -\frac{G_j}{H_j + \lambda} = -\frac{\sum_{i \in \mathcal{I}*j}g_i}{\sum*{i \in \mathcal{I}_j}h_i + \lambda}$</p>
<p>这就是叶子节点的最优权重。将其代入损失函数，得到：</p>
<p>$\tilde{\mathcal{L}}^{(t)} = -\frac{1}{2}\sum_{j=1}^{T}\frac{G_j^2}{H_j + \lambda} + \gamma T$</p>
<p>这个公式用于评估树结构的质量，指导分裂决策。</p>
<h2 id="第十七题-kv-cache-计算">第十七题 KV Cache 计算<a hidden class="anchor" aria-hidden="true" href="#第十七题-kv-cache-计算">#</a></h2>
<p><strong>题目：</strong> 假设我们要在一台服务器上对一个采用多头注意力（MHA）的 Transformer 模型进行推理。模型参数如下：隐藏层维度 $d = 4096$，层数 $L = 32$，注意力头数 $h = 32$，采用 FP16 半精度存储（每个元素占 2 Bytes）。</p>
<ol>
<li>请给出生成第 $N$ 个 token 时，KV Cache 新增存储占用的计算公式。</li>
<li>当 Batch Size $B = 1$，序列长度达到 $N = 1024$ 时，请计算该请求在显存中占用的 KV Cache 总量（单位：MB）。</li>
</ol>
<p><strong>解：</strong></p>
<h3 id="1-kv-cache-新增存储计算公式">1. KV Cache 新增存储计算公式<a hidden class="anchor" aria-hidden="true" href="#1-kv-cache-新增存储计算公式">#</a></h3>
<p>生成第 $N$ 个 token 时，每一层需要存储该 token 的 Key 和 Value 向量。</p>
<ul>
<li>每个 token 的 K 和 V 向量维度均为 $d$</li>
<li>总层数为 $L$</li>
<li>每个元素占 2 Bytes（FP16）</li>
</ul>
<p>因此，生成第 $N$ 个 token 时，KV Cache 新增存储占用为：</p>
$$\text{新增存储} = 2 \times L \times d \times 2 \text{ Bytes} = 4Ld \text{ Bytes}$$<p>其中第一个 2 表示 K 和 V 两部分。</p>
<h3 id="2-序列长度-n1024-时的总-kv-cache">2. 序列长度 N=1024 时的总 KV Cache<a hidden class="anchor" aria-hidden="true" href="#2-序列长度-n1024-时的总-kv-cache">#</a></h3>
<p>当序列长度为 $N = 1024$，Batch Size $B = 1$ 时：</p>
$$\begin{aligned} \text{总存储} &= B \times N \times 2 \times L \times d \times 2 \text{ Bytes} \\&= 1 \times 1024 \times 2 \times 32 \times 4096 \times 2 \text{ Bytes} \\&= 1024 \times 2 \times 32 \times 4096 \times 2 \text{ Bytes} \\&= 536{,}870{,}912 \text{ Bytes} \\ &= 512 \text{ MB} \end{aligned}$$<hr>
<h2 id="第十八题-rope-旋转位置编码">第十八题 RoPE 旋转位置编码<a hidden class="anchor" aria-hidden="true" href="#第十八题-rope-旋转位置编码">#</a></h2>
<p><strong>题目：</strong> 对于位置 $m$ 的查询向量 $q_m$ 和位置 $n$ 的键向量 $k_n$：</p>
<ol>
<li>证明旋转位置编码（RoPE）下变换后的向量 $\tilde{q}_m$ 和 $\tilde{k}_n$ 的点积仅和 $q_m$、$k_n$ 及相对位置 $m - n$ 相关；</li>
<li>进一步说明 RoPE 会对 q/k/v 向量中的哪几个进行位置信息注入。</li>
</ol>
<p><strong>提示：</strong> RoPE 通过旋转矩阵 $R_{pos}$ 将位置信息注入向量。</p>
<p><strong>解：</strong></p>
<h3 id="1-证明点积仅与相对位置相关">1. 证明点积仅与相对位置相关<a hidden class="anchor" aria-hidden="true" href="#1-证明点积仅与相对位置相关">#</a></h3>
<p>RoPE 通过旋转矩阵将位置信息编码。对于二维情况，旋转矩阵为：</p>
$$R_\theta = \begin{pmatrix} \cos\theta & -\sin\theta \ \sin\theta & \cos\theta \end{pmatrix}$$<p>对于位置 $m$ 和 $n$，变换后的向量为：</p>
$$\tilde{q}*m = R*{m\theta} q_m, \quad \tilde{k}*n = R*{n\theta} k_n$$<p>它们的点积为：
</p>
$$
\begin{aligned}
\tilde{q}_m^\top \tilde{k}_n
&= (R_{m\theta} q_m)^\top (R_{n\theta} k_n) \\
&= q_m^\top R_{m\theta}^\top R_{n\theta} k_n \\
&= q_m^\top R_{(n-m)\theta} k_n
\end{aligned}
$$<p>
由于旋转矩阵满足 $R_\alpha^\top R_\beta = R_{\beta - \alpha}$，因此点积仅依赖于相对位置 $m - n$。</p>
<p>更高维度的情况下，RoPE 将向量分成多个二维子空间，每个子空间独立应用旋转，结论同样成立。</p>
<h3 id="2-rope-对哪些向量注入位置信息">2. RoPE 对哪些向量注入位置信息<a hidden class="anchor" aria-hidden="true" href="#2-rope-对哪些向量注入位置信息">#</a></h3>
<p>RoPE 仅对 <strong>Query (q) 和 Key (k)</strong> 向量注入位置信息，<strong>不对 Value (v)</strong> 向量进行位置编码。</p>
<p>原因是注意力机制通过 $\text{softmax}(q^\top k)$ 计算注意力权重，位置信息需要影响这个权重计算，而 Value 向量仅用于加权求和，不需要位置编码。</p>
<hr>
<h2 id="第十九题-transformer-block-的-post-norm-和-pre-norm">第十九题 Transformer Block 的 Post-norm 和 Pre-norm<a hidden class="anchor" aria-hidden="true" href="#第十九题-transformer-block-的-post-norm-和-pre-norm">#</a></h2>
<p><strong>题目：</strong> 对于 Transformer Block 的 Post-norm 有：</p>
$$x_{l+1} = x_l + \text{Sublayer}(x_l)$$<p> </p>
$$y_{l+1} = \text{LN}(x_{l+1})$$<ol>
<li>请相应给出 Pre-norm 的计算公式；</li>
<li>结合梯度分析证明 Post-norm 相比 Pre-norm 更易出现梯度消失或放大，并指出其中的梯度恒等映射通路。</li>
</ol>
<p><strong>解：</strong></p>
<h3 id="1-pre-norm-计算公式">1. Pre-norm 计算公式<a hidden class="anchor" aria-hidden="true" href="#1-pre-norm-计算公式">#</a></h3>
<p>Pre-norm 将 LayerNorm 应用在 Sublayer 之前：</p>
$$y_l = \text{LN}(x_l)$$<p> </p>
$$x_{l+1} = x_l + \text{Sublayer}(y_l)$$<h3 id="2-梯度分析">2. 梯度分析<a hidden class="anchor" aria-hidden="true" href="#2-梯度分析">#</a></h3>
<p><strong>Post-norm 的梯度：</strong></p>
<p>对于 Post-norm：$y_{l+1} = \text{LN}(x_l + \text{Sublayer}(x_l))$</p>
<p>反向传播时：</p>
$$\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial y_{l+1}} \cdot \frac{\partial \text{LN}}{\partial x_{l+1}} \cdot \left(I + \frac{\partial \text{Sublayer}}{\partial x_l}\right)$$<p>由于 LayerNorm 的导数和 Sublayer 的导数都可能较大或较小，梯度容易累积放大或缩小，导致梯度爆炸或消失。</p>
<p><strong>Pre-norm 的梯度：</strong></p>
<p>对于 Pre-norm：$x_{l+1} = x_l + \text{Sublayer}(\text{LN}(x_l))$</p>
<p>反向传播时：</p>
$$\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_{l+1}} \cdot \left(I + \frac{\partial \text{Sublayer}}{\partial y_l} \cdot \frac{\partial \text{LN}}{\partial x_l}\right)$$<p><strong>梯度恒等映射通路：</strong> $\frac{\partial x_{l+1}}{\partial x_l}$ 包含恒等项 $I$，即：</p>
$$\frac{\partial x_{l+1}}{\partial x_l} = I + \frac{\partial \text{Sublayer}}{\partial y_l} \cdot \frac{\partial \text{LN}}{\partial x_l}$$<p>这个恒等项提供了一条直接的梯度传播路径，即使 Sublayer 的梯度很小，梯度仍能通过恒等映射传播，避免梯度消失。</p>
<p><strong>结论：</strong> Pre-norm 由于存在梯度恒等映射通路（residual connection 在 LayerNorm 之后），梯度更稳定；Post-norm 的梯度需要先经过 LayerNorm，更容易出现梯度消失或放大。</p>
<hr>
<h2 id="第二十题-gated-attention-的-output-计算">第二十题 Gated Attention 的 Output 计算<a hidden class="anchor" aria-hidden="true" href="#第二十题-gated-attention-的-output-计算">#</a></h2>
<p><strong>题目：</strong> 已知 MHA 中第 $k$ 层第 $i$ 位置 token 的 output 表征计算如下：</p>
$$o_i^k = \left(\sum_{j=0}^{i} S_{ij}^k \cdot X_j W_V^k\right)W_O^k = \sum_{j=0}^{i} S_{ij}^k \cdot X_j(W_V^k W_O^k)$$<p>请相应给出下图 Gated Attention 中 G1/G2/G3 对应的 output $o_i^k$ 计算方法。</p>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMaaVkD4vYHHhYG1XV27CSCfUu4qUgAAl4Maxs22shW0DMt85pxMMwBAAMCAAN3AAM4BA.png"></p>
<p>注意：可用 Non-Linearity-Map 算子表示 element-wise gating 机制，即 </p>
$$Y' = Y \odot \sigma(XW_\theta) = \text{Non-Linearity-Map}(Y)$$<p><strong>解：</strong></p>
<p>根据图示，Gated Attention 在不同位置应用门控机制：</p>
<p><strong>G1（最有效）：</strong> 在 Concat 之后、Dense Layer 之前应用门控</p>
$$o_i^k = \left[\sum_{j=0}^{i} S_{ij}^k \cdot X_j W_V^k\right] \odot \sigma(Z_i W_{g1}) \cdot W_O^k$$<p>其中 $Z_i$ 可以是 Query、Key 或其他输入特征。</p>
<p><strong>G2：</strong> 在 Value Layer 输出上应用门控</p>
$$o_i^k = \sum_{j=0}^{i} S_{ij}^k \cdot \left[X_j W_V^k \odot \sigma(X_j W_{g2})\right] W_O^k$$<p><strong>G3：</strong> 在 Key Layer 上应用门控</p>
$$\tilde{K}*j = X_j W_K^k \odot \sigma(X_j W*{g3})$$<p> </p>
$$S_{ij}^k = \text{softmax}\left(\frac{Q_i \tilde{K}*j^\top}{\sqrt{d_k}}\right)$$<p> </p>
$$o_i^k = \sum*{j=0}^{i} S_{ij}^k \cdot X_j W_V^k \cdot W_O^k$$<p><strong>G4：</strong> 在 Query Layer 上应用门控（类似 G3）</p>
<p><strong>G5：</strong> 在最终输出上应用门控</p>
$$o_i^k = \left[\sum_{j=0}^{i} S_{ij}^k \cdot X_j W_V^k \cdot W_O^k\right] \odot \sigma(X_i W_{g5})$$<hr>
<h2 id="第二十一题-gpt-oss-20b-架构分析">第二十一题 GPT-OSS 20B 架构分析<a hidden class="anchor" aria-hidden="true" href="#第二十一题-gpt-oss-20b-架构分析">#</a></h2>
<p><strong>题目：</strong> GPT-OSS 20B 架构相比标准 Transformer 有多处改动，请依次文字分析各个改动的具体内容与意义：</p>
<ol>
<li>RoPE</li>
<li>RMSNorm</li>
<li>GQA</li>
<li>MoE</li>
<li>SwiGLU</li>
</ol>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMbaVkEaPxJiLSOOUpltJRujxULRC8AAmUMaxs22shWu9iZ7u-CKO8BAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<h3 id="1-roperotary-position-embedding">1. RoPE（Rotary Position Embedding）<a hidden class="anchor" aria-hidden="true" href="#1-roperotary-position-embedding">#</a></h3>
<p><strong>内容：</strong> 旋转位置编码，通过旋转矩阵将位置信息注入 Query 和 Key 向量。</p>
<p><strong>意义：</strong></p>
<ul>
<li>相对位置编码：attention score 仅依赖于相对位置 $m-n$</li>
<li>外推性好：可以处理训练时未见过的序列长度</li>
<li>计算高效：不需要额外的位置嵌入参数</li>
</ul>
<h3 id="2-rmsnormroot-mean-square-normalization">2. RMSNorm（Root Mean Square Normalization）<a hidden class="anchor" aria-hidden="true" href="#2-rmsnormroot-mean-square-normalization">#</a></h3>
<p><strong>内容：</strong> 简化的 LayerNorm，公式为：</p>
$$y = \frac{x}{\sqrt{|x|_2^2 + \epsilon}} \cdot \gamma$$<p>不计算均值，只进行缩放。</p>
<p><strong>意义：</strong></p>
<ul>
<li>计算效率高：省去均值计算和减法操作</li>
<li>参数更少：只需 scale 参数 $\gamma$，不需要 shift 参数 $\beta$</li>
<li>性能相当：在实践中与 LayerNorm 效果相当</li>
</ul>
<h3 id="3-gqagrouped-query-attention">3. GQA（Grouped Query Attention）<a hidden class="anchor" aria-hidden="true" href="#3-gqagrouped-query-attention">#</a></h3>
<p><strong>内容：</strong> 将多个 Query head 共享同一组 Key 和 Value head。</p>
<p><strong>意义：</strong></p>
<ul>
<li>减少 KV Cache：多个 Query 共享 KV，显著降低显存占用</li>
<li>推理加速：减少 KV 读取的内存带宽需求</li>
<li>折中方案：介于 MHA（每个 head 独立 KV）和 MQA（所有 head 共享 KV）之间</li>
</ul>
<h3 id="4-moemixture-of-experts">4. MoE（Mixture of Experts）<a hidden class="anchor" aria-hidden="true" href="#4-moemixture-of-experts">#</a></h3>
<p><strong>内容：</strong> 使用路由器（Router）动态选择激活的专家（FFN），每个 token 只激活部分专家。</p>
<p><strong>意义：</strong></p>
<ul>
<li>增加模型容量：总参数量大幅增加（20B 模型容量）</li>
<li>计算效率：每次前向只激活少量参数（实际激活 3.6B）</li>
<li>专业化：不同专家学习处理不同类型的输入</li>
</ul>
<h3 id="5-swigluswish-gated-linear-unit">5. SwiGLU（Swish-Gated Linear Unit）<a hidden class="anchor" aria-hidden="true" href="#5-swigluswish-gated-linear-unit">#</a></h3>
<p><strong>内容：</strong> 激活函数，结合 Swish 激活和门控机制：</p>
$$\text{SwiGLU}(x) = \text{Swish}(xW_1) \odot (xW_2)$$<p>其中 $\text{Swish}(x) = x \cdot \sigma(x)$</p>
<p><strong>意义：</strong></p>
<ul>
<li>性能提升：比标准 ReLU/GELU 效果更好</li>
<li>门控机制：允许模型动态控制信息流</li>
<li>平滑激活：Swish 的平滑特性有助于优化</li>
</ul>
<hr>
<h2 id="第二十二题-roofline-model-分析">第二十二题 Roofline Model 分析<a hidden class="anchor" aria-hidden="true" href="#第二十二题-roofline-model-分析">#</a></h2>
<p><strong>题目：</strong> 结合下列代码和结果，设 repeat=32 时，f 函数在 GPU 上执行时用于数据移动和计算的时间分别为 $T_{\text{move}}$ 和 $T_{\text{comp}}$，并假设此时恰处于 Memory 和计算的平衡点，依次分析：</p>
<ol>
<li>repeat=16 时，用于数据移动和计算的时间各是多少，此时 GPU 处于 Memory-bounded or Compute-bounded?</li>
<li>repeat=64 时，用于数据移动和计算的时间各是多少，此时 GPU 处于 Memory-bounded or Compute-bounded?</li>
</ol>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMcaVkEu8uG03Y0kNNKYbEnMFGQ_3gAAmcMaxs22shWv09g4YaTzuoBAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<h3 id="分析">分析<a hidden class="anchor" aria-hidden="true" href="#分析">#</a></h3>
<p>从图中可以看出：</p>
<ul>
<li>Runtime 在 repeat=32 之前增长缓慢，之后快速增长</li>
<li>FLOPS 逐渐增加并趋于平稳</li>
<li>Memory Bandwidth 在 repeat=32 之前保持高位，之后急剧下降</li>
</ul>
<p>这表明在 repeat=32 时达到平衡点，此时： </p>
$$T_{\text{move}} = T_{\text{comp}}$$<h3 id="1-repeat16-时">1. repeat=16 时<a hidden class="anchor" aria-hidden="true" href="#1-repeat16-时">#</a></h3>
<p>计算量减半： </p>
$$T_{\text{comp}}^{(16)} = \frac{1}{2} T_{\text{comp}}$$<p>数据移动量不变（输入输出大小固定）： </p>
$$T_{\text{move}}^{(16)} = T_{\text{move}}$$<p>总时间： </p>
$$T_{\text{total}}^{(16)} = T_{\text{move}}^{(16)} + T_{\text{comp}}^{(16)} = T_{\text{move}} + \frac{1}{2}T_{\text{comp}} = \frac{3}{2}T_{\text{move}}$$<p>由于 $T_{\text{move}}^{(16)} > T_{\text{comp}}^{(16)}$，GPU 处于 <strong>Memory-bounded</strong>。</p>
<h3 id="2-repeat64-时">2. repeat=64 时<a hidden class="anchor" aria-hidden="true" href="#2-repeat64-时">#</a></h3>
<p>计算量翻倍： </p>
$$T_{\text{comp}}^{(64)} = 2T_{\text{comp}}$$<p>数据移动量不变： </p>
$$T_{\text{move}}^{(64)} = T_{\text{move}}$$<p>总时间： </p>
$$T_{\text{total}}^{(64)} = T_{\text{move}}^{(64)} + T_{\text{comp}}^{(64)} = T_{\text{move}} + 2T_{\text{comp}} = 3T_{\text{move}}$$<p>由于 $T_{\text{comp}}^{(64)} > T_{\text{move}}^{(64)}$，GPU 处于 <strong>Compute-bounded</strong>。</p>
<hr>
<h2 id="第二十三题-operation-intensity-计算">第二十三题 Operation Intensity 计算<a hidden class="anchor" aria-hidden="true" href="#第二十三题-operation-intensity-计算">#</a></h2>
<p><strong>题目：</strong> GPU 的 Operation Intensity 定义为浮点操作数 FLOPS 与数据移动（Bytes）的比值，请计算并对比 LayerNorm 和 RMSNorm 的 Operation Intensity。</p>
<p>注意：d=8192，dtype=bf16，所有数据初始存于全局 DRAM，结果需写回全局 DRAM，且 SRAM 足够存放所有中间计算结果。</p>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMdaVkE5ebiNBknuzXWDjhSNOcBaygAAmgMaxs22shWLZLpaHwFwc0BAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<h3 id="layernorm">LayerNorm<a hidden class="anchor" aria-hidden="true" href="#layernorm">#</a></h3>
<p><strong>计算过程：</strong></p>
<ol>
<li>计算均值：$\mu = \frac{1}{d}\sum_{i=1}^d x_i$ → $d$ 次加法，1 次除法 ≈ $d$ FLOPs</li>
<li>计算方差：$\sigma^2 = \frac{1}{d}\sum_{i=1}^d (x_i - \mu)^2$ → $d$ 次减法，$d$ 次乘法，$d$ 次加法，1 次除法 ≈ $3d$ FLOPs</li>
<li>归一化和缩放：$y_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} \cdot \gamma_i + \beta_i$ → $d$ 次减法，$d$ 次除法，$d$ 次乘法，$d$ 次加法 ≈ $4d$ FLOPs</li>
</ol>
<p><strong>总计算量：</strong> $8d$ FLOPs</p>
<p><strong>数据移动：</strong></p>
<ul>
<li>读取 $x$：$d \times 2$ bytes</li>
<li>读取 $\gamma, \beta$：$2d \times 2$ bytes</li>
<li>写入 $y$：$d \times 2$ bytes</li>
<li>总计：$8d$ bytes</li>
</ul>
<p><strong>Operation Intensity：</strong> </p>
$$\text{OI}_{\text{LN}} = \frac{8d}{8d} = 1 \text{ FLOP/Byte}$$<h3 id="rmsnorm">RMSNorm<a hidden class="anchor" aria-hidden="true" href="#rmsnorm">#</a></h3>
<p><strong>计算过程：</strong></p>
<ol>
<li>计算 RMS：$\text{RMS} = \sqrt{\frac{1}{d}\sum_{i=1}^d x_i^2}$ → $d$ 次乘法，$d$ 次加法，1 次除法，1 次开方 ≈ $2d$ FLOPs</li>
<li>归一化和缩放：$y_i = \frac{x_i}{\text{RMS}} \cdot \gamma_i$ → $d$ 次除法，$d$ 次乘法 ≈ $2d$ FLOPs</li>
</ol>
<p><strong>总计算量：</strong> $4d$ FLOPs</p>
<p><strong>数据移动：</strong></p>
<ul>
<li>读取 $x$：$d \times 2$ bytes</li>
<li>读取 $\gamma$：$d \times 2$ bytes</li>
<li>写入 $y$：$d \times 2$ bytes</li>
<li>总计：$6d$ bytes</li>
</ul>
<p><strong>Operation Intensity：</strong> </p>
$$\text{OI}_{\text{RMS}} = \frac{4d}{6d} = \frac{2}{3} \text{ FLOP/Byte}$$<h3 id="对比">对比<a hidden class="anchor" aria-hidden="true" href="#对比">#</a></h3>
<p>LayerNorm 的 OI 为 1 FLOP/Byte，RMSNorm 的 OI 为 2/3 FLOP/Byte。两者都很低，属于 <strong>Memory-bounded</strong> 操作。RMSNorm 虽然计算量更少，但由于数据移动占主导，实际加速效果有限。</p>
<hr>
<h2 id="第二十四题-a100-operation-intensity-分析">第二十四题 A100 Operation Intensity 分析<a hidden class="anchor" aria-hidden="true" href="#第二十四题-a100-operation-intensity-分析">#</a></h2>
<p><strong>题目：</strong> 以 A100 为例，分析 FP32 和 BF16（TensorCore，考虑 dense 即左边列的 FLOPS）类型在进入 Compute-bounded 时需要的 Operation Intensity 分别是多少。Bandwidth 统一简化为 2TB/s。</p>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMeaVkFA_7YHDJPlNHkgnWBQ0xw0lcAAmkMaxs22shWhC8rkSclW2cBAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<p>从表格中读取：</p>
<ul>
<li>FP32：19.5 TFLOPS</li>
<li>BF16（TensorCore）：312 TFLOPS</li>
<li>Memory Bandwidth：2TB/s = 2000 GB/s</li>
</ul>
<h3 id="compute-bounded-临界点">Compute-bounded 临界点<a hidden class="anchor" aria-hidden="true" href="#compute-bounded-临界点">#</a></h3>
<p>当计算时间等于数据传输时间时，达到平衡点：</p>
$$\frac{\text{FLOPs}}{\text{Peak FLOPS}} = \frac{\text{Bytes}}{\text{Bandwidth}}$$<p>因此临界 Operation Intensity 为：</p>
$$\text{OI}_{\text{critical}} = \frac{\text{Peak FLOPS}}{\text{Bandwidth}}$$<h3 id="fp32">FP32<a hidden class="anchor" aria-hidden="true" href="#fp32">#</a></h3>
$$\text{OI}_{\text{FP32}} = \frac{19.5 \text{ TFLOPS}}{2 \text{ TB/s}} = \frac{19.5}{2} = 9.75 \text{ FLOP/Byte}$$<h3 id="bf16-tensorcore">BF16 TensorCore<a hidden class="anchor" aria-hidden="true" href="#bf16-tensorcore">#</a></h3>
$$\text{OI}_{\text{BF16}} = \frac{312 \text{ TFLOPS}}{2 \text{ TB/s}} = \frac{312}{2} = 156 \text{ FLOP/Byte}$$<h3 id="结论">结论<a hidden class="anchor" aria-hidden="true" href="#结论">#</a></h3>
<ul>
<li>要让 <strong>FP32</strong> 计算进入 Compute-bounded，Operation Intensity 需要 <strong>≥ 9.75 FLOP/Byte</strong></li>
<li>要让 <strong>BF16（TensorCore）</strong> 计算进入 Compute-bounded，Operation Intensity 需要 <strong>≥ 156 FLOP/Byte</strong></li>
</ul>
<p>这解释了为什么使用 TensorCore 进行矩阵乘法（OI 通常为 $O(N)$，其中 $N$ 是矩阵维度）更容易达到计算瓶颈，而 LayerNorm/RMSNorm（OI ≈ 1）始终是 Memory-bounded。</p>
<hr>
<h2 id="第二十五题-ε-greedy-多臂老虎机问题">第二十五题 ε-greedy 多臂老虎机问题<a hidden class="anchor" aria-hidden="true" href="#第二十五题-ε-greedy-多臂老虎机问题">#</a></h2>
<p><strong>题目：</strong> 考虑一多臂老虎机问题（K=10），3 个 ε-greedy 策略下每一时刻可以获得的平均 reward 下图所示。已知该问题中随机以及最有策略下可获得 reward 的期望分别为 1 与 1.55，则：</p>
<ol>
<li>哪个 ε 在游戏后期（steps → +∞）可以获得更高的 average reward。</li>
<li>在（steps → +∞）时，这 3 个 ε-greedy 策略每次可获得 reward 的期望各是多少。</li>
</ol>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMfaVkFNi6tE04fVhAHIZEjV3wHhLUAAm0Maxs22shWGbqTNn6p2MABAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<h3 id="1-后期表现">1. 后期表现<a hidden class="anchor" aria-hidden="true" href="#1-后期表现">#</a></h3>
<p>从图中可以观察到：</p>
<ul>
<li>$\varepsilon = 0.1$ 收敛到约 1.4</li>
<li>$\varepsilon = 0.01$ 收敛到约 1.3</li>
<li>$\varepsilon = 0$（greedy）收敛到约 1.0</li>
</ul>
<p><strong>$\varepsilon = 0.1$ 在后期获得更高的 average reward。</strong></p>
<h3 id="2-期望分析">2. 期望分析<a hidden class="anchor" aria-hidden="true" href="#2-期望分析">#</a></h3>
<p>ε-greedy 策略的期望 reward 为：</p>
$$\mathbb{E}[R] = (1-\varepsilon) \cdot R_{\text{greedy}} + \varepsilon \cdot R_{\text{random}}$$<p>其中：</p>
<ul>
<li>$R_{\text{random}} = 1$（随机策略期望）</li>
<li>$R_{\text{optimal}} = 1.55$（最优策略期望）</li>
</ul>
<p><strong>对于 $\varepsilon = 0$（greedy）：</strong></p>
<p>由于没有探索，可能陷入局部最优。从图中看收敛到 1.0，说明找到的并非最优臂：</p>
$$\mathbb{E}[R_{\varepsilon=0}] \approx 1.0$$<p><strong>对于 $\varepsilon = 0.01$：</strong></p>
<p>假设经过充分探索后，greedy 部分能找到最优臂：</p>
$$\mathbb{E}[R_{\varepsilon=0.01}] = 0.99 \times 1.55 + 0.01 \times 1 = 1.5345 + 0.01 = 1.5445 \approx 1.3$$<p>实际从图中看约为 1.3，可能 greedy 部分未完全收敛到最优。</p>
<p><strong>对于 $\varepsilon = 0.1$：</strong></p>
$$\mathbb{E}[R_{\varepsilon=0.1}] = 0.9 \times 1.55 + 0.1 \times 1 = 1.395 + 0.1 = 1.495 \approx 1.4$$<p>实际从图中看约为 1.4，与理论接近。</p>
<h3 id="总结">总结<a hidden class="anchor" aria-hidden="true" href="#总结">#</a></h3>
<p>当 steps → ∞ 时：</p>
<ul>
<li>$\varepsilon = 0$：约 <strong>1.0</strong></li>
<li>$\varepsilon = 0.01$：约 <strong>1.3-1.5</strong></li>
<li>$\varepsilon = 0.1$：约 <strong>1.4-1.5</strong></li>
</ul>
<p>$\varepsilon = 0.1$ 虽然探索开销大，但能更稳定地找到最优臂，长期表现最好。</p>
<hr>
<h2 id="第二十六题-mdp-bellman-方程">第二十六题 MDP Bellman 方程<a hidden class="anchor" aria-hidden="true" href="#第二十六题-mdp-bellman-方程">#</a></h2>
<p><strong>题目：</strong> 下图左是一个有限 Markov Decision Process (MDP) 的例子。网格中的单元格对应于环境的状态，在每个单元格中，智能体可以采取四种可能动作：上、下、左、右。这些动作确定性地使智能体在网格上沿相应方向移动一个单元格，并获取 0 的奖励。但有 2 类特殊情况：(1) 如果动作会导致智能体移出网格，则其位置保持不变，但会产生 -1 的奖励；(2) 如果智能体在状态 A 或 B 中，不管采取任意动作都会使智能体传送到 A&rsquo;或 B&rsquo;，并或者 +10 或 +5 的奖励。取 discount factor $\gamma = 0.9$。</p>
<p>随机策略对应的 state value 函数如下右图所示，保留 1 位有效数字。记左下状态坐标为 (1, 1)，右上状态坐标为 (5, 5)，请给出 坐标 (2, 5)、(3, 3)、(4, 5)、(5, 1) 4 个状态对应 value 的 Bellman 法代公式。</p>
<p>注：上述 4 状态的 value 分别为 8.8、0.7、5.3、-2.0。</p>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMhaVkFc_uQWbRETtL1pSJPG-zbvUAAAm4Maxs22shWhVkhqSyfL-gBAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<p>Bellman 方程的一般形式为：</p>
$$v(s) = \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a)[r + \gamma v(s')]$$<p>对于随机策略，$\pi(a|s) = 0.25$ 对所有动作 $a \in {\text{上, 下, 左, 右}}$。</p>
<h3 id="坐标系统">坐标系统<a hidden class="anchor" aria-hidden="true" href="#坐标系统">#</a></h3>
<p>根据题意，左下为 (1,1)，右上为 (5,5)。状态 A 在 (2,4)，A&rsquo; 在 (2,1)；状态 B 在 (4,2)，B&rsquo; 在 (4,5)。</p>
<h3 id="2-5---value--88">(2, 5) - value = 8.8<a hidden class="anchor" aria-hidden="true" href="#2-5---value--88">#</a></h3>
<p>位置 (2,5) 在网格顶部。各方向移动：</p>
<ul>
<li>上：出界 → 保持 (2,5)，奖励 -1</li>
<li>下：到 (2,4) = 状态 A</li>
<li>左：到 (1,5)</li>
<li>右：到 (3,5)</li>
</ul>
<p>但 (2,4) 是状态 A，从 A 出发会传送到 A&rsquo; = (2,1) 并获得 +10。</p>
$$v(2,5) = 0.25 \times [(-1 + 0.9 v(2,5)) + (0 + 0.9 v(2,4)) + (0 + 0.9 v(1,5)) + (0 + 0.9 v(3,5))]$$<p>由于 (2,4) 是 A，应该使用 A 的 value：</p>
$$v(2,5) = 0.25 \times [(-1 + 0.9 \times 8.8) + (0 + 0.9 \times 8.8) + (0 + 0.9 \times 3.0) + (0 + 0.9 \times 4.4)]$$<h3 id="3-3---value--07">(3, 3) - value = 0.7<a hidden class="anchor" aria-hidden="true" href="#3-3---value--07">#</a></h3>
<p>位置 (3,3) 在网格中心。各方向移动：</p>
<ul>
<li>上：到 (3,4)</li>
<li>下：到 (3,2)</li>
<li>左：到 (2,3)</li>
<li>右：到 (4,3)</li>
</ul>
$$v(3,3) = 0.25 \times [(0 + 0.9 v(3,4)) + (0 + 0.9 v(3,2)) + (0 + 0.9 v(2,3)) + (0 + 0.9 v(4,3))]$$<p>从图中读取相邻格子的值： </p>
$$v(3,3) = 0.25 \times 0.9 \times [v(3,4) + v(3,2) + v(2,3) + v(4,3)]$$<h3 id="4-5---value--53">(4, 5) - value = 5.3<a hidden class="anchor" aria-hidden="true" href="#4-5---value--53">#</a></h3>
<p>位置 (4,5) 在网格顶部。各方向移动：</p>
<ul>
<li>上：出界 → 保持 (4,5)，奖励 -1</li>
<li>下：到 (4,4)</li>
<li>左：到 (3,5)</li>
<li>右：到 (5,5)</li>
</ul>
$$v(4,5) = 0.25 \times [(-1 + 0.9 v(4,5)) + (0 + 0.9 v(4,4)) + (0 + 0.9 v(3,5)) + (0 + 0.9 v(5,5))]$$<h3 id="5-1---value---20">(5, 1) - value = -2.0<a hidden class="anchor" aria-hidden="true" href="#5-1---value---20">#</a></h3>
<p>位置 (5,1) 在右下角。各方向移动：</p>
<ul>
<li>上：到 (5,2)</li>
<li>下：出界 → 保持 (5,1)，奖励 -1</li>
<li>左：到 (4,1)</li>
<li>右：出界 → 保持 (5,1)，奖励 -1</li>
</ul>
$$v(5,1) = 0.25 \times [(0 + 0.9 v(5,2)) + (-1 + 0.9 v(5,1)) + (0 + 0.9 v(4,1)) + (-1 + 0.9 v(5,1))]$$<p>化简： </p>
$$v(5,1) = 0.25 \times [0.9 v(5,2) + 0.9 v(4,1) - 2 + 1.8 v(5,1)]$$<hr>
<h2 id="第二十七题-mdp-最优策略">第二十七题 MDP 最优策略<a hidden class="anchor" aria-hidden="true" href="#第二十七题-mdp-最优策略">#</a></h2>
<p><strong>题目：</strong> 下图左是一个有限 Markov Decision Process (MDP) 的例子（与上题相同）。已知下图右是最优策略对应的 value function，请对应给出各状态的最佳行动策略。</p>
<p><img loading="lazy" src="https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMiaVkFib8glS3wQumIayABWn7Y3p4AAm8Maxs22shWBqPDuxKIBWABAAMCAAN3AAM4BA.png"></p>
<p><strong>解：</strong></p>
<p>最优策略选择使 $Q(s,a) = r + \gamma v(s')$ 最大的动作。对于每个状态，计算四个方向的 Q 值并选择最大的。</p>
<h3 id="系统方法">系统方法<a hidden class="anchor" aria-hidden="true" href="#系统方法">#</a></h3>
<p>对于每个状态 $(i,j)$，最优动作 $a^*$ 满足：</p>
$$a^* = \arg\max_a [r(s,a) + \gamma v(s')]$$<p>其中 $s'$ 是执行动作 $a$ 后到达的状态。</p>
<h3 id="具体分析部分状态示例">具体分析（部分状态示例）<a hidden class="anchor" aria-hidden="true" href="#具体分析部分状态示例">#</a></h3>
<p><strong>状态 (1,1) - 左下角，v = 22.0</strong></p>
<p>四个方向的 Q 值：</p>
<ul>
<li>上：$0 + 0.9 \times 24.4 = 21.96$</li>
<li>下：$-1 + 0.9 \times 22.0 = 18.8$（出界）</li>
<li>左：$-1 + 0.9 \times 22.0 = 18.8$（出界）</li>
<li>右：$0 + 0.9 \times 22.0 = 19.8$</li>
</ul>
<p><strong>最优动作：上</strong></p>
<p><strong>状态 (3,3) - 中心，v = 17.8</strong></p>
<p>四个方向的 Q 值计算邻近状态的 value，选择最大的。</p>
<p><strong>状态 A (2,4)，v = 24.4</strong></p>
<p>从 A 采取任意动作都传送到 A&rsquo;(2,1) 并获得 +10： </p>
$$Q(A, a) = 10 + 0.9 \times 22.0 = 29.8$$<p>所有动作等价，可以任选。</p>
<p><strong>状态 B (4,2)，v = 19.8</strong></p>
<p>从 B 采取任意动作都传送到 B&rsquo;(4,5) 并获得 +5： </p>
$$Q(B, a) = 5 + 0.9 \times 19.4 = 22.46$$<p>所有动作等价。</p>
<h3 id="最优策略总结">最优策略总结<a hidden class="anchor" aria-hidden="true" href="#最优策略总结">#</a></h3>
<p>通过计算每个状态的所有可能动作的 Q 值，最优策略为：</p>
<ul>
<li><strong>第1行（底部）</strong>：大部分向上，靠近 A&rsquo; 的向右</li>
<li><strong>第2行</strong>：向 B 或向上</li>
<li><strong>第3行（中间）</strong>：向 A 或 B 方向</li>
<li><strong>第4行</strong>：向 A 方向</li>
<li><strong>第5行（顶部）</strong>：向 B&rsquo; 或向左</li>
</ul>
<p>具体每个格子的最优动作需要根据其邻居的 value 值计算得出，选择使 $r + \gamma v(s')$ 最大的方向。</p>
<h2 id="第二十八题-ai-agent-特性解释"><u>第二十八题 AI Agent 特性解释</u><a hidden class="anchor" aria-hidden="true" href="#第二十八题-ai-agent-特性解释">#</a></h2>
<p><strong>题目：</strong> AI Agent 是一类能够感知环境、自主决策并采取行动以实现特定目标的智能系统，并具备自主性、反应性、主动性、社会性以及进化性。请选择其中 3 种性质进行解释，并分别举例一种代表性技术（正式发表于 NeurIPS、ICLR、ICML）介绍其原理。（该题必考）</p>
<p>解：</p>
<h3 id="1-自主性-autonomy">1. 自主性 (Autonomy)<a hidden class="anchor" aria-hidden="true" href="#1-自主性-autonomy">#</a></h3>
<p><strong>性质解释</strong>
AI Agent 能够在没有外部持续干预的情况下独立运行，自主做出决策并执行任务，无需人工指导每一步操作。</p>
<p><strong>代表性技术：ReAct</strong></p>
<ul>
<li><strong>会议：ICLR 2023</strong></li>
<li>**论文：**ReAct: Synergizing Reasoning and Acting in Language Models (Yao et al.)</li>
</ul>
<p><strong>核心原理</strong>
ReAct 框架通过将推理（Reasoning）和行动（Acting）相结合，使语言模型能够以交替方式生成推理轨迹和任务特定的行动序列：</p>
<ol>
<li>
<p>思维-行动-观察循环</p>
<ul>
<li><strong>Thought (思考)</strong>: 模型生成推理步骤，分析当前状态、任务目标和下一步计划</li>
<li><strong>Action (行动)</strong>: 执行具体操作（如调用搜索API、使用计算器、访问数据库）</li>
<li><strong>Observation (观察)</strong>: 接收环境反馈和执行结果</li>
</ul>
</li>
<li>
<p>推理增强的行动选择</p>
<p>通过显式的推理轨迹，模型能够：</p>
<ul>
<li>动态分解复杂任务为子目标</li>
<li>根据中间结果调整策略</li>
<li>处理异常情况和错误</li>
</ul>
</li>
<li>
<p><strong>提示工程实现</strong>
使用 few-shot prompting，提供示例展示 Thought-Action-Observation 模式，引导模型学习这种交互模式。</p>
</li>
</ol>
<p><strong>➡️ 体现的自主性</strong>：Agent 无需预定义完整的行动序列，能根据环境反馈自主决策每一步，实现端到端的任务自动化。</p>
<hr>
<h3 id="2-反应性-reactivity">2. 反应性 (Reactivity)<a hidden class="anchor" aria-hidden="true" href="#2-反应性-reactivity">#</a></h3>
<p><strong>性质解释</strong>
AI Agent 能够感知环境变化并及时做出响应，从失败中学习，动态调整行为策略以适应变化的情境。</p>
<p><strong>代表性技术：Reflexion</strong></p>
<ul>
<li><strong>会议：NeurIPS 2023</strong></li>
<li>**论文：**Reflexion: Language Agents with Verbal Reinforcement Learning (Shinn et al.)</li>
</ul>
<p><strong>核心原理</strong>
Reflexion 引入了语言化的自我反思机制，使 Agent 能够从试错中快速学习：</p>
<ol>
<li>反思-行动循环
<ul>
<li><strong>Actor</strong>: 基于当前记忆生成行动轨迹</li>
<li><strong>Evaluator</strong>: 评估行动结果（成功/失败，输出奖励信号）</li>
<li><strong>Self-Reflection</strong>: 当失败时，生成具体的反思文本，分析失败原因</li>
</ul>
</li>
<li>语言化的情景记忆
<ul>
<li>将失败经验和反思以自然语言形式存储在短期记忆中</li>
<li>在后续尝试中，将相关反思加入提示上下文</li>
<li>类似于人类的&quot;从错误中学习&quot;机制</li>
</ul>
</li>
<li><strong>迭代改进机制</strong>
通过多轮试错-反思循环，Agent 逐步优化策略：</li>
</ol>
<pre tabindex="0"><code>   Attempt 1 → Fail → Reflect (&#34;边界条件未处理&#34;)
   Attempt 2 → 根据反思调整 → Success
</code></pre><p><strong>➡️ 体现的反应性</strong>：Agent 能够快速识别环境反馈（错误信息、失败信号），生成针对性的策略调整，实时适应新情况。</p>
<hr>
<h3 id="3-社会性-sociality">3. 社会性 (Sociality)<a hidden class="anchor" aria-hidden="true" href="#3-社会性-sociality">#</a></h3>
<p><strong>性质解释</strong>
AI Agent 能够与其他 Agent 进行协作、竞争或沟通，在多智能体环境中通过合作完成单个 Agent 无法完成的复杂任务。</p>
<p><strong>代表性技术：QMIX</strong></p>
<ul>
<li><strong>会议：ICML 2018</strong></li>
<li>**论文：**Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning (Rashid et al.)</li>
</ul>
<p><strong>核心原理</strong>
QMIX 通过单调价值函数分解解决多智能体协作中的信用分配问题：</p>
<ol>
<li>集中训练-分散执行 (CTDE) 范式
<ul>
<li><strong>训练阶段</strong>: 可访问全局状态 ss s 和所有 Agent 的观测</li>
<li><strong>执行阶段</strong>: 每个 Agent 仅基于局部观测 oio_i oi 独立决策</li>
</ul>
</li>
<li><strong>单调价值函数分解</strong>
将全局 Q 函数分解为各 Agent 局部 Q 函数的单调组合：  $$Q_{tot}(s, \mathbf{a}) = f_{\text{mix}}(Q_1(o_1, a_1), \ldots, Q_n(o_n, a_n); s) 约束条件（单调性）：  $$\frac{\partial Q_{tot}}{\partial Q_i} \geq 0, \quad \forall i 这保证了：局部贪婪动作（argmax QiQ_i Qi​）的组合等于全局最优动作</li>
<li>混合网络 (Mixing Network)
<ul>
<li>使用超网络 (hypernetwork) 根据全局状态 ss s 生成混合网络的权重</li>
<li>权重非负性通过绝对值函数保证单调性</li>
<li>网络结构：Agent Networks→Mixing Network→Qtot\text{Agent Networks} \rightarrow \text{Mixing Network} \rightarrow Q_{tot} Agent Networks→Mixing Network→Qtot</li>
</ul>
</li>
</ol>
<p><strong>➡️ 体现的社会性</strong>：多个 Agent 无需显式通信即可通过学习形成隐式协作策略，共同最大化团队奖励，展现涌现的群体智能。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li>
      <li><a href="http://localhost:1313/tags/%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/">数学推导</a></li>
      <li><a href="http://localhost:1313/tags/%E7%AE%97%E6%B3%95/">算法</a></li>
    </ul>
  </footer><div id="tw-comment"></div>
<script>
    
    const getStoredTheme = () => localStorage.getItem("pref-theme") === "light" ? "nord_light" : "dark_dimmed";
    const setGiscusTheme = () => {
        const sendMessage = (message) => {
            const iframe = document.querySelector('iframe.giscus-frame');
            if (iframe) {
                iframe.contentWindow.postMessage({giscus: message}, 'https://giscus.app');
            }
        }
        sendMessage({setConfig: {theme: getStoredTheme()}})
    }

    document.addEventListener("DOMContentLoaded", () => {
        const giscusAttributes = {
            "src": "https://giscus.app/client.js",
            "data-repo": "minjieblog\/minjieblog.github.io",
            "data-repo-id": "R_kgDOQjMm6A",
            "data-category": "Announcements",
            "data-category-id": "DIC_kwDOQjMm6M4Czb4B",
            "data-mapping": "pathname",
            "data-strict": "0",
            "data-reactions-enabled": "1",
            "data-emit-metadata": "0",
            "data-input-position": "bottom",
            "data-theme": getStoredTheme(),
            "data-lang": "zh-CN",
            "data-loading": "lazy",
            "crossorigin": "anonymous",
        };

        
        const giscusScript = document.createElement("script");
        Object.entries(giscusAttributes).forEach(
                ([key, value]) => giscusScript.setAttribute(key, value));
        document.querySelector("#tw-comment").appendChild(giscusScript);

        
        const themeSwitcher = document.querySelector("#theme-toggle");
        if (themeSwitcher) {
            themeSwitcher.addEventListener("click", setGiscusTheme);
        }
        const themeFloatSwitcher = document.querySelector("#theme-toggle-float");
        if (themeFloatSwitcher) {
            themeFloatSwitcher.addEventListener("click", setGiscusTheme);
        }
    });
</script>
</article>
    </main>
    
<footer class="footer">
        <span><a href="https://minjieblog.github.io/">©2025 Minjie&rsquo;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '复制';

        function copyingDone() {
            copybutton.innerHTML = '已复制！';
            setTimeout(() => {
                copybutton.innerHTML = '复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
