---
title: "数学基础算法篇"
date: 2025-12-21T15:50:54+08:00
draft: false
tags: ["算法", "哈希", "算法分析", "尾不等式", "数据流"]
categories: ["研究生课程"]
summary: |
    本笔记涵盖数学基础算法篇的完整内容，包括算法分析与相似度搜索、尾不等式及其应用、数据流算法（频繁元素检测、滑动窗口模型）、分布式数据流处理、哈希技术（布隆过滤器、LSH）、线性规划与整数规划、内存计算架构、社区发现算法以及子模函数应用等核心理论与实践。
description: |
    金老师主讲的研究生课程《数学基础算法篇》完整笔记，从算法分析基础开始，系统介绍相似度搜索、概率不等式、流式数据处理、分布式计算、哈希技术、优化算法、图算法等内容，理论与实践相结合，为解决大规模数据处理问题提供数学和算法基础。
comments: true
---

## 第一讲 算法分析

### 一、算法简介

算法分析是计算机科学的基础，用于评估算法的效率和资源消耗。

**算法复杂度分析：**
- **时间复杂度**：衡量算法执行时间随输入规模增长的趋势
- **空间复杂度**：衡量算法所需存储空间随输入规模增长的趋势
- **渐近分析**：O、Ω、Θ记号

**常见复杂度类型：**
- O(1)：常数时间
- O(log n)：对数时间
- O(n)：线性时间
- O(n log n)：线性对数时间
- O(n²)：平方时间
- O(2ⁿ)：指数时间

**算法设计范式：**
- 分治法（Divide and Conquer）
- 动态规划（Dynamic Programming）
- 贪心算法（Greedy Algorithm）
- 回溯法（Backtracking）
- 分支界定法（Branch and Bound）

### 二、相似度搜索

相似度搜索是在大规模数据中找到与查询对象相似的数据项。

**相似度度量：**
- **欧氏距离（Euclidean Distance）**：
  ```
  d(x, y) = √(Σ(xᵢ - yᵢ)²)
  ```
- **曼哈顿距离（Manhattan Distance）**：
  ```
  d(x, y) = Σ|xᵢ - yᵢ|
  ```
- **余弦相似度（Cosine Similarity）**：
  ```
  sim(x, y) = (x·y) / (||x|| ||y||)
  ```
- **Jaccard相似度**：
  ```
  J(A, B) = |A ∩ B| / |A ∪ B|
  ```

**应用场景：**
- 推荐系统
- 图像检索
- 文档相似度检测
- 近似最近邻搜索（ANN）

**朴素方法的局限：**
线性扫描的时间复杂度为O(n)，对于大规模数据集不可行。

### 三、高维空间的相似性搜索

在高维空间中，传统的索引结构（如KD树）性能退化严重，这被称为"维度灾难"。

**维度灾难（Curse of Dimensionality）：**
- 数据点之间的距离趋于相等
- 数据点趋向于分布在空间的"表面"
- 索引结构的效率降低

**解决方案：**

**1. 降维技术：**
- 主成分分析（PCA）
- 随机投影
- t-SNE

**2. 近似算法：**
- **局部敏感哈希（LSH）**：将相似的点以高概率映射到同一个桶
- **乘积量化（Product Quantization）**：将向量空间分解为子空间
- **HNSW（Hierarchical Navigable Small World）**：基于图的近似最近邻搜索

**LSH的基本原理：**
- 使用哈希函数族h，满足：相似的对象碰撞概率高，不相似的对象碰撞概率低
- 通过多个哈希函数和多个哈希表提高召回率
- 查询时只需检查哈希到同一桶的候选点

---

## 第二讲 尾不等式

### 一、尾不等式分析概要

尾不等式用于界定随机变量偏离其期望值的概率，在算法分析和概率算法设计中具有重要作用。

**为什么需要尾不等式：**
- 期望值只描述了平均情况
- 需要了解"坏情况"发生的概率
- 为随机算法提供性能保证

**应用领域：**
- 随机算法分析
- 负载均衡
- 哈希表性能分析
- 采样算法

### 二、三个常见的尾不等式

**1. Markov不等式（马尔可夫不等式）：**

对于非负随机变量X和a > 0：
```
P(X ≥ a) ≤ E[X] / a
```

**特点：**
- 只需要知道期望
- 界比较松
- 适用于任何非负随机变量

**2. Chebyshev不等式（切比雪夫不等式）：**

对于随机变量X，有：
```
P(|X - E[X]| ≥ a) ≤ Var(X) / a²
```

**特点：**
- 需要知道期望和方差
- 比Markov不等式更紧
- 不需要独立性假设

**3. Chernoff界（切尔诺夫界）：**

对于独立的随机变量X₁, X₂, ..., Xₙ ∈ [0,1]，令X = ΣXᵢ，μ = E[X]：
```
P(X ≥ (1+δ)μ) ≤ e^(-δ²μ/3)  (0 < δ ≤ 1)
P(X ≤ (1-δ)μ) ≤ e^(-δ²μ/2)  (0 < δ ≤ 1)
```

**特点：**
- 界最紧，指数级衰减
- 需要独立性假设
- 广泛应用于随机算法分析

### 三、计数问题

**问题描述：**
估计一个数据流中不同元素的个数（基数估计）。

**朴素方法的问题：**
- 存储所有元素需要O(n)空间
- 对于大规模数据流不可行

**概率计数算法：**

**Flajolet-Martin算法：**
1. 使用哈希函数h将元素映射到[0, 2^L-1]
2. 对每个元素计算其哈希值的尾部0的个数
3. 记录观察到的最大尾部0个数R
4. 估计值：2^R

**原理：**
- 如果有n个不同元素，期望看到log₂(n)个尾部0
- 使用多个哈希函数取平均值提高精度
- 空间复杂度：O(log log n)

**HyperLogLog算法：**
- Flajolet-Martin的改进版本
- 使用调和平均数代替算术平均数
- 精度更高，误差约为1.04/√m（m为桶数）
- 空间效率极高

---

## 第三讲 数据流

### 一、数据流模型

数据流模型描述了数据以流的形式到达，只能顺序访问一次或有限次的计算场景。

**数据流的特点：**
- 数据量巨大，无法全部存储
- 数据到达速度快，需要实时处理
- 只能进行一次或有限次扫描
- 需要在有限空间内近似计算

**典型应用：**
- 网络流量监控
- 金融交易分析
- 社交媒体数据处理
- IoT传感器数据

**数据流算法的目标：**
- 使用亚线性（sublinear）空间
- 提供可证明的近似保证
- 单次扫描或少量扫描

### 二、频繁元素-确定性算法

**问题定义：**
找出数据流中出现频率超过某个阈值的元素（heavy hitters）。

**Misra-Gries算法：**

**算法描述：**
1. 维护最多k个计数器
2. 对于每个到来的元素：
   - 如果已有计数器，增加其计数
   - 如果没有计数器且有空位，创建新计数器
   - 如果没有空位，所有计数器减1，删除值为0的计数器
3. 输出计数器中的元素

**性能保证：**
- 空间复杂度：O(k)
- 如果元素出现次数 > n/k，一定会被找到
- 可能有假阳性，但可以通过二次扫描验证

**应用：**
- 找出访问量最大的网页
- 检测网络中的大流量
- 识别热门话题

### 三、频繁元素-随机算法

**Count-Min Sketch算法：**

**数据结构：**
- d × w 的二维计数器数组
- d个独立的哈希函数h₁, h₂, ..., h_d

**算法操作：**

**更新（插入元素x）：**
```
对于 i = 1 到 d：
    count[i][hᵢ(x)] += 1
```

**查询（估计元素x的频率）：**
```
返回 min{count[i][hᵢ(x)] : i = 1..d}
```

**性能保证：**
- 空间复杂度：O(d × w)
- 误差界：ε·n (n为总元素数)，概率至少1-δ
- 选择w = ⌈e/ε⌉, d = ⌈ln(1/δ)⌉
- 只会高估，不会低估

**优势：**
- 空间效率高
- 支持点查询和范围查询
- 可以处理删除操作（使用带符号的计数）

### 四、滑动窗口模型

**问题描述：**
只关心最近W个元素的统计特性，更早的数据被丢弃。

**挑战：**
- 无法存储所有W个元素
- 需要及时更新统计信息

**DGIM算法（用于计数）：**

**基本思想：**
- 将窗口划分为桶（bucket）
- 每个桶代表一段连续的1
- 桶的大小是2的幂次
- 维护O(log W)个桶

**桶的性质：**
1. 每种大小的桶最多2个
2. 桶按时间戳排序
3. 最老的桶可能不完整

**查询操作：**
统计窗口内1的个数 ≈ 完整桶的大小之和 + 半个最老桶

**误差保证：**
- 相对误差：最多50%
- 可以通过增加每种大小桶的数量来降低误差

**应用扩展：**
- 滑动窗口中的平均值
- 滑动窗口中的中位数（近似）
- 滑动窗口中的distinct计数

---

## 第四讲 分布式数据流

### 一、分布式数据流模型

在分布式环境中，数据流分散在多个节点上，需要协调多个节点进行计算。

**系统架构：**
- **多个监测节点**：每个节点观察部分数据流
- **协调节点**：汇总和处理来自监测节点的信息
- **通信约束**：最小化节点间的通信量

**挑战：**
- 数据分散性
- 通信开销
- 同步问题
- 节点故障

**典型场景：**
- 分布式网络监控
- 多数据中心的日志分析
- 边缘计算
- CDN流量统计

### 二、聚集查询

**问题定义：**
计算分布在多个节点上的数据的聚集函数（如SUM、COUNT、AVG）。

**基本方法：**

**1. 连续聚集：**
- 每个节点维护本地的统计信息
- 周期性发送给协调节点
- 协调节点汇总计算全局结果

**2. 快照聚集：**
- 在特定时刻获取全局快照
- 需要处理同步问题
- 使用逻辑时钟或物理时钟

**优化技术：**

**采样与估计：**
- 不发送所有数据，只发送样本
- 使用统计方法估计全局结果
- 权衡精度和通信开销

**增量更新：**
- 只发送变化部分
- 减少冗余通信
- 适用于变化缓慢的数据

**数据结构支持：**
- 使用Count-Min Sketch等概要结构
- 可以在协调节点合并
- 支持分布式查询

### 三、topk监控

**问题定义：**
实时监控分布式系统中全局的top-k元素（如最热门的k个商品、最活跃的k个用户）。

**挑战：**
- 全局top-k可能不在任何单个节点的局部top-k中
- 需要在精度和通信量之间平衡
- 数据分布可能高度倾斜

**解决方案：**

**1. 阈值算法：**
- 协调节点维护全局top-k的阈值θ
- 每个节点报告超过θ的元素
- 动态调整θ以平衡通信量

**算法流程：**
```
初始化：θ = 0
循环：
  1. 每个节点报告频率 > θ 的元素
  2. 协调节点更新全局top-k
  3. 计算新阈值θ（如第k大元素的频率）
  4. 将θ广播给各节点
```

**2. 采样方法：**
- 各节点以概率p采样元素
- 上传采样的数据到协调节点
- 基于采样数据估计全局top-k

**3. 层次化监控：**
- 构建监控树
- 中间节点聚合子节点的信息
- 减少单点通信压力

**性能优化：**
- **局部过滤**：只上传可能进入全局top-k的元素
- **批量通信**：积累一定数量的更新后批量发送
- **缓存机制**：利用时间局部性减少通信

**实际应用：**
- 实时热搜榜
- 分布式缓存的热点识别
- 网络安全中的异常检测
- 广告系统的CTR监控

---

## 第五讲 哈希

### 一、哈希函数和哈希表

哈希技术是一种通过哈希函数将数据映射到固定大小的表中的方法，实现快速的数据存储和检索。

**核心概念：**
- **哈希函数**：将任意大小的数据映射到固定大小的值
- **哈希表**：基于数组实现的数据结构，通过哈希函数计算索引位置
- **冲突处理**：当不同的键映射到相同位置时的解决策略
  - 链地址法（Chaining）
  - 开放地址法（Open Addressing）

**时间复杂度：**
- 平均情况：O(1) 查找、插入、删除
- 最坏情况：O(n)（当所有元素都冲突时）

### 二、布隆过滤器（Bloom Filter）

布隆过滤器是一种空间高效的概率型数据结构，用于判断一个元素是否在集合中。

**特点：**
- 可能产生假阳性（False Positive）：说存在但实际不存在
- 不会产生假阴性（False Negative）：说不存在就一定不存在
- 不支持删除操作（标准版本）

**应用场景：**
- 网页URL去重
- 垃圾邮件过滤
- 缓存穿透防护
- 大数据去重

**工作原理：**
1. 使用k个不同的哈希函数
2. 将元素映射到位数组的k个位置
3. 查询时检查这k个位置是否都为1

### 三、最小哈希和LSH（Locality-Sensitive Hashing）

**最小哈希（MinHash）：**
用于估计两个集合的Jaccard相似度，常用于文档去重和相似度检测。

**局部敏感哈希（LSH）：**
一种降维技术，使得相似的数据项以高概率被映射到相同的桶中。

**应用：**
- 近似最近邻搜索
- 图像相似度检测
- 文本去重
- 推荐系统

---

## 第六讲 线性规划与整数规划

### 一、线性规划：单纯形算法

**线性规划问题标准形式：**
```
最大化/最小化：c^T x
约束条件：Ax ≤ b, x ≥ 0
```

**单纯形算法（Simplex Method）：**
- 由George Dantzig于1947年提出
- 从可行域的一个顶点出发
- 沿着目标函数值改进的方向移动到相邻顶点
- 直到找到最优解或判定无界

**算法步骤：**
1. 将问题转换为标准形式
2. 找到初始基本可行解
3. 检验数判断是否达到最优
4. 若未达到最优，选择入基变量和出基变量
5. 进行基变换，更新解
6. 重复步骤3-5直到最优

### 二、整数规划：问题定义

整数规划是线性规划的扩展，要求部分或全部变量取整数值。

**分类：**
- **纯整数规划**：所有变量都必须是整数
- **混合整数规划（MIP）**：部分变量是整数，部分是连续变量
- **0-1整数规划**：变量只能取0或1

**应用场景：**
- 资源分配
- 生产计划
- 网络设计
- 任务调度

### 三、整数规划：分支界定法（Branch and Bound）

**基本思想：**
将原问题分解为若干子问题，通过界定（bounding）技术减少搜索空间。

**算法流程：**
1. **松弛**：求解去掉整数约束的线性规划松弛问题
2. **界定**：用松弛问题的最优值作为上界（最大化问题）
3. **分支**：选择一个非整数变量进行分支
4. **剪枝**：
   - 当前节点的界不如已知最优解时剪枝
   - 松弛问题无可行解时剪枝
   - 松弛问题的解满足整数约束时更新最优解

### 四、整数规划：切平面法（Cutting Plane Method）

**核心思想：**
通过添加线性约束（切平面）逐步逼近整数规划的可行域，直到得到整数最优解。

**Gomory割平面：**
- 从单纯形表中推导出的割平面
- 切掉当前非整数最优解
- 不切掉任何整数可行解

**算法步骤：**
1. 求解线性规划松弛问题
2. 若解为整数，则为最优解，算法结束
3. 若解不为整数，生成割平面约束
4. 将割平面加入原问题
5. 重新求解并重复步骤2-4

---

## 第七讲 内存计算

### 一、海量内存概述

随着硬件技术的发展，单机内存容量已经可以达到TB级别，这为大数据处理带来了新的机遇。

**内存计算的优势：**
- **速度快**：内存访问速度比磁盘快3-5个数量级
- **延迟低**：避免了磁盘I/O的延迟
- **适合迭代计算**：机器学习、图计算等需要多次迭代的场景

**挑战：**
- 成本较高
- 数据持久化问题
- 容错机制

### 二、基于单机版内存增大优势

**单机大内存的应用场景：**
- 内存数据库（如Redis, Memcached）
- 实时数据分析
- 高性能缓存系统
- 图数据处理

**技术特点：**
- 简化系统架构，减少网络通信开销
- 提高数据处理的吞吐量
- 适合中等规模的数据集

**优化策略：**
- 数据结构优化（压缩、列式存储）
- NUMA-aware内存分配
- 大页内存（Huge Pages）的使用

### 三、基于共享式内存和分布式内存结合架构优势

**混合架构设计：**

**共享式内存（Shared Memory）：**
- 多个处理器共享同一物理内存空间
- 通信开销低
- 编程相对简单
- 可扩展性受限

**分布式内存（Distributed Memory）：**
- 每个节点有独立的内存空间
- 通过网络进行通信
- 可扩展性强
- 编程复杂度较高

**结合架构的优势：**
1. **弹性扩展**：根据数据规模动态调整资源
2. **负载均衡**：合理分配计算任务
3. **容错能力**：数据副本和快照机制
4. **性能优化**：本地内存访问 + 跨节点通信

**典型系统：**
- Apache Spark（基于RDD的内存计算框架）
- Apache Flink（流式和批处理统一计算）
- Alluxio（分布式内存文件系统）

### 四、总结

内存计算已成为大数据处理的重要技术方向：
- 针对不同场景选择合适的架构
- 平衡性能、成本和可扩展性
- 结合持久化存储保证数据安全
- 关注新硬件技术（如持久化内存）的发展

---

## 第八讲 社区发现

社区发现是复杂网络分析中的重要问题，目标是找出网络中紧密连接的节点群组。

### 一、图切割（Graph Partitioning）

**目标：**
将图分割成若干个子图，使得子图内部边多，子图之间边少。

**经典方法：**
- **最小割（Min-Cut）**：最小化切割边的数量
- **比率割（Ratio Cut）**：考虑社区大小的平衡
- **归一化割（Normalized Cut）**：考虑节点度数的归一化

**应用：**
- 社交网络分析
- 生物网络聚类
- 图像分割

### 二、边介数（Edge Betweenness）

**定义：**
边介数是指网络中所有最短路径中经过该边的路径数量。

**GN算法（Girvan-Newman）：**
1. 计算网络中所有边的介数
2. 移除介数最高的边
3. 重新计算边介数
4. 重复步骤2-3，直到达到期望的社区数量

**特点：**
- 能够发现层次化的社区结构
- 计算复杂度较高：O(m²n)
- 适用于小规模网络

### 三、模块度（Modularity）

**定义：**
模块度Q用于衡量网络社区划分的质量。

**公式：**
```
Q = (1/2m) Σ[Aᵢⱼ - (kᵢkⱼ/2m)]δ(cᵢ,cⱼ)
```

其中：
- m：边的总数
- Aᵢⱼ：邻接矩阵
- kᵢ：节点i的度
- δ(cᵢ,cⱼ)：节点i和j是否在同一社区

**特性：**
- Q值范围：[-0.5, 1]
- Q > 0.3通常表示有明显的社区结构
- 模块度最大化是NP困难问题

### 四、Louvain方法

Louvain算法是一种基于模块度优化的快速社区发现算法。

**算法步骤：**

**第一阶段（模块度优化）：**
1. 初始化：每个节点为一个独立社区
2. 遍历每个节点：
   - 尝试将该节点移动到邻居节点所在的社区
   - 计算模块度增益ΔQ
   - 选择使ΔQ最大且为正的移动
3. 重复步骤2直到模块度不再增加

**第二阶段（网络聚合）：**
1. 将同一社区的所有节点合并成一个超级节点
2. 社区间的边权重等于原节点间边权重之和
3. 对新网络重复第一阶段

**重复两个阶段直到模块度不再显著增加。**

**优势：**
- 时间复杂度：O(n log n)
- 能处理大规模网络（百万级节点）
- 能发现层次化社区结构
- 实现简单，效果好

**应用案例：**
- 社交网络社区检测
- 生物网络模块识别
- 知识图谱聚类

---

## 第九讲 子模函数及其应用

### 一、应用背景

子模函数在组合优化中有广泛应用，许多实际问题都具有子模性质。

**典型应用场景：**
- 信息传播最大化
- 传感器布置优化
- 文档摘要
- 特征选择
- 图像分割

### 二、子模函数（Submodular Function）

**定义：**
集合函数f: 2^V → ℝ 是子模的，如果对于任意A ⊆ B ⊆ V 和 x ∉ B，有：
```
f(A ∪ {x}) - f(A) ≥ f(B ∪ {x}) - f(B)
```

**直观理解：**
边际收益递减（Diminishing Returns）：向小集合添加元素的收益不小于向大集合添加相同元素的收益。

**常见子模函数：**
1. **覆盖函数**：f(S) = |∪ₛ∈S Cₛ|
2. **截断函数**：f(S) = min(|S|, k)
3. **图割函数**
4. **熵函数**

**性质：**
- 子模函数的非负线性组合仍是子模的
- 子模函数的最小化可以在多项式时间内精确求解
- 子模函数的最大化是NP困难的，但存在近似算法

### 三、集合覆盖问题（Set Cover Problem）

**问题定义：**
给定全集U和若干子集S₁, S₂, ..., Sₙ ⊆ U，找到最少数量的子集使其并集等于U。

**形式化：**
```
最小化：|S|
约束条件：∪ₛ∈S s = U
```

**复杂性：**
- NP困难问题
- 不存在常数因子近似算法（除非P=NP）

**贪心算法：**
1. 初始化：S = ∅, R = U（未覆盖元素）
2. 循环直到R = ∅：
   - 选择覆盖R中最多元素的集合s
   - S = S ∪ {s}
   - R = R \ s
3. 返回S

**性能保证：**
- 贪心算法的近似比：O(ln n)
- 这是可达到的最好近似比（在P≠NP假设下）

**子模性与贪心算法：**
集合覆盖函数f(S) = |∪ₛ∈S s|是子模的，对于单调子模函数最大化：
- 贪心算法保证(1 - 1/e)近似比
- 这个界是紧的

**实际应用：**
- **设施选址**：用最少的设施覆盖所有需求点
- **无线网络覆盖**：最小化基站数量
- **测试用例选择**：用最少的测试覆盖所有代码路径
- **特征选择**：选择最少的特征保持分类性能

**高级话题：**
- 加权集合覆盖
- 多目标集合覆盖
- 在线集合覆盖
- 分布式集合覆盖算法

---

## 课程总结

本课程系统地介绍了数学基础算法的核心内容，涵盖了从理论到实践的多个重要主题：

**基础理论部分（第1-2讲）：**
- **算法分析**为评估算法效率提供了数学工具，相似度搜索和高维空间技术是现代大数据应用的基础
- **尾不等式**提供了随机算法性能的概率保证，是设计和分析概率算法的重要理论基础

**数据流处理（第3-4讲）：**
- **数据流算法**解决了在有限空间内处理海量数据的问题，频繁元素检测和滑动窗口模型在实时系统中应用广泛
- **分布式数据流**扩展到多节点场景，聚集查询和top-k监控为大规模分布式系统提供了实用解决方案

**核心算法技术（第5-7讲）：**
- **哈希技术**为大规模数据的快速检索和去重提供了基础工具，布隆过滤器和LSH在实际应用中具有重要价值
- **线性规划与整数规划**是运筹优化的核心方法，单纯形算法、分支界定法和切平面法为求解复杂优化问题提供了理论基础
- **内存计算**代表了大数据处理的技术趋势，通过合理利用单机大内存和分布式架构可以显著提升计算性能

**图算法与优化（第8-9讲）：**
- **社区发现**算法帮助我们理解复杂网络的结构特征，Louvain方法在实践中表现出色
- **子模优化**为许多实际问题提供了理论保证的近似算法，贪心策略在子模函数优化中具有良好的性能保证

**核心思想总结：**
1. **近似与权衡**：在精确性和效率之间寻找平衡
2. **概率与随机化**：利用随机化技术突破确定性算法的局限
3. **分布式思维**：将算法扩展到大规模分布式环境
4. **理论保证**：为实际算法提供可证明的性能边界

这些算法和技术在实际应用中经常需要结合使用，深入理解其数学基础对于解决复杂的工程问题至关重要。掌握这些方法不仅能提升算法设计能力，更能在面对实际问题时选择合适的解决方案，在效率、精度和资源消耗之间做出明智的权衡。