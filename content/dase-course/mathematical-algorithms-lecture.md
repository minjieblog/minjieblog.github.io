---
title: "数学基础算法篇"
date: 2025-12-21T15:50:54+08:00
draft: false
tags: ["算法", "哈希", "算法分析", "尾不等式", "数据流"]
categories: ["研究生课程"]
summary: |
    本笔记涵盖数学基础算法篇的完整内容，包括算法分析与相似度搜索、尾不等式及其应用、数据流算法（频繁元素检测、滑动窗口模型）、分布式数据流处理、哈希技术（布隆过滤器、LSH）、线性规划与整数规划、内存计算架构、社区发现算法以及子模函数应用等核心理论与实践。
description: |
    金老师主讲的研究生课程《数学基础算法篇》完整笔记，从算法分析基础开始，系统介绍相似度搜索、概率不等式、流式数据处理、分布式计算、哈希技术、优化算法、图算法等内容，理论与实践相结合，为解决大规模数据处理问题提供数学和算法基础。
comments: true
---

## 第一讲 算法分析

### 一、算法简介

#### 1. 算法和效率

**算法定义：**

- 任何良定义的计算过程，该过程取某个值或者值的集合作为输入，并产生某个值或值的集合作为输出
- 把输入转换成输出的计算步骤的一个序列

**算法的应用场景：**

- 生物基因分析
- 互联网海量数据管理
- 电子商/务
- 高速路由器上的IP包分析（频数统计、Top-k查询、范围查询、中位数、平均数+方差等）

**效率分析：**

- 求解相同问题的不同算法的效率可能具有显著的差异
- 性能可以用曲线来表达
- 插入排序：$c_1n^2$ vs 归并排序：$c_2n \log n$
- 尽管 $c_1$ 通常小于 $c_2$，但当 $n$ 增长时，最终插入排序的开销更大

**案例：** 快机器A（100亿条指令/秒）执行插入排序（$2n^2$ 条指令）vs 慢机器B（1000万条指令/秒）执行归并排序（$50n \log n$ 条指令），当n足够大时，B机器反而更快

**渐进性能：** 考虑当n足够大时的复杂度，当n足够大时，$\Theta(n^2)$ 算法总是优于 $\Theta(n^3)$ 算法

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM4aV2-Y_nSPP3RnBaJomSa9IW30u8AAj8LaxtLRfBWeIy-Mi1mMe8BAAMCAAN3AAM4BA.png)

#### 2. 渐进符号表示

**O-记号（"big-Oh"，渐近上界）：**

- $f(n) = O(g(n))$ if $\exists$ 常数 $c, n_0$，满足 $0 \leq f(n) \leq cg(n), \forall n \geq n_0$
- 案例：$2n^2 = O(n^3)$ ($c=1, n_0=2$)
- 集合形式：$O(g(n)) = \{f(n): \exists \text{ 常数 } c, n_0，\text{满足 } 0 \leq f(n) \leq cg(n), \forall n \geq n_0\}$

**Ω-记号（渐进下界）：**

- $\Omega(g(n)) = \{f(n): \exists \text{ 常数 } c, n_0，\text{使得 } 0 \leq cg(n) \leq f(n), \forall n \geq n_0\}$

**Θ-记号（渐进紧确界）：**

- $\Theta(g(n)) = \{f(n): \exists \text{ 常数 } c_1, c_2, n_0，\text{满足 } 0 \leq c_1g(n) \leq f(n) \leq c_2g(n), \forall n \geq n_0\}$

**o-记号（非渐近紧确的上界）：**

- $o(g(n)) = \{f(n): \text{对任意正常数 } c > 0，\text{存在常数 } n_0，\text{使得对所有 } n \geq n_0，\text{有 } 0 \leq f(n) < cg(n)\}$

**ω-记号（非渐近紧确的下界）：**

- $\omega(g(n)) = \{f(n): \text{对任意正常数 } c > 0，\text{存在常数 } n_0，\text{使得对所有 } n \geq n_0，\text{有 } 0 \leq cg(n) < f(n)\}$

**三种分析类型：**

- **最坏情况（通常使用）：** $T(n)$ = 对于任意规模n的输入数据，算法的最大运行时间
- **平均情况（有时使用）：** $T(n)$ = 对于规模为n的所有输入情况，算法的期望运行时间（假设已知输入数据的统计分布）
- **最佳情况（虚构的）：** 所有输入系列之中，运行时间最快的情况下的运行时间

**思考题1：紧确界Θ和下界Ω、上界O之间的关系如何？**

**解答：**

三者关系可以类比于数学中的等号、大于等于号和小于等于号：

- **紧确界 $\Theta$**：$f(n) = \Theta(g(n))$ 意味着 $f(n)$ 的增长率与 $g(n)$ 相同，即 $f(n)$ 被 $g(n)$ 从上下两边同时夹住。当且仅当 $f(n) = O(g(n))$ 且 $f(n) = \Omega(g(n))$ 时，$f(n) = \Theta(g(n))$。

- **上界 $O$**：$f(n) = O(g(n))$ 意味着 $f(n)$ 的增长率不快于 $g(n)$，$g(n)$ 是 $f(n)$ 的渐近上界。

- **下界 $\Omega$**：$f(n) = \Omega(g(n))$ 意味着 $f(n)$ 的增长率不慢于 $g(n)$，$g(n)$ 是 $f(n)$ 的渐近下界。

**关系总结：**
$$\Theta(g(n)) = O(g(n)) \cap \Omega(g(n))$$

这说明紧确界是上界和下界的交集，表示函数的精确增长率。

#### 3. 算法设计基本方法

**分治策略：**

- 将原始问题拆分成若干个相似的（规模更小）子问题
- 递归求解子问题
- 组合子问题的解，以产生最终答案

**动态规划：**

- 通常用于解决最优化问题，通过做出一组选择来达到最优解
- 在做出每个选择的同时，通常会生成与原问题形式相同的子问题
- 关键在于保存每个此类子问题的解，当其重复出现时即可避免重复求解
- 有时可以将指数时间的算法转换为多项式时间的算法

**贪心算法：**

- 基本思路是使用局部最优解来求得全局最优解
- 但是，贪心算法并不总是针对所有问题获得最优解
- 关键是需要知道如何正确区分适用场景

**思考题2：快速排序算法的渐进复杂度应该如何表示？**

**解答：**

快速排序的复杂度表示取决于分析的角度：

- **最坏情况**：$O(n^2)$ - 当每次划分都极度不平衡时（如数组已排序或逆序），每次只能减少一个元素，导致递归深度为 $n$。

- **平均情况**：$\Theta(n \log n)$ - 在随机输入或随机化快速排序中，平均情况下划分比较均衡，递归树深度为 $O(\log n)$。

- **最佳情况**：$\Theta(n \log n)$ - 每次划分都完全平衡时，递归树深度为 $\log n$。

**实践中的表示：**
快速排序通常被描述为平均时间复杂度 $\Theta(n \log n)$，最坏情况 $O(n^2)$。通过随机化技术（随机选择主元），可以使最坏情况的概率极低，因此实际应用中快速排序表现优异。

**思考题3：请各说出两种算法，分别是根据分治策略、动态规划、贪心算法设计得来的。**

**解答：**

**分治策略算法：**
1. **归并排序（Merge Sort）**：将数组分成两半，递归排序后合并。时间复杂度 $\Theta(n \log n)$。
2. **快速排序（Quick Sort）**：选择主元划分数组，递归排序左右两部分。平均时间复杂度 $\Theta(n \log n)$。

**动态规划算法：**
1. **最长公共子序列（LCS）**：通过保存子问题的解（二维表格）避免重复计算。时间复杂度 $O(mn)$。
2. **背包问题（Knapsack Problem）**：使用表格记录不同容量和物品数量下的最优解。时间复杂度 $O(nW)$，其中 $n$ 是物品数，$W$ 是背包容量。

**贪心算法：**
1. **Huffman编码**：根据字符频率构建最优前缀编码树，每次选择频率最小的两个节点合并。
2. **Dijkstra最短路径算法**：每次选择距离源点最近的未访问节点，更新其邻居的距离。时间复杂度 $O((V+E) \log V)$（使用优先队列）。

#### 4. 摊还分析

**应用场景：**

- 用含n个操作的序列 $(o_1, o_2, \ldots, o_n)$ 维护某数据结构
- 操作代价：单次操作的代价可能会很大（例如 $\Theta(n)$），最坏情况下的代价 = $\max c(o_i)$
- 总代价：$\sum_{i=1}^{n} c_i$，总代价未必就是 $n \times$ (最坏情况下的单次操作代价)
- 摊还代价：在上述场景下如何做更紧的分析？（总代价$/n$）

**三种典型技术：**

1. **聚合分析：** 计算所有操作的总和开销，再除以操作个数，就是平均开销

2. **核算法：** 赋予一个操作的费用，称为它的摊还代价。当一个操作的摊还代价超出其实际代价时，差额部分存入数据结构中的特定对象，存入的差额称为信用。对于后续操作中摊还代价小于实际代价的情况，信用可以用于支付差额。需要确保操作序列的总摊还代价是序列总真实代价的上界。

3. **势能法：** 将势能与整个数据结构相关联，而不是特定对象相关联。将势能释放即可用于支付未来操作的代价。公式：摊余成本 = 真实开销 + 新势能 - 旧势能

### 二、相似度搜索

#### 1. 相似性搜索简介

**问题定义：**

给定一个查询对象（query object），在大规模图像集合中定位相似的图像。

**核心思想：**

- 将图像从**图像空间（image space）**转换到**特征空间（feature space）**
- 每张图像可以表示为 $d$ 维特征向量
- 在特征空间中寻找离查询对象最近的点，即其**最近邻居（nearest neighbour, NN）**

**距离度量：**

在 $d$ 维特征空间中，两点 $p = (p_1, p_2, \ldots, p_d)$ 和 $q = (q_1, q_2, \ldots, q_d)$ 之间的距离常用欧氏距离：

$$d(p, q) = \sqrt{\sum_{i=1}^{d} (p_i - q_i)^2}$$

**最近邻搜索（NN Search）：**

给定查询点 $q$ 和数据集 $S$，找到 $p \in S$ 使得：

$$p = \arg\min_{x \in S} d(q, x)$$

其中，NN-dist 表示查询点到最近邻的距离。

------

#### 2. 一维空间索引方法

**(1) 二叉搜索树（Binary Search Tree, BST）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM5aV3Fa9zU3VWFcRCCqmN8l2-Ml5UAAkgLaxtLRfBWEN7haJ8zR-4BAAMCAAN3AAM4BA.png)

**特点：**

- 左子树节点值 < 根节点值 < 右子树节点值
- 搜索时间复杂度：平均 $O(\log n)$，**最坏 $O(n)$（退化为链表）**

**不平衡的二叉搜索树：**

- 当插入顺序不当时，树会退化成链表结构
- 例如：依次插入 5, 10, 15, 20, 25, 22 会形成右偏树
- 搜索效率降低到 $O(n)$

**(2) 红黑树（Red-Black Tree）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM6aV3FtfZXv1QLPd0_73xlosMYIA8AAkoLaxtLRfBWQtwtzMw5E2kBAAMCAAN3AAM4BA.png)

**定义：** 一种自平衡的二叉搜索树，通过节点染色（红色/黑色）和旋转操作保持平衡。

**性质：**

1. 每个节点是红色或黑色
2. 根节点是黑色
3. 所有叶子节点（NIL/null）是黑色
4. 红色节点的两个子节点都是黑色（不能有两个连续的红色节点）
5. 从任一节点到其每个叶子的所有路径都包含**相同数目的黑色节点**

**性能：**

- 搜索、插入、删除时间复杂度：$O(\log n)$
- 保证最长路径不超过最短路径的2倍

**(3) B树（B-Tree）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM7aV3GPw3Qewy7fROAG7yxzaXfwZ8AAksLaxtLRfBWb6_kWo_PDuIBAAMCAAN3AAM4BA.png)

**特点：**

- 多路平衡搜索树，适合**磁盘存储**
- 每个节点可以有多个键值和子节点
- 所有叶子节点在同一层

**结构组成：**

- **键值（key）**：即索引中记录的主键
- **指针（pointer）**：存储子节点地址的信息
- **数据（data）**：即索引记录中除主键外的数据

**性能：**

- 搜索、插入、删除时间复杂度：$O(\log_m n)$，其中 $m$ 是节点的最大子节点数
- 减少磁盘I/O次数

**(4) B+树（B+ Tree）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM8aV3GdhGx_8924HQZERFbIS6enpQAAk4LaxtLRfBWYmUJe3xEX5QBAAMCAAN3AAM4BA.png)

**特点：**

- B树的变体，数据库索引的常用结构
- **所有数据都存储在叶子节点**
- 非叶子节点只存储键值和指针，不存储数据
- 叶子节点之间通过指针连接，形成有序链表

**优势：**

1. 更高的扇出（fan-out），减少树的高度
2. 叶子节点的链表结构便于范围查询
3. 非叶子节点不存储数据，可以在内存中**缓存更多索引项**

**性能：**

- 搜索时间复杂度：$O(\log_m n)$
- 范围查询效率：$O(\log_m n + k)$，其中 $k$ 是返回的记录数

------

#### 3. 多维空间索引方法

**(1) R树（R-Tree）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM9aV3HCZtWsfQpkPErNyHQSsum2BwAAk8LaxtLRfBWnG_mVZglRE8BAAMCAAN3AAM4BA.png)

**定义：** R树是一种用于空间数据索引的树状数据结构，特别适合处理多维空间对象（如矩形、多边形等）。

**核心思想：**

- 用**最小边界矩形（MBR, Minimum Bounding Rectangle）**近似表示空间对象
- 构建层次化的MBR树结构
- 父节点的MBR包含其所有子节点的MBR

**结构特点：**

- 叶子节点：存储实际的空间对象及其MBR
- 非叶子节点：存储子节点的MBR
- 同一层的MBR可能重叠

**应用场景：**

- 地理信息系统（GIS）
- 计算机辅助设计（CAD）
- 空间数据库

**(2) 空间填充曲线（Space-Filling Curves）**

**基本思想：** 通过连续曲线遍历多维空间中的所有点，将多维空间映射到一维空间，从而可以使用一维索引方法。

**1. Z曲线（Z-order Curve / Morton Curve）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM-aV3H4RbQP_0jaJW9j-OpHEAWpjIAAlALaxtLRfBWCOJIBqgmnVQBAAMCAAN3AAM4BA.png)

**特点：**

- 也称为Morton码
- 通过交叉组合坐标的二进制位来编码
- 编码方式：对于二维点 $(x, y)$，交替取 $x$ 和 $y$ 的**二进制位**

**编码示例（2维）：**

1阶Z曲线（$2 \times 2$ 网格）

- 编号顺序: 0 → 1 → 2 → 3
- 形状: Z字形

2阶Z曲线（$4 \times 4$ 网格）：

- 编号: 00 → 01 → 02 → 03 → ... → 30 → 31 → 32 → 33 （二阶其实就是又多了一个符号位，对4个$2 \times 2$的网格进行再次编号$0,1,2,3$）
- 每个$2 \times 2$子区域内部按Z字形连接

**优点：**

- 编码简单，计算效率高
- 空间局部性较好

**缺点：**

- 曲线不连续，存在跳跃
- 局部性保持不如Hilbert曲线

**2. Hilbert曲线（Hilbert Curve）**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM_aV3Ko-ZlQ23bwJB9CQNjy8u_15UAAlcLaxtLRfBW2zNx8ZQjGA8BAAMCAAN3AAM4BA.png)

**特点：**

- 连续的分形曲线
- 更好地保持空间局部性
- 相邻的曲线位置对应相邻的空间位置

**递归构造：**

- 1阶Hilbert曲线：连接$2 \times 2$网格中的4个点
- $n$阶Hilbert曲线：将空间分为4个象限，每个象限是上一阶的曲线，起点经过**顺时针旋转$90^\circ$**后连接起来

**优点：**

- 更好的聚类性：空间上接近的点在曲线上也接近
- 曲线连续，无跳跃

**缺点：**

- 编码计算相对复杂
- 生成算法复杂度较高

**性能比较：**

| 特性       | Z曲线  | Hilbert曲线 |
| ---------- | ------ | ----------- |
| 计算复杂度 | 低     | 中          |
| 空间局部性 | 较好   | 优秀        |
| 连续性     | 不连续 | 连续        |
| 聚类效果   | 一般   | 优秀        |

------

#### 4. 四叉树索引（Quadtree Index）

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANAaV3OXaoV67hYOz0vkGu_nCYRhU8AAmYLaxtLRfBWZb0oHyXRF1QBAAMCAAN3AAM4BA.png)

**(1) 定义与构造方法**

**核心思想：** 递归地将二维空间分割成四个相等的象限，直到每个区域满足特定条件。

**构造方法：**

1. 将整个数据空间分割成四个相等的矩形，分别对应：
   - 西北（NW, Northwest）
   - 东北（NE, Northeast）
   - 西南（SW, Southwest）
   - 东南（SE, Southeast）
2. 若每个象限内包含的要素不超过给定的**桶量（bucket size）**则停止
3. 否则对超过桶量的矩形按照同样的方法进行划分
4. 直到桶量满足要求或者不再减少为止，最终形成一颗有层次的四叉树

**(2) 优缺点分析**

**优点：**

1. 一定程度上实现了地理要素真正被网格分割
2. 保证了桶内要素不超过某个量，提高了检索效率

**缺点：**

1. 对于海量数据，四叉树的**深度会很深**，影响查询效率
2. **可扩展性**不如网格索引：
   - 当扩大区域时，需要重新划分空间区域，重建四叉树
   - 当增加或删除一个对象，可能导致深度加一或减一
   - 叶节点也有可能重新定位

------

#### 5. 网格索引（Grid Index）

**（1） 基本思想**

将研究区域用横竖线划分成**大小相等或不等的网格**，每个网格可视为一个**桶（bucket）**。

**索引构建：**

1. 将空间划分为大小相等或不等的网格
2. 记录落入每一个网格区域内的空间**实体编号**
3. 建立网格号到对象列表的映射（**倒排索引**）

**查询过程：**

1. 先计算出查询对象所在**网格**
2. 再在该网格中快速查询所选空间实体

**（2） 倒排索引示例**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANBaV3WhNTjWU5Q231j1yYnWNwuPKkAAnULaxtLRfBWM7cBp-F-SAsBAAMCAAN3AAM4BA.png)

**案例**： 有三个制图物体：一条河流，一个湖泊，一条省界，关键字分别是 5, 11 和 23。

**对象-网格映射**

- 河流（ID=5）穿过的栅格：2, 34, 35, 67, 68
- 湖泊（ID=11）覆盖的栅格：68, 69, 100, 101
- 省界（ID=23）通过的栅格：5, 37, 36, 35, 67, 99, 98, 97

**查询示例**

- 查询网格68：返回 [5, 11]（河流和湖泊）
- 查询网格35：返回 [5, 23]（河流和省界）

**（3） 优缺点分析**

**优点**

1. **简单**：实现容易，概念直观
2. **易于实现**：数据结构简单，编码量少

**缺点**：网格大小影响检索性能

### 三、高维空间的相似性搜索

#### 1. 高维空间的特性

**(1) 维度灾难问题**

**问题引入：** 在各维度上划分原始空间，生成若干个子空间，再将各点划至各子空间内。

- **低维空间**（2维或3维）：容易理解，且较为合理

- 高维空间

  （例如100维）：

  - 将会产生 $2^{100} = 10^{30}$ 个子空间
  - 几乎所有子空间都是空的

**(2) 超立方体特性**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANCaV3cyWdrUwh_tZTRtU5qRSjNAjkAApkLaxtLRfBWOE1dSBTD8IMBAAMCAAN5AAM4BA.png)

考虑超立方体，其边长为 0.95。

**2维情况：**

- 任意点在此子空间内的概率：$0.95^2 ≈ 0.90$

**100维情况：**

- 任意点在此子空间内的概率：$0.95^{100} ≈ 0.0059$

**结论：** 随着维度增加，点落在中心区域的概率急剧下降。

**(3) 超球体特性**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANDaV3c_hjXDSrlmkfaaS25KycAAXrZAAKaC2sbS0XwVregKYSG_Io5AQADAgADeQADOAQ.png)

考虑最大的超球（内切于单位立方体）。

**2维空间：**

- 超球的体积为 $\pi/4 = 0.785$

**40维空间：**

- 超球的体积为 $3.278 × 10^{-21}$

**关键发现：**

- 显然，主要空间都在边边角角上
- 至少需要 $3 × 10^{20}$ 个点，才可期望在超球内部至少有一个点

------

#### 2. 访问概率

**(1) 问题定义**

**核心问题：** 给定任一查询，某个特定区域必定会被检索到的概率是多少？

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANEaV3dhFyq49zuTxISmTvNuKry6CkAAqkLaxtLRfBWYkR9SbeMMMwBAAMCAAN3AAM4BA.png)

**(2) 访问规则**

**重要性质：** 如果右边的区域先被访问，左边的也必须被访问到。这意味着在高维空间中，查询半径内的区域访问具有传递性。

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANFaV3d35kygJpiwCdie69K0dV5tMAAArcLaxtLRfBW3FTE9lC5dYcBAAMCAAN5AAM4BA.png)

**(3) 实验结果**

**不同区域形状的访问概率：**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANGaV3eBzW92f--UYVRub991bQJohoAArgLaxtLRfBW6SI5TCuK4U0BAAMCAAN3AAM4BA.png)

**结论：** 在维度增加到30-50维时，每个区域被访问到的概率极高。

**含义：** 在高维空间中，传统的空间划分索引方法失效，因为几乎所有区域都需要被访问。

------

#### 3. 签名文件（Signature Files）

**(1) 设计思路**

**核心理念：**

- 原始数据规模大、处理难度高
- 针对原始数据对象分别构建**小规模的签名数据**
- 这些数据能够以**过滤器**的角色支持谓词查询

**(2) 工作流程**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANHaV3ehqo-kf54S8CSU7bjh8SRj4MAAusLaxtLRfBWTat-WpKazN4BAAMCAAN5AAM4BA.png)

**处理步骤：**

1. 使用**哈希函数**将原始数据映射为签名
2. **签名文件**作为第一层过滤器
3. 只有通过**过滤的数据**才访问原始数据

**优势：**

- 签名文件体积小，可以快速扫描
- 减少对原始数据的访问次数
- 适合作为预处理层

------

#### 4. 向量近似文件（VA-File）

**(1) 算法概述**

**来源：** VLDB 1998

**基本思想：**

- 通过 **approximation（近似）**方式创建 VA-File 作为 Filter
- 先过滤大部分不可能的候选点
- 只对可能的候选点计算精确距离

**(2) 数据结构**

**空间划分：**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANIaV3fLuSGmen8wqK_2e7_YdCYp6EAAuwLaxtLRfBW1EmXxEU43mwBAAMCAAN3AAM4BA.png)

**编码方式：**

- 将每个维度划分成若干个区间（例如用2比特表示4个区间：00, 01, 10, 11）
- 每个点用所在网格的编码表示
- 例如：点(0.1, 0.9) → 编码 "00 11"

**示例：**

| 向量数据   | VA-File编码 |
| ---------- | ----------- |
| (0.1, 0.9) | 00 11       |
| (0.6, 0.8) | 10 11       |
| (0.1, 0.4) | 00 01       |
| (0.9, 0.1) | 11 00       |

**(3) 最小和最大边界**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANJaV3hH_Q87FO2pzE9Y5PWNfZkxPoAAhYMaxtLRfBWt_doP7T1mBsBAAMCAAN5AAM4BA.png)

**关键概念：**

- **minBnd**（最小边界）：查询点到网格的最小可能距离
- **maxBnd**（最大边界）：查询点到网格的最大可能距离

**重要性质：** 各栅格的边界之间的距离可以预先计算！

**两阶段算法**

- **第1阶段：过滤**

  1. 针对每一点计算 minBnd 和 maxBnd 值
  2. 消除无法成为最近邻居的那些点
  3. 过滤一些点的**minBnd**小于已知最近邻的**maxBnd**值

  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANKaV3hcji7zvA--tQdSpdTwH6GfUoAAhgMaxtLRfBWB18WNo1POdIBAAMCAAN3AAM4BA.png)

  | approx. | minBnd | maxBnd | rank |
  | ------- | ------ | ------ | ---- |
  | 10 11   | 0.39   | 0.68   | 2    |
  | 11 00   | 0.11   | 0.45   | 1    |
  | 00 11   | 0.58   | -      | ×    |
  | 00 01   | 0.47   | -      | ×    |

- **第2阶段：精炼**

  1. 根据 minBnd 以**递增顺序**访问各向量
  2. 计算真实的距离
  3. 当 minBnd 超出已知的最近邻居时，**终止**

  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANLaV3i4yPZNomwYZoEhFHI3D_wNiwAAh8MaxtLRfBWWopi09bxxnYBAAMCAAN3AAM4BA.png)

  

**(4) 性能分析**

**块选择率随维度变化**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANNaV3l2d0GyxFRPzco6DAPrND41e0AAikMaxtLRfBWyfvq6zfqnrEBAAMCAAN5AAM4BA.png)

**实验条件**：N=100,000，均匀分布，k=10

**观察**

- 低维（<10维）：需要访问约3%的向量块
- 中维（10-30维）：访问率下降到约0.5%
- 高维（>30维）：访问率稳定在约0.3%

**与树结构对比**、**模拟数据**（N=50,000，k=10）、**图像数据**（N=50,000，k=10）、**运行时间对比：**详见PPT

------

#### 5. 深入理解：Contrast

**(1) 定义**

**Contrast** 描述**最近邻居与最远邻居**之间的差异性高低：

$$\text{contrast} = \frac{D_{\max} - D_{\min}}{D_{\min}}$$

**(2) 维度影响**

- 当维度数量增多时，通常 contrast 值会降低
- 这意味着在高维空间中，所有点到查询点的距离趋于相似

**(3) 距离分布**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANOaV3uf7aDhonH3kabLWRpH_TFNgMAAjMMaxtLRfBW4OapX0BwTfQBAAMCAAN3AAM4BA.png)

**观察：** 对于任意点来说，到其他各个点的距离的分布情况随维度变化。

**不同维度的距离分布：**

- **d=2**：分布较平缓，有明显的近邻和远邻区分
- **d=6**：分布变得更集中
- **d=14**：分布形状变得"尖锐"
- **d=25**：分布极度集中，几乎所有点距离都接近平均值

**结论：** 显然，当维度越高时，整体形状会越"尖锐"。

**(4) 几何直观**

从另一个视角看：

- 在低维空间，查询点周围的点分布**有明显**的距离差异
- 在高维空间，所有点似乎都在同一个"超球面"上
- 这使得"**最近邻**"的概念变得模糊

## 第二讲 尾不等式

### 一、尾不等式分析概要

#### 1. 问题引入

**背景：**

很多情况下，精确计算一个随机事件的概率是很困难的。

**案例：** 一个服从参数分别为 1,000 和 1/3 的二项分布随机变量 X，计算尾概率 Pr[X < 100]。

**解决思路：**

- 当精确计算比较困难时，利用近似方法求得概率的近似值不失为一种理想的选择
- 但近似方法又会涉及到另一个问题：**近似值偏离真实值**到底有多大？

**问题引入1：抛硬币问题**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANQaV4WLjxqnqazvCjRY1rsRQ86sIAAAgcNaxtLRfBWDzM0W0vqlH0BAAMCAAN3AAM4BA.png)

假设抛一枚均匀的硬币，抛得正面和反面朝上的概率都为0.5，而且每次抛币与前次结果无关。

- 直觉理解：直觉上来说，抛的次数越多正面朝上的频率越接近于0.5；当抛硬币的次数达到一定次数后，正面朝上的频率非常接近于0.5，波动很小
- 核心问题：抛多少次才能以95%的概率保证正面朝上的频率和真实概率间的差距小于某个阈值（比如0.125）呢？

**问题引入2：蒙特卡罗方法**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANPaV4WCi8T82w84LrwMkLW64ORTosAAgYNaxtLRfBWua3BvfssctMBAAMCAAN5AAM4BA.png)

用蒙特卡罗方法（Monte Carlo方法）近似计算π的方法，如果随机打点 1,000,000次能保证以95%的概率近似π到2位、3位…小数吗?

**注：** 蒙特卡罗法也称统计**模拟法、统计试验法**。是把概率现象作为研究对象的数值模拟方法。是按抽样调查法求取统计值来推定未知特性量的计算方法。

------

#### 2. 求解尾概率不等式的基本方法

求解一个问题的尾概率的方法通常可以分为两大类：

**(1) 定积分、查表法**

- 适用场景：当明确知道问题所对应的概率密度函数时
- 方法：可以采用定积分的方式，把尾概率所对应的区域累积起来；简单来说，可以通过查表法（概率教科书后面的表格）或者使用R/Matlab等软件来做
- 案例：标准正态分布表可以查询不同区间的概率值

**(2) 尾概率不等式法**

- 适用场景：当无法确切知道对应的概率密度函数的时候
- 常见的尾概率不等式包括：Markov不等式、Chebyshev不等式、Chernoff不等式

------

### 二、三个常见的尾不等式

#### 1. Markov不等式

**定义：** 令 X 为样本空间上的**非负**随机变量，对任意的一个正实数 a，有

$$P(X \geq a) \leq \frac{E[X]}{a}$$

**证明：**

假设 A 是一个事件，定义

$$A = {\omega \in \Omega | X(\omega) \geq a}$$

则随机变量的期望可以计算为：

$$E(X) = \sum_{\omega \in \Omega} X(\omega)P(\omega)$$

$$= \sum_{\omega \in A} X(\omega)P(\omega) + \sum_{\omega \notin A} X(\omega)P(\omega)$$

$$\geq a \cdot P(A) + \sum_{\omega \notin A} X(\omega)P(\omega)$$

$$\geq a \cdot P(A)$$

因此，结论成立，即

$$P(A) = P(X \geq a) \leq \frac{E(X)}{a}$$

**案例分析：**

令随机变量X为抛n次均匀硬币正面向上的次数，运用Markov不等式计算n次抛币结果中正面朝上的次数超过3n/4的概率上界。

- 解：因为随机变量X是一个n次独立的贝努里实验结果，因此 $E(X) = np$，其中 p 为每次贝努里实验的成功概率。根据Markov不等式，$$P(X > 3n/4) \leq \frac{E[X]}{3n/4} = \frac{n/2}{3n/4} = \frac{2}{3}$$
- 分析：直觉上说，硬币抛的次数越多，正面向上的频率应该越接近于1/2，那么频率大于3/4的概率应该越小。而Markov不等式给出的上界与硬币抛的次数n无关。可以看出，**Markov不等式给出的尾概率上界比较松**。

------

#### 2. Chebyshev不等式

**定义：** 令X为定义在样本空间Ω上的随机变量，令E(X)和Var(X)分别为X的期望和方差，对任意的一个正实数r，有

$$P(|X - E(X)| \geq r) \leq \frac{Var(X)}{r^2}$$

**证明思路：**

不难看出，

$$P(|X - E(X)| \geq r) = P((X - E(X))^2 \geq r^2)$$

已知 $E((X - E(X))^2) = Var(X)$，对上式中的尾概率运用 Markov 不等式得到

$$P((X(\omega) - E(X))^2 \geq r^2) \leq \frac{E((X(\omega) - E(X))^2)}{r^2} = \frac{Var(X)}{r^2}$$

因此，结论成立。

**案例分析：**

令随机变量X为抛n次均匀硬币正面向上的次数，运用Chebyshev不等式计算n次抛币结果中正面朝上的次数超过3n/4的概率上界。

- 解：已知 $E[X] = np$；$Var[X] = np(1-p)$。$$P(X > 3n/4) = P(X/n > 3/4) = P(X/n - 1/2 > 1/4)$$ $$< P(|X/n - 1/2| > 1/4) \leq \frac{16np(1-p)}{n^2} = \frac{4}{n}$$
- 结论：显然，当 n=80 时，这个概率就小于 5% 了。这说明 **Chebyshev不等式给出的界比 Markov不等式更紧**。

------

#### 3. Chernoff不等式

**基本概念：**

- 独立Bernoulli试验：令 $X_1, X_2, ..., X_n$ 为独立的n个事件，$Pr[X_i=1] = p$；$Pr[X_i=0] = 1-p$。令 $X = \sum X_i$，则称X具有二项分布。
- Poisson试验：令 $X_1, X_2, ..., X_n$ 为独立的n个事件，$Pr[X_i=1] = p_i$；$Pr[X_i=0] = 1-p_i$。令 $X = \sum X_i$。易知，Bernoulli试验是Poisson试验的特例。

**Chernoff不等式（简化版）：**

若 $X_i$ 为定义在样本空间Ω上的n个独立贝努里随机变量，且 $P(X_i=1) = p_i$。令 $X = \sum_{i=1}^{n} X_i$ 和 $\mu = \sum_{i=1}^{n} p_i$，对任意小的 $\delta \in (0,1)$，则以下不等式成立：

$$P(X < (1-\delta)\mu) < \exp(-\mu\delta^2/2)$$

$$P(X > (1+\delta)\mu) < \exp(-\mu\delta^2/4)$$

**Chernoff不等式（精确版）：**

$$P(X < (1-\delta)\mu) < \left(\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}}\right)^\mu$$

$$P(X > (1+\delta)\mu) < \left(\frac{e^{\delta}}{(1+\delta)^{(1+\delta)}}\right)^\mu$$

**证明思路：**

证明第一个不等式。对任意 $t > 0$，

$$P(X < (1-\delta)\mu) = P(\exp(-tX) > \exp(-t(1-\delta)\mu))$$

$$< \frac{\prod_{i=1}^{n} E(\exp(-tX_i))}{\exp(-t(1-\delta)\mu)}$$

因为 $(1-x < e^{-x})$，所以

$$E(\exp(-tX_i)) = p_ie^{-t} + (1-p_i)$$

$$= 1 - p_i(1-e^{-t})$$

$$< \exp(p_i(e^{-t}-1))$$

因此，

$$\prod_{i=1}^{n} E(\exp(-tX_i)) < \prod_{i=1}^{n} \exp(p_i(e^{-t}-1))$$

$$= \exp(\mu(e^{-t}-1))$$

进一步的，

$$P(X < (1-\delta)\mu) < \frac{\exp(\mu(e^{-t}-1))}{\exp(-t(1-\delta)\mu)} = \exp(\mu(e^{-t}+t-t\delta-1))$$

上式中的上界是关于变量 t 的函数，随着 t 取值的变化，概率上界也在变化。因此可以通过择 t 的值，得到概率上界的最小值。为了获得概率上界的最小值，对 $\mu(e^{-t}+t-t\delta-1)$ 关于 t 求导，并令其为 0，得到当 $t = \ln\frac{1}{1-\delta}$ 时，概率上界取到最小值。将 $t = \ln\frac{1}{1-\delta}$ 代入公式，可以得到结论。

**应用案例：**

*案例1：球队胜率*

某球队赢每一场比赛的概率是1/3。假设比赛结果相互独立，试求他们在一个有n场比赛的赛季获得一半以上场次胜利的概率的上界。

- 分析：$X_i$：获胜为1，输为0。则和 $Y = \sum X_i$，$\mu = E[Y] = n/3$；$\delta = 1/2$。$$P(Y > (1+0.5)\mu) < \exp(-\mu\delta^2/4) = \exp\left(-\frac{n}{3} \cdot \frac{(1/2)^2}{4}\right) = \exp(-n/48)$$
- 结论：若 n=40，概率不高于 0.43；若 n=100，概率不高于 0.12。备注：若调用更精确版本，这两个概率分别为：0.23、0.027

*案例1（补充）*

某球队赢每一场比赛的概率是3/4。假设比赛结果相互独立，试求他们在一个有n场比赛的赛季输掉一半以上场次的概率的上界。

- 分析：$X_i$：获胜为1，输为0。则和 $Y = \sum X_i$，$\mu = E[Y] = 3n/4$；此时，$\delta = 1/3$。$$P(Y < n/2) = P(Y < (1-1/3)\mu) < \exp(-\mu\delta^2/2) = \exp(-n/24)$$
- 结论：n=40，概率小于 0.19；n=100，概率小于 0.015

*案例2：球和箱子*

均匀、独立地将n个球放置到n个箱子里。令随机变量 $Y_1$ 表示放到第一个箱子里的球的个数。希望确定值m，使得 $Pr[Y_1 > m] \leq 1/n^2$。

- 分析：易知，$p_i = 1/n$；$\mu = 1$。$$P[X > (1+\delta)\mu] < \exp(-\mu\delta^2/4) = 1/n^2$$两边取对数：$\mu\delta^2/4 = 2\ln n$ ⇒ $\delta = \sqrt{8\ln n}$

*案例3：集合平衡（Set Balancing）*

考虑一个 n×m 的矩阵A，各项为0或1，如何寻找向量 $b \in {-1, +1}^m$，使得 $||Ab||_\infty$ 最小。

- 问题建模：令 $c = Ab$，则 $||Ab||*\infty = \max(c_i)$。考虑m个物品（subject），各有最多n个特性（feature），构成一个 n×m 的矩阵A。各列代表一个物品，各行代表特性。项 $a*{ij} \in {0, 1}$ 表示物品j是否拥有特性i。
- 核心思想：通过向量b将所有物品划分成两个分组，每一个项的值 $c_i$ 表示这两个分组在第i个特性上的划分的差值。如果能够使得这样的差值在各个特性上均很小，那么就说明各个特性均比较均匀地划分到两个组之中。
- 算法设计：构造了一个极度简单的算法来构成向量b：各项 $b_i$ 随机均匀地从 {-1, +1} 中选取，即：$$b_i = \begin{cases} -1 & \text{with probability } 1/2 \ +1 & \text{with probability } 1/2 \end{cases}$$这个算法极度简单，因为根本没有考虑A。
- 分析：考虑矩阵 A 的第 i 行，则 $c_i = \sum_j a_{ij}b_j$。令 k 是该行中非0项的个数。$|c_i|$ 的期望值是0。当 $k \leq 2\sqrt{2m\ln n}$ 时，显然 $|c_i|$ 小于等于式子右边。因此，主要考虑k的值比较大的情况。值为+1的项数的期望值为 k/2。当 $c_i < -2\sqrt{2m\ln n}$ 时，正的 $b_i$'s 不超过 $\frac{k}{2} - \sqrt{2m\ln n} = (1-\delta)\mu$。应用Chernoff不等式，得：$$\exp\left(-\frac{\mu\delta^2}{2}\right) = \exp\left(-\frac{k}{2} \cdot \frac{8m\ln n}{2k^2}\right) = \exp\left(-\frac{2m\ln n}{k}\right) \leq \exp\left(-\frac{2m\ln n}{m}\right) \leq n^{-2}$$说明对单个 $c_i$ 而言，单边的最大概率是 $n^{-2}$。而在该例中，有双边概率，因此：$$Pr[|c_i| > 2\sqrt{2m\ln n}] \leq \frac{2}{n^2}$$最后，取得n行的一个最终值：$$Pr[||Ab||_\infty > 2\sqrt{2m\ln n}] \leq n \cdot Pr[|c_i| > 2\sqrt{2m\ln n}] \leq \frac{2}{n}$$

*案例4：抛硬币（Chernoff版本）*

令随机变量X为抛n次均匀硬币正面向上的次数，运用Chernoff不等式计算n次抛币结果中正面朝上的次数超过3n/4的概率上界。

- 解：已知 $E(X) = np = n/2$。运用Chernoff不等式，$$P(X > 3n/4) = P(X > (1+1/2) \cdot n/2)$$ $$= P(X > (1+1/2)E(X))$$ $$< \exp\left(-\frac{n}{2} \cdot (1/2)^2 / 4\right)$$ $$= \exp(-n/32)$$
- 结果：当 n=50 时，概率为：0.21；当 n=80 时，概率为：0.08；当 n=300 时，概率为：0.000085

------

#### 4. 尾概率不等式的实际使用

关于尾概率不等式的实际使用，其实是要回答三类问题。这里的原因在于总共有三个控制参数：一个是次数 n，一个是偏移期望的程度 δ，另一个是最终的置信度参数。总是可以固定两个参数，求另外一个参数的情况。

**问题类型：**

- 其一：已知采样次数和偏移的程度，求解置信度
- 其二：已知采样次数和置信度，求解偏移的程度
- 其三：已知置信度和偏移的程度，求解采样次数

**第一类问题示例：**

例如：投掷了硬币1000次，总的期望值是500，则当 δ=0.2 的时候，即是在询问正面朝上的总次数超过了 (1+0.2)×500=600 的概率。

- 已知：n=1000，μ=1/2，δ=0.2，求解置信度
- 根据Chernoff不等式：$$P[X > (1+\delta)n\mu] < \exp(-n\mu\delta^2/4)$$即：$P[X > 600] < \exp(-5) = 0.0067$

**第二类问题示例：**

例如：总共投掷了1000次，总的期望值是500，则当想要知道正面朝上的概率不低于95%时，能够确保的正面朝上的次数是几次。

- 已知：n=1000，μ=1/2，置信度为0.05，求解偏移程度
- 根据Chernoff不等式，$P[X > (1+\delta)n\mu] < \exp(-n\mu\delta^2/4)$
- 令 $\exp(-n\mu\delta^2/4) = 0.05$，则：δ=0.15，(1+0.15)×500=575
- 则能够以95%的概率确保的正面朝上的次数为575次

**第三类问题示例：**

至少需要投掷几次硬币，才可确保正面朝上的比率在0.6以下的概率不低于95%。

- 分析：μ=1/2；(1+δ)μ=0.6 ⇒ δ=0.2
- 根据Chernoff不等式：$P[X > (1+\delta)n\mu] < \exp(-n\mu\delta^2/4)$
- 可以得到：$\exp(-0.04n\mu/4) < 0.05$
- 求解以上式子，得到：n > 599.1
- 所以至少需要投掷600次硬币才能保证正面朝上的比率在0.6以下的概率不低于95%

------

### 三、计数问题

#### 1. Morris算法

**问题背景与动机：**

- 场景描述：某电子商城想记录某本畅销书的销售量
- 传统方法：用一个整数变量来描述，初始化为0，每卖出一本则加1
- 问题分析：用二进制表示数n需要 $\lceil \log_2 n \rceil$ 位，即计算机需要 $\lceil \log_2 n \rceil$ 位存储整数n。当n值比较大时，存储开销会很大，可否降低开销？

**Morris算法原理：**

核心思想是只需要 $\lceil \log_2 \log_2 n \rceil$ 位就可以近似表示一个大整数。

算法描述：

```
Morris算法
Input: 事件流F
Output: 指定事件的计数 C

1 初始化计数器X=0
2 while 事件流F未结束 do
3   if 指定事件发生 then
4     以 1/2^X 的概率更新 X=X+1
5 C=2^X-1
6 return C
```

两个核心操作：

1. 更新操作：当指定事件发生时，以 $1/2^X$ 的概率更新X的值为X+1；以 $1-1/2^X$ 的概率保持X的值不变
2. 估计计数结果：返回近似**估计值** $C = 2^X - 1$

**Morris算法示例：**

| 事件流 | 真实计数 | 抽样概率 | X的值 | 计数估计值 |
| ------ | -------- | -------- | ----- | ---------- |
|        | 0        | 1        | 0     | 0          |
| 1      | 1        | 1/2      | 1     | 1          |
| 1      | 2        | 1/2      | 1     | 1          |
| 1      | 3        | 1/4      | 2     | 3          |
| 1      | 4        | 1/4      | 2     | 3          |
| 1      | 5        | 1/4      | 2     | 3          |
| 1      | 6        | 1/4      | 2     | 3          |
| 1      | 7        | 1/8      | 3     | 7          |
| 1      | 8        | 1/8      | 3     | 7          |

**Morris算法理论分析：**

定理：令事件真实计数为N，$X_N$ 是Morris算法维护的计数器，则其输出的估计值 $2^{X_N}-1$ 是真实计数N的**无偏估计**。

证明过程：注意到当 $X_{N-1} = j$ 时，$X_N = j+1$ 的概率为 $2^{-j}$，而保持 $X_N = j$ 的概率为 $1-2^{-j}$，因此

$$E(2^{X_N}) = E(E(2^{X_N}|X_{N-1}=j))$$

$$= \sum_{j \geq 1} P(X_{N-1}=j)E(2^{X_N}|X_{N-1}=j)$$

接下来，条件数学期望 $E(2^{X_N}|X_{N-1}=j)$ 可以计算如下：

$$E(2^{X_N}|X_{N-1}=j) = 2^{j+1}2^{-j} + 2^j(1-2^{-j})$$

$$= 2^j + 2 - 1 = 2^j + 1$$

最后，运用数学归纳法证明最终结果。

当 N=1 时，$X_N = 1$。因此，$E(2^1-1) = 2^1-1 = 1$ 结论成立。

假设当 N=k 时，结论 $E(2^{X_k}-1) = k$ 也成立。

当 N=k+1 时，

$$E(2^{X_{k+1}}) = E(E(2^{X_{k+1}}|X_k=j))$$

$$= \sum_{j \geq 1} P(X_k=j)E(2^{X_{k+1}}|X_k=j)$$

$$= \sum_{j \geq 1} P(X_k=j)(2^j+1)$$

$$= \sum_{j \geq 1} P(X_k=j)(2^j-1) + \sum_{j \geq 1} P(X_k=j)2$$

$$= E(2^{X_k}-1) + 2$$

$$= k + 2$$

即当 N=k+1 时，有 $E(2^{X_{k+1}}-1) = k+1$ 也成立。

方差分析：

$$Var(2^{X_N}) = E((2^{X_N})^2) - (E(2^{X_N}))^2$$

$$= E(2^{2X_N}) - (N+1)^2$$

通过递推可以得到：

$$E(2^{2X_N}) = \frac{3N(N+1)}{2} + 1$$

所以，

$$Var(2^{X_N}) \approx \frac{1}{2}N^2$$

------

#### 2. Morris+算法

**问题分析与改进思路：**

- Morris算法的劣势：虽然Morris算法给出了真实计数的无偏估计，但随着计数N的增加，该估计的方差以二次多项式的形式在增加
- 统计学重要结论：令 $X_1, X_2, ..., X_n$ 为n个独立同分布的样本，且对任意 $1 \leq i \leq n$ 有 $E(X_i) = \mu$ 和 $Var(X_i) = \sigma^2$，那么样本均值的期望与方差分别为$$E(\sum X_i / n) = \mu$$ $$Var(\sum X_i / n) = \sigma^2 / n$$
- 结论：通过多次估计取平均可以获取波动更小的计数的无偏估计

**Morris+算法描述：**

核心思想：对事件计数的每次更新维护n个计数，当事件流结束时，计算这n个计数的平均值，会得到波动更小的真实计数的无偏估计。

```
Morris+算法
输入：事件流F, δ和ε
输出：指定事件计数C

01 n = ⌈1/δε²⌉
02 初始化计数数组 X[1…n]=0
03 while 事件流F未结束 do
04   if 指定事件发生 then
05     for i=1 to n do
06       以1/2^Xi的概率更新Xi=Xi+1
07 for i=1 to n do
08   C=C+2^Xi-1
09 C=C/n
10 return C
```

**Morris+算法分析：**

根据方差的性质，相对于Morris算法，Morris+算法返回的计数估计值的方差减小到了 $O(N^2/n)$。

根据Chebyshev不等式，

$$P(|\hat{N} - N| > \varepsilon N) < \frac{Var(\hat{N})}{\varepsilon^2 N^2}$$

由于 $Var(\hat{N}) = O(N^2/n)$，因此：

$$P(|\hat{N} - N| > \varepsilon N) < \frac{O(N^2/n)}{\varepsilon^2 N^2} \approx \frac{1}{n\varepsilon^2}$$

令 $\frac{1}{n\varepsilon^2} < \delta$，即 $n = O(1/\delta\varepsilon^2)$ 时，$P(|\hat{N} - N| > \varepsilon N) < \delta$

这表明事件计数的估计值是偏离真实值N大于εN的概率小于δ。此时，称 $\hat{N}$ 为N的 **(ε,δ)近似估计**。

**复杂度分析：**

- 空间复杂度：总共有 $O(1/\delta\varepsilon^2)$ 个计数器，每个计数器占用 $O(\log\log n)$ 位。因此，空间复杂度是：$O(\log\log n / \delta\varepsilon^2)$
- 时间复杂度（Per-tuple processing cost）：每处理一个元素，需要循环 $O(1/\delta\varepsilon^2)$ 次，因此开销是 $O(1/\delta\varepsilon^2)$

------

#### 3. Morris++算法

**拔河（Tug-of-War）思想：**

当目标概率是δ时，可以将实例数从 $1/\delta$ 降至 $\log(1/\delta)$。

- 核心思路：运行 t 个Morris+实例，每个实例的失败概率为 1/3，即：$$P(|\hat{N} - N| > \varepsilon N) < \frac{1}{2k\varepsilon^2} = \frac{1}{3}$$注：每个Morris+运行了k个Morris实例，且 $k = O(1/\varepsilon^2)$。然后，输出所有 t 个Morris+实例的**中位数**估计值。
- 关键观察：失败的 Morris+ 实例的预期数量不超过 t/3。如果中位数估计值出错，则表明至少一半Morris+ 实例失败了，表示失败实例的数量至少偏离期望值达到 t/6。（原因：t/3 + t/6 = t/2）

**Morris++算法描述：**

```
Morris++算法
输入：事件流F, δ和ε
输出：指定事件计数C

01 n = ⌈ln1/δ⌉, m = ⌈1/ε²⌉
02 初始化数组X[1…n, 1…m]=0, C[1…n]=0
03 while 事件流F未结束 do
04   if 指定事件发生 then
05     for i=1 to n do
06       for j=1 to m do
07         以1/2^Xij的概率更新Xij=Xij+1
08 for i=1 to n do
09   for j=1 to m
10     Ci=Ci+(2^Xij-1)
11   Ci = Ci/n
12 C=C[1…n]的中位数
13 return C
```

**Morris++算法分析：**

定义：

$$Y_i = \begin{cases} 1, & \text{if } |\frac{1}{k}\sum_{j=1}^{k} \hat{n}_{ij} - n| > \varepsilon N \ 0, & \text{Otherwise} \end{cases}$$

由于 $k = O(1/\varepsilon^2)$，可知：$P(Y_i=1) < 1/3$

由于 $\mu = E(\sum Y_i) = t/3$，通过Chernoff不等式，可知

$$P(\sum Y_i > t/2) \leq P(\sum Y_i > (1+1/2)\mu)$$

$$\leq \exp(-\mu(1/2)^2/4) < \exp(-t/48) < \delta$$

因此：可知：$t = O(\log 1/\delta)$

最终结论：可以用 $O(\log(1/\delta)/\varepsilon^2)$ 个Morris实例的复杂度来得到 (ε, δ) 近似的算法。

**进一步分析：**

- 总体思路：利用tug-of-war方法降低了空间复杂度
- 综合运用了Chebyshev不等式和Chernoff不等式：
  1. 在调用Chebyshev不等式时，目的是将失败概率降低到常数量级（例如1/3）
  2. 在调用Chernoff不等式时，才将失败概率降低到任意一个给定阈值
- 思考：第一步的失败概率如果是1/4，或者1/2，是否也可行？

## 第三讲 数据流

### 一、数据流模型

数据流模型描述了数据以流的形式到达，只能顺序访问一次或有限次的计算场景。

**数据流的特点：**
- 数据量巨大，无法全部存储
- 数据到达速度快，需要实时处理
- 只能进行一次或有限次扫描
- 需要在有限空间内近似计算

**典型应用：**
- 网络流量监控
- 金融交易分析
- 社交媒体数据处理
- IoT传感器数据

**数据流算法的目标：**
- 使用亚线性（sublinear）空间
- 提供可证明的近似保证
- 单次扫描或少量扫描

### 二、频繁元素-确定性算法

**问题定义：**
找出数据流中出现频率超过某个阈值的元素（heavy hitters）。

**Misra-Gries算法：**

**算法描述：**
1. 维护最多k个计数器
2. 对于每个到来的元素：
   - 如果已有计数器，增加其计数
   - 如果没有计数器且有空位，创建新计数器
   - 如果没有空位，所有计数器减1，删除值为0的计数器
3. 输出计数器中的元素

**性能保证：**
- 空间复杂度：O(k)
- 如果元素出现次数 > n/k，一定会被找到
- 可能有假阳性，但可以通过二次扫描验证

**应用：**
- 找出访问量最大的网页
- 检测网络中的大流量
- 识别热门话题

### 三、频繁元素-随机算法

**Count-Min Sketch算法：**

**数据结构：**
- d × w 的二维计数器数组
- d个独立的哈希函数h₁, h₂, ..., h_d

**算法操作：**

**更新（插入元素x）：**
```
对于 i = 1 到 d：
    count[i][hᵢ(x)] += 1
```

**查询（估计元素x的频率）：**
```
返回 min{count[i][hᵢ(x)] : i = 1..d}
```

**性能保证：**
- 空间复杂度：O(d × w)
- 误差界：ε·n (n为总元素数)，概率至少1-δ
- 选择w = ⌈e/ε⌉, d = ⌈ln(1/δ)⌉
- 只会高估，不会低估

**优势：**
- 空间效率高
- 支持点查询和范围查询
- 可以处理删除操作（使用带符号的计数）

### 四、滑动窗口模型

**问题描述：**
只关心最近W个元素的统计特性，更早的数据被丢弃。

**挑战：**
- 无法存储所有W个元素
- 需要及时更新统计信息

**DGIM算法（用于计数）：**

**基本思想：**
- 将窗口划分为桶（bucket）
- 每个桶代表一段连续的1
- 桶的大小是2的幂次
- 维护O(log W)个桶

**桶的性质：**
1. 每种大小的桶最多2个
2. 桶按时间戳排序
3. 最老的桶可能不完整

**查询操作：**
统计窗口内1的个数 ≈ 完整桶的大小之和 + 半个最老桶

**误差保证：**
- 相对误差：最多50%
- 可以通过增加每种大小桶的数量来降低误差

**应用扩展：**
- 滑动窗口中的平均值
- 滑动窗口中的中位数（近似）
- 滑动窗口中的distinct计数

---

## 第四讲 分布式数据流

### 一、分布式数据流模型

在分布式环境中，数据流分散在多个节点上，需要协调多个节点进行计算。

**系统架构：**
- **多个监测节点**：每个节点观察部分数据流
- **协调节点**：汇总和处理来自监测节点的信息
- **通信约束**：最小化节点间的通信量

**挑战：**
- 数据分散性
- 通信开销
- 同步问题
- 节点故障

**典型场景：**
- 分布式网络监控
- 多数据中心的日志分析
- 边缘计算
- CDN流量统计

### 二、聚集查询

**问题定义：**
计算分布在多个节点上的数据的聚集函数（如SUM、COUNT、AVG）。

**基本方法：**

**1. 连续聚集：**
- 每个节点维护本地的统计信息
- 周期性发送给协调节点
- 协调节点汇总计算全局结果

**2. 快照聚集：**
- 在特定时刻获取全局快照
- 需要处理同步问题
- 使用逻辑时钟或物理时钟

**优化技术：**

**采样与估计：**
- 不发送所有数据，只发送样本
- 使用统计方法估计全局结果
- 权衡精度和通信开销

**增量更新：**
- 只发送变化部分
- 减少冗余通信
- 适用于变化缓慢的数据

**数据结构支持：**
- 使用Count-Min Sketch等概要结构
- 可以在协调节点合并
- 支持分布式查询

### 三、topk监控

**问题定义：**
实时监控分布式系统中全局的top-k元素（如最热门的k个商品、最活跃的k个用户）。

**挑战：**
- 全局top-k可能不在任何单个节点的局部top-k中
- 需要在精度和通信量之间平衡
- 数据分布可能高度倾斜

**解决方案：**

**1. 阈值算法：**
- 协调节点维护全局top-k的阈值θ
- 每个节点报告超过θ的元素
- 动态调整θ以平衡通信量

**算法流程：**
```
初始化：θ = 0
循环：
  1. 每个节点报告频率 > θ 的元素
  2. 协调节点更新全局top-k
  3. 计算新阈值θ（如第k大元素的频率）
  4. 将θ广播给各节点
```

**2. 采样方法：**
- 各节点以概率p采样元素
- 上传采样的数据到协调节点
- 基于采样数据估计全局top-k

**3. 层次化监控：**
- 构建监控树
- 中间节点聚合子节点的信息
- 减少单点通信压力

**性能优化：**
- **局部过滤**：只上传可能进入全局top-k的元素
- **批量通信**：积累一定数量的更新后批量发送
- **缓存机制**：利用时间局部性减少通信

**实际应用：**
- 实时热搜榜
- 分布式缓存的热点识别
- 网络安全中的异常检测
- 广告系统的CTR监控

---

## 第五讲 哈希

### 一、哈希函数和哈希表

哈希技术是一种通过哈希函数将数据映射到固定大小的表中的方法，实现快速的数据存储和检索。

**核心概念：**
- **哈希函数**：将任意大小的数据映射到固定大小的值
- **哈希表**：基于数组实现的数据结构，通过哈希函数计算索引位置
- **冲突处理**：当不同的键映射到相同位置时的解决策略
  - 链地址法（Chaining）
  - 开放地址法（Open Addressing）

**时间复杂度：**
- 平均情况：O(1) 查找、插入、删除
- 最坏情况：O(n)（当所有元素都冲突时）

### 二、布隆过滤器（Bloom Filter）

布隆过滤器是一种空间高效的概率型数据结构，用于判断一个元素是否在集合中。

**特点：**
- 可能产生假阳性（False Positive）：说存在但实际不存在
- 不会产生假阴性（False Negative）：说不存在就一定不存在
- 不支持删除操作（标准版本）

**应用场景：**
- 网页URL去重
- 垃圾邮件过滤
- 缓存穿透防护
- 大数据去重

**工作原理：**
1. 使用k个不同的哈希函数
2. 将元素映射到位数组的k个位置
3. 查询时检查这k个位置是否都为1

### 三、最小哈希和LSH（Locality-Sensitive Hashing）

**最小哈希（MinHash）：**
用于估计两个集合的Jaccard相似度，常用于文档去重和相似度检测。

**局部敏感哈希（LSH）：**
一种降维技术，使得相似的数据项以高概率被映射到相同的桶中。

**应用：**
- 近似最近邻搜索
- 图像相似度检测
- 文本去重
- 推荐系统

---

## 第六讲 线性规划与整数规划

- 线性规划问题研究在资源约束条件下的最大化或最小化目标问题,表示方式有**标准型和松弛型**,单纯形算法来求解线性规划问题
- 整数规划比线性规划有更多约束条件
- 分支界定法是解决整数规划问题的有效方法，但是当**变量数量多**的时候效率会下降
- 切平面法是解决整数规划问题的有效方法

### 一、线性规划:单纯形算法

#### 1. 线性函数与线性规划

**线性函数的定义:**

给定一组实数 $a_1, a_2, ..., a_n$ 和一组变量 $x_1, x_2, ..., x_n$,定义在这些变量上的线性函数为:

$$f(x_1, x_2, ..., x_n) = a_1x_1 + a_2x_2 + ... + a_nx_n$$

**线性约束的定义:**

如果 $b$ 是一个实数,而 $f$ 是一个线性函数,则:

- $f(x_1, x_2, ..., x_n) = b$ 是**线性等式**
- $f(x_1, x_2, ..., x_n) \geq b$ 和 $f(x_1, x_2, ..., x_n) \leq b$ 是**线性不等式**

线性约束表示线性等式或者线性不等式。

**线性规划问题的定义:**

一个线性规划问题是指:一个线性函数最小化或最大化的问题,该线性函数服从一组有限个线性约束。

可以分为:

- **最小化线性规划** vs. **最大化线性规划**

**线性规划的几何意义:**

- **可行解**:满足所有约束条件的 $x_1, x_2$ 的取值称为一个可行解
- **可行区域**:所有可行解构成的区域

**示例:**

$$
\begin{align}
\text{最大化} \quad & x_1 + x_2 \\
\text{满足约束条件:} \quad & 4x_1 - x_2 \leq 8 \\
& 2x_1 + x_2 \leq 10 \\
& 5x_1 - 2x_2 \geq -2 \\
& x_1, x_2 \geq 0
\end{align}
$$

在图示中,可行区域为一个多边形区域,最优解 $x_1 + x_2 = 8$ 出现在可行域的**顶点**处。

**重要性质:** 线性规划的最优解通常出现在可行域的顶点处。

---

#### 2. 线性规划转标准型

**标准型的定义:**

已知 $n$ 个实数 $c_1, c_2, ..., c_n$;   $m$ 个实数 $b_1, b_2, ..., b_m$;   以及 $mn$ 个实数 $a_{ij}$,  其中 $i = 1,2,...,m$;$j = 1,2,...,n$。需要找到 $n$ 个实数 $x_1, x_2,...,x_n$。

**一般形式:**

$$
\begin{align}
\text{最大化} \quad & c_1x_1 + c_2x_2 + ... + c_nx_n \quad \text{(目标函数)} \\
\text{满足约束条件:} \quad & a_{i1}x_1 + a_{i2}x_2 + ... + a_{in}x_n \leq b_i \quad (i = 1,2,...,m) \quad \text{(约束)} \\
& x_j \geq 0 \quad (j = 1,2,..., n) \quad \text{(非负约束)}
\end{align}
$$

**矩阵表示形式:**

构造:

- $m \times n$ 矩阵 $A = (a_{ij})$
- 一个 $m$ 维向量 $b = (b_i)$
- 一个 $n$ 维向量 $c = (c_i)$
- 一个 $n$ 维向量 $x = (x_i)$

标准型可表示为:

$$
\begin{align}
\text{最大化} \quad & c^Tx \quad \text{(目标函数)} \\
\text{满足约束条件:} \quad & Ax \leq b \quad \text{(约束)} \\
& x \geq 0 \quad \text{(非负约束)}
\end{align}
$$

可用元组 **(A, b, c)** 表达一个标准的线性规划问题。

**标准型的特点:**

- 目标函数是**最大化**
- 所有约束都是**不等式**(小于等于号)
- 所有变量都有**非负约束**

---

**转换为标准型的技巧:**

一个线性规划问题可能不是标准型,可能的原因及解决方法包括:

**(1)目标函数是最小化而非最大化**

**解决方法:** 将目标函数中的系数取负数

**示例:**

$$
\begin{aligned}
\text{最小化} \quad & -2x_1 + 3x_2 \\
\text{满足约束:} \quad & x_1 + x_2 = 7 \\
& x_1 - 2x_2 \leq 4 \\
& x_1 \geq 0
\end{aligned}
\quad \rightarrow \quad
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2 \\
\text{满足约束:} \quad & x_1 + x_2 = 7 \\
& x_1 - 2x_2 \leq 4 \\
& x_1 \geq 0
\end{aligned}
$$

---

**(2)变量不具有非负约束**

**解决方法:** 将该变量 $x_j$ 每次出现的地方都改为 $x_j' - x_j''$,且 $x_j'$ 和 $x_j''$ 均 $\geq 0$

**示例:**

$$
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2 \\
\text{满足约束:} \quad & x_1 + x_2 = 7 \\
& x_1 - 2x_2 \leq 4 \\
& x_1 \geq 0
\end{aligned}
\quad \rightarrow \quad
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2' + 3x_2'' \\
\text{满足约束:} \quad & x_1 + x_2' - x_2'' = 7 \\
& x_1 - 2x_2' + 2x_2'' \leq 4 \\
& x_1, x_2', x_2'' \geq 0
\end{aligned}
$$ {e}

---

---

**(3)可能有等式约束**

**解决方法:** 转化成一对不等式

**示例:**

$$
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2' + 3x_2'' \\
\text{满足约束:} \quad & x_1 + x_2' - x_2'' = 7 \\
& x_1 - 2x_2' + 2x_2'' \leq 4 \\
& x_1, x_2', x_2'' \geq 0
\end{aligned}
\quad \rightarrow \quad
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2' + 3x_2'' \\
\text{满足约束:} \quad & x_1 + x_2' - x_2'' \leq 7 \\
& x_1 + x_2' - x_2'' \geq 7 \\
& x_1 - 2x_2' + 2x_2'' \leq 4 \\
& x_1, x_2', x_2'' \geq 0
\end{aligned}
$$

---

**(4)可能有不等式约束,但不是小于等于号,而是大于等于号**

**解决方法:** 更改约束的符号(两边同时乘以 $-1$)

**示例:**

$$
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2' + 3x_2'' \\
\text{满足约束:} \quad & x_1 + x_2' - x_2'' \leq 7 \\
& x_1 + x_2' - x_2'' \geq 7 \\
& x_1 - 2x_2' + 2x_2'' \leq 4 \\
& x_1, x_2', x_2'' \geq 0
\end{aligned}
\quad \rightarrow \quad
\begin{aligned}
\text{最大化} \quad & 2x_1 - 3x_2' + 3x_2'' \\
\text{满足约束:} \quad & x_1 + x_2' - x_2'' \leq 7 \\
& -x_1 - x_2' + x_2'' \leq -7 \\
& x_1 - 2x_2' + 2x_2'' \leq 4 \\
& x_1, x_2', x_2'' \geq 0
\end{aligned}
$$

---

#### 3. 线性规划转松弛型

**松弛型的定义:**

**松弛型(Slack Form)**:约束都是等式(除了要求变量非负的约束)

**标准型 vs 松弛型:**

- **标准型**:所有的约束都是不等式
- **松弛型**:约束都是等式(除了要求变量非负的约束)

---

**引入松弛变量:**

通过引入新变量,将不等式改变成等式:

$$\sum_{j=1}^{n} a_{ij}x_j \leq b_i \quad \rightarrow \quad s = b_i - \sum_{j=1}^{n} a_{ij}x_j, \quad s \geq 0$$

称 $s$ 为**松弛变量**,因为它度量了以上不等式左右两边的松弛或差别。

---

**更简洁的表示:**

去除关于"最大化"、"满足约束"这些词,直接写成等式形式。

**示例:**

原标准型:

$$
\begin{align}
\text{最大化} \quad & 2x_1 - 3x_2 + 3x_3 \\
\text{满足约束条件:} \quad & x_1 + x_2 - x_3 \leq 7 \\
& -x_1 - x_2 + x_3 \leq -7 \\
& x_1 - 2x_2 + 2x_3 \leq 4 \\
& x_1, x_2, x_3 \geq 0
\end{align}
$$

转换为松弛型(引入松弛变量 $x_4, x_5, x_6$):

$$
\begin{align}
z &= 2x_1 - 3x_2 + 3x_3 \\
x_4 &= 7 - x_1 - x_2 + x_3 \\
x_5 &= -7 + x_1 + x_2 - x_3 \\
x_6 &= 4 - x_1 + 2x_2 - 2x_3
\end{align}
$$

**重要概念:**

- **等式左边:基本变量**(在等式左边的变量)
- **等式右边:非基本变量**(在等式右边的变量)

---

**松弛型的元组表示:**

可用元组 **(N, B, A, b, c, v)** 表示松弛型。

**示例:**

$$
\begin{align}
z &= 28 - \frac{x_3}{6} - \frac{x_5}{6} - \frac{2x_6}{3} \\
x_1 &= 8 + \frac{x_3}{6} + \frac{x_5}{6} - \frac{x_6}{3} \\
x_2 &= 4 - \frac{8x_3}{3} - \frac{2x_5}{3} + \frac{x_6}{3} \\
x_4 &= 18 - \frac{x_3}{2} + \frac{x_5}{2}
\end{align}
$$

**元组表示:**

- $B = \{1, 2, 4\}$(基本变量集合)
- $N = \{3, 5, 6\}$(非基本变量集合)
- $c = (c_3, c_5, c_6)^T = (-1/6, -1/6, -2/3)^T$
- $v = 28$

矩阵 $A$:

$$
A = \begin{pmatrix}
a_{13} & a_{15} & a_{16} \\
a_{23} & a_{25} & a_{26} \\
a_{43} & a_{45} & a_{46}
\end{pmatrix} = \begin{pmatrix}
1/6 & 1/6 & -1/3 \\
-8/3 & -2/3 & 1/3 \\
-1/2 & 1/2 & 0
\end{pmatrix}
$$

向量 $b$:

$$
b = \begin{pmatrix}
b_1 \\
b_2 \\
b_4
\end{pmatrix} = \begin{pmatrix}
8 \\
4 \\
18
\end{pmatrix}
$$

---

#### 4. 单纯形算法

**算法核心思想:**

单纯形算法的本质是从可行域的一个顶点出发,沿着目标函数值改进的方向移动到相邻顶点,直到找到最优解。

**基本解的概念:**

松弛型等式系统拥有无限个解。我们集中于**基本解**:

- 把等式右边所有(非基本)变量设为 $0$
- 再计算等式左边(基本)变量的值
- 再计算目标值

**每次迭代的目标:** 重新整理线性规划,使得基本解有一个更大的目标值。

---

**算法详细步骤(以最大化问题为例):**

**初始问题:**

$$
\begin{align}
\text{最大化} \quad z &= 3x_1 + x_2 + 2x_3 \\
\text{满足约束条件:} \quad & x_1 + x_2 + 3x_3 \leq 30 \\
& 2x_1 + 2x_2 + 5x_3 \leq 24 \\
& 4x_1 + x_2 + 2x_3 \leq 36 \\
& x_1, x_2, x_3 \geq 0
\end{align}
$$

**步骤1:转换为松弛型**

引入松弛变量 $x_4, x_5, x_6$:

$$
\begin{align}
z &= 3x_1 + x_2 + 2x_3 \\
x_4 &= 30 - x_1 - x_2 - 3x_3 \\
x_5 &= 24 - 2x_1 - 2x_2 - 5x_3 \\
x_6 &= 36 - 4x_1 - x_2 - 2x_3
\end{align}
$$

**初始基本解:**

- 基本解:$(\bar{x}_1, \bar{x}_2, ..., \bar{x}_6) = (0, 0, 0, 30, 24, 36)$
- 目标值:$z = 3 \times 0 + 1 \times 0 + 2 \times 0 = 0$

---

**步骤2:第一次迭代**

**观察分析:**

- 考虑增加 $x_1$ 的值(因为其系数为正,可以增加目标值),使所有值保持非负
- 从三个约束式可知:
  - $x_1$ 超过 $30$ 时,$x_4$ 变负
  - $x_1$ 超过 $12$ 时,$x_5$ 变负
  - $x_1$ 超过 $9$ 时,$x_6$ 变负
- 因此,$x_1$ 最多取 $9$,此时 $x_6 = 0$
- **互换 $x_1$ 和 $x_6$**($x_1$ 入基,$x_6$ 出基)

**第一次迭代后:**

$$
\begin{align}
z &= 27 + \frac{x_2}{4} + \frac{x_3}{2} - \frac{3x_6}{4} \\
x_1 &= 9 - \frac{x_2}{4} - \frac{x_3}{2} - \frac{x_6}{4} \\
x_4 &= 21 - \frac{3x_2}{4} - \frac{5x_3}{2} + \frac{x_6}{4} \\
x_5 &= 6 - \frac{3x_2}{2} - 4x_3 + \frac{x_6}{2}
\end{align}
$$

**新基本解:**

- 基本解:$(9, 0, 0, 21, 6, 0)$
- 目标值:$z = 27$

---

**步骤3:第二次迭代**

**观察分析:**

- 增加 $x_2$ 或 $x_3$ 都可增加目标值
- 设选择 $x_3$,从三个式子可知 $x_3$ 的最大值分别为 $18, 42/5, 3/2$
- 因此,选择第3个约束($x_3$ 最多取 $3/2$),围绕 $x_3$ 和 $x_5$ 进行转动
- **互换 $x_3$ 和 $x_5$**($x_3$ 入基,$x_5$ 出基)

**第二次迭代后:**

$$
\begin{align}
z &= \frac{111}{4} + \frac{x_2}{16} - \frac{x_5}{8} - \frac{11x_6}{16} \\
x_1 &= \frac{33}{4} - \frac{x_2}{16} + \frac{x_5}{8} - \frac{5x_6}{16} \\
x_3 &= \frac{3}{2} - \frac{3x_2}{8} - \frac{x_5}{4} + \frac{x_6}{8} \\
x_4 &= \frac{69}{4} + \frac{3x_2}{16} + \frac{5x_5}{8} - \frac{x_6}{16}
\end{align}
$$

---

**步骤4:第三次迭代**

**第三次迭代后:**

$$
\begin{align}
z &= 28 - \frac{x_3}{6} - \frac{x_5}{6} - \frac{2x_6}{3} \\
x_1 &= 8 + \frac{x_3}{6} + \frac{x_5}{6} - \frac{x_6}{3} \\
x_2 &= 4 - \frac{8x_3}{3} - \frac{2x_5}{3} + \frac{x_6}{3} \\
x_4 &= 18 - \frac{x_3}{2} + \frac{x_5}{2}
\end{align}
$$

**最终基本解:**

- 此时,基本解是 $(8, 4, 0, 18, 0, 0)$
- 目标值 $z = 28$
- **因为目标函数中所有非基本变量的系数都是负数,无法继续增加目标值,求解结束!**

**最优解:** $x_1 = 8, x_2 = 4, x_3 = 0$,最大值 $z = 28$

---

**算法总结:**

1. **转换为松弛型**:引入松弛变量将不等式转换为等式

2. **找到初始基本可行解**:将所有非基本变量设为 $0$

3. **检验是否最优**:检查目标函数中非基本变量的系数
   - 如果都 $\leq 0$(最大化问题),则达到最优
   - 如果都 $\geq 0$(最小化问题),则达到最优

4. **选择入基变量**:选择目标函数系数为正(最大化)或负(最小化)的非基本变量

5. **选择出基变量**:选择使入基变量取值最小的约束对应的基本变量

6. **基变换**:通过代数运算更新松弛型

7. **重复步骤3-6**:直到达到最优或判定无界

### 二、整数规划：问题定义

#### 1. 整数规划的基本概念

**整数规划的定义:**

**整数规划(Integer Programming, IP)** 是在线性规划基础上,要求部分或全部决策变量必须取整数值的优化问题。

**一般形式:**

$$
\begin{align}
\text{最大化(或最小化)} \quad & \sum_{i=1}^{n} c_ix_i \\
\text{满足约束条件:} \quad & \sum_{i=1}^{n} a_{ji}x_i \leq b_j \quad (j = 1,2,...,m) \\
& x_i \geq 0, \quad x_i \in \mathbb{Z} \quad (\text{部分或全部}\ i)
\end{align}
$$

---

**整数规划的分类:**

根据变量的整数要求不同,整数规划可分为三类:

**(1)混合整数规划(Mixed Integer Programming, MIP)**

部分变量必须是整数,部分变量可以是连续值。对部分域所有$x_i$,满足:$x_i \geq 0$且为整数。

**(2)纯整数规划(Pure Integer Programming, PIP)**

所有决策变量都必须取整数值。对每个$x_i$,满足:$x_i \geq 0$且为整数。

**(3)0-1整数规划(Binary Integer Programming)**

变量只能取0或1两个值,用于表示"是/否"决策。对每个$x_i$,满足:$x_i \in \{0,1\}$。

---

#### 2. 整数规划的实际应用示例

**运输问题:**

需要运输180台电视和110台洗衣机。有两种运输方式:

- **小型货车**:可装载20台电视和20台洗衣机,成本360元
- **大型卡车**:可装载40台电视和10台洗衣机,成本400元

**数学模型:**

$$
\begin{align}
\text{最小化} \quad & 360x_1 + 400x_2 \\
\text{满足约束条件:} \quad & 20x_1 + 40x_2 \geq 180 \\
& 20x_1 + 10x_2 \geq 110 \\
& x_1, x_2 \geq 0, \quad x_1, x_2 \in \mathbb{Z}
\end{align}
$$

其中$x_1$表示使用小型货车的数量,$x_2$表示使用大型卡车的数量。

---

#### 3. 整数规划的建模技术

**技术1:定义二元变量**

除了约定部分或所有变量必须为整数值之外,也允许定义二元变量,即:$x_i \in \{0,1\}$。

**优势**：能够引入逻辑约束

**示例**：假设$x_i \in \{0,1\}$:

- 如果选择了$x_1$,则不能选择$x_2$,那么可以表示成:$x_1 + x_2 \leq 1$;

- 如果选择了$x_1$,则必须选择$x_2$,那么可以表示成:$x_1 \leq x_2$;

- 必须选择$x_1$或$x_2$,或两者均选取,那么可以表示成:$x_1 + x_2 \geq 1$;

---

**技术2:限定变量的范围**

**目标**：限定变量$x$的范围是:$x \leq 2$或者$x \geq 6$

**方法:**

挑选一个二元变量$w = \begin{cases} 1, & x \leq 2 \\ 0, & x \geq 6 \end{cases}$

设定$M$是一个很大的数,转变成为IP约束:

$$
\begin{align}
x &\leq 2 + M(1-w) \\
x &\geq 6 - Mw \\
w &\in \{0,1\}
\end{align}
$$

**验证:**

- 如果$x \leq 2$,则令$w = 1$:约束变为$x \leq 2$和$x \geq 6 - M$(后者自动满足)
- 如果$x \geq 6$,则令$w = 0$:约束变为$x \leq 2 + M$(自动满足)和$x \geq 6$

在两种情况下,IP约束都被满足。

---

**技术3:表达复杂表达式之间的"或"关系**

**目标**：表达复杂表达式之间的"或"关系

**示例**：$x_1 + 2x_2 \geq 12$或$4x_2 - 10x_3 \leq 1$

**整数规划建模:**

$$
\begin{align}
x_1 + 2x_2 &\geq 12 - M(1-w) \\
4x_2 - 10x_3 &\leq 1 + Mw \\
w &\in \{0,1\}
\end{align}
$$

**验证:**

- 如果$w = 1$,则第一个约束生效:$x_1 + 2x_2 \geq 12$
- 如果$w = 0$,则第二个约束生效:$4x_2 - 10x_3 \leq 1$

---

**技术4:考虑分段线性函数**

**目标**：表达分段线性函数

**示例:**

$$
y = \begin{cases}
2x, & \text{if } 0 \leq x \leq 3 \\
9-x, & \text{if } 4 \leq x \leq 7 \\
-5+x, & \text{if } 8 \leq x \leq 9
\end{cases}
$$

**建模方法:**

每段分别定义$w_i$和$x_i$:

$$
w_1 = \begin{cases} 1, & 0 \leq x \leq 3 \\ 0, & \text{otherwise} \end{cases}, \quad
x_1 = \begin{cases} x, & 0 \leq x \leq 3 \\ 0, & \text{otherwise} \end{cases}
$$

类似地定义$w_2, x_2$和$w_3, x_3$

**约束系统:**

$$
\begin{align}
& 0 \leq x_1 \leq 3w_1, \quad w_1 \in \{0,1\} \\
& 4w_2 \leq x_2 \leq 7w_2, \quad w_2 \in \{0,1\} \\
& 8w_3 \leq x_3 \leq 9w_3, \quad w_3 \in \{0,1\} \\
& w_1 + w_2 + w_3 = 1 \\
& x = x_1 + x_2 + x_3 \\
& x_i \text{ integer } \forall i
\end{align}
$$

**最终表达式:**

$$y = 2x_1 + (9w_2 - x_2) + (-5w_3 + x_3)$$

---

#### 4. 整数规划问题求解:从两个变量开始

**案例问题:**

$$
\begin{align}
\text{Maximize: } z &= 3x + 4y \\
\text{Subject to: } & 5x + 8y \leq 24 \\
& x, y \geq 0, \quad x, y \in \mathbb{Z}
\end{align}
$$

**简单的解法:**

- 先求解线性规划(忽略整数要求),得到$x = 4.8, y = 0$和$z = 14.4$
- 四舍五入,得到$x = 5, y = 0$,但此解不可行!
- 取整,得到$x = 4, y = 0$,且$z = 12$。该解与$x = 0, y = 3$时的解值相同。

**最优解:**$x = 3, y = 1$,且$z = 13$

**结论:**

- Q1:最优整数解是什么? $(3, 1)$
- Q2:能否使用线性规划来解决整数规划问题? 不能直接使用,需要专门的算法

### 三、整数规划：分支界定法（Branch and Bound）

#### 1. 枚举树 - 完全枚举思想

**0-1背包问题示例:**

有6件物品,背包容量不超过14,求最大利用率:

| 物品 | iPad | server | Brass Rat | Au Bon Pain | 6.041 tutoring | 15.053 dinner |
|------|------|--------|-----------|-------------|----------------|---------------|
| 价格 | 5 | 7 | 4 | 3 | 4 | 6 |
| 利用率 | 16 | 22 | 12 | 8 | 11 | 19 |

**数学模型:**
$$
\begin{align}
\text{Maximize: } & 16x_1 + 22x_2 + 12x_3 + 8x_4 + 11x_5 + 19x_6 \\
\text{Subject to: } & 5x_1 + 7x_2 + 4x_3 + 3x_4 + 4x_5 + 6x_6 \leq 14 \\
& x_i \in \{0,1\} \quad \text{for } 1 \leq i \leq 6
\end{align}
$$

**枚举法分析:**

- 考虑决策变量的所有可能值,即:$n \rightarrow 2^n$
- 想法:将问题分成两部分迭代。首次迭代时,考虑$x_1 \in \{0,1\}$的情况
- 树中的每个节点代表原始问题加上额外的约束条件

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMjaVoBTouvp1AvSDp_b3CmLWbTp4EAApsNaxtn5tFW6-nZU-GZ9swBAAMCAAN3AAM4BA.png)

**枚举树基本概念:**

- **节点2和节点3**被称为枝举树中节点1的**子节点**
- **IP(1)** 是原始的整数规划问题
- **IP(2)** 通过向IP(1)添加约束条件"$x_1 = 0$"得到
- **IP(3)** 通过向IP(1)添加约束条件"$x_1 = 1$"得到
- **IP(1)的最优解**可以通过从IP(2)和IP(3)中选取最好的解来获得（*整数解*）
- **最优解也可能**在IP(2)和IP(3)两个分支中

#### 2. 整数规划线性松弛

**线性松弛(LP relaxation)的定义:**

如果去掉变量必须为整数的要求,就称其为整数规划问题的**线性松弛**。

**背包问题的线性松弛:**

$$
\begin{align}
\text{最大化: } & 24x_1 + 2x_2 + 20x_3 + 4x_4 \\
\text{约束条件: } & 8x_1 + 1x_2 + 5x_3 + 4x_4 \leq 9 \\
& 0 \leq x_i \leq 1, \quad \text{对于 } 1 \leq i \leq 4
\end{align}
$$

**贪心算法求解:**

背包问题的线性松弛可以通过"贪心算法"来求解:

可以将目标函数看作是美元金额,并将约束条件视为对重量的限制。

| item | 1 | 2 | 3 | 4 |
|------|---|---|---|---|
| value/lb. | \$3 | \$2 | \$4 | \$1 |

**求解策略:**

如果按照每磅价值从高到低依次将物品放入背包,会得到什么结果?

通过求解每个整数规划问题的线性松弛,可为每个整数规划问题得到一个界限。

**（1） LP(k)的求解结果会给出一个具体的界限值。**

**示例:LP(4)的求解**

$$
\begin{align}
\text{Maximize: } & 24x_1 + 2x_2 + 20x_3 + 4x_4 \\
\text{Subject to: } & 8x_1 + 1x_2 + 5x_3 + 4x_4 \leq 9 \\
& x_1 = 0, x_2 = 0 \\
& 0 \leq x_i \leq 1 \text{ for } 3 \leq i \leq 4
\end{align}
$$

- LP(4)的最优解:$x_1 = 0, x_2 = 0, x_3 = 1, x_4 = 1, z = 24$
- 如果LP(k)的最优解对于IP(k)也是可行的,那么它也是IP(k)的最优解

**重要性质:**

对于所有$j$来说,$z_{IP}(j) \leq z_{LP}(j)$,例如:$z_{IP}(1) \leq 32$

不直接求解IP(k),而是求其线性松弛(LP relaxation),以获得边界值。

**（2）当前最优解(incumbent)的定义:**

算法偶然找到的、具有最佳目标函数值的可行整数解。

**注意**：当前最优解是整数规划问题的一个可行解,且是迄今为止找到的最佳解。

**LP(1)的求解:**

$$
\begin{align}
\text{Maximize: } & 24x_1 + 2x_2 + 20x_3 + 4x_4 \\
\text{Subject to: } & 8x_1 + 1x_2 + 5x_3 + 4x_4 \leq 9 \\
& 0 \leq x_i \leq 1 \text{ for } i = 1 \text{ to } 4
\end{align}
$$

- LP(1)的最优解:$x_1 = 1/2, x_2 = 0, x_3 = 1, x_4 = 0, z = 32$

**重要观察:**

对于所有$j$来说,$z_{IP}(j) \leq z_{LP}(j)$,例如:$z_{IP}(1) \leq 32$

**（3） 剪枝**

**推论**：如果$z_{LP}(k) \leq z_I$,可以剪枝活动节点$k$的IP(k),其中$z_I$是当前最优解的目标函数值。

**活动节点**：节点尚未被剪枝,并且LP(k)还没有被解出来

**LP(2)的分析:**

$$
\begin{align}
\text{Maximize: } & 24x_1 + 2x_2 + 20x_3 + 4x_4 \\
\text{Subject to: } & 8x_1 + 1x_2 + 5x_3 + 4x_4 \leq 9 \\
& x_1 = 0 \\
& 0 \leq x_i \leq 1 \text{ for } i = 2 \text{ to } 4
\end{align}
$$

- LP(2)的最优解为:$z_{LP}(2) = 25$
- 假设我们已经知道了一组解:$x_1 = 1, x_2 = 1, x_3 = 0, x_4 = 0, z_I = 26$,则可以剪枝LP(2)

---

#### 3. 分支界定算法的完整流程

**在什么条件下,我们不能从最大化的分支定界树中剪枝活动节点$j$?**

**算法伪代码:**

```
while there is some active nodes do
    select an active node j
    mark j as inactive
    Solve LP(j): denote solution as x(j);
    Case 1 -- if z_LP(j) ≤ z_I then prune node j;
    Case 2 -- if z_LP(j) > z_I and
              if x(j) is feasible for IP(j)
              then Incumbent := x(j), and z_I := z_LP(j);
              then prune node j;
    Case 3 -- if z_LP(j) > z_I and
              if x(j) is not feasible for IP(j) then
              mark the children of node j as active
endwhile
```

**中文说明:**

当存在某些活动节点时,执行以下操作:
- 选择一个活动节点$j$
- 将$j$标记为不活动
- 求解LP(j):令$x(j)$表示解决方案;
- **情况1**--如果$z_{LP}(j) \leq z_I$,则剪枝节点$j$;
- **情况2**--如果$z_{LP}(j) > z_I$且$x(j)$是IP(j)的可行解,则Incumbent $:= x(j)$,$z_I := z_{LP}(j)$;然后剪枝节点$j$;
- **情况3**--如果$z_{LP}(j) > z_I$且$x(j)$不是IP(j)可行解,则标记节点$j$的子节点为活动节点

结束循环

---

#### 4. 分支界定法案例

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMkaVoGiOWpcgq6az-mMRXSFgP_1cQAArsNaxtn5tFWpVsQCV-DqPwBAAMCAAN4AAM4BA.png)

**初始状态:LP(1)**
$$
\begin{align}
\text{Maximize: } & 24x_1 + 2x_2 + 20x_3 + 4x_4 \\
\text{Subject to: } & 8x_1 + 1x_2 + 5x_3 + 4x_4 \leq 9 \\
& 0 \leq x_i \leq 1 \text{ for } i = 1 \text{ to } 4
\end{align}
$$

- 没有当前最优解,$z_I = -\infty$
- LP(1)的最优方案是:$x_1 = 1/2, x_2 = 0, x_3 = 1, x_4 = 0, z_{LP}(2) = 32$

**分支到LP(2):**

- LP(2)的最优方案是:$x_1 = 0, x_2 = 1, x_3 = 1, x_4 = 3/4, z_{LP}(2) = 25$

**分支到LP(3):**

- 没有当前最优解,$z_I = -\infty$,$z_{LP}(1) = 32$
- LP(3)的最终方案是:$x_1 = 1, x_2 = 0, x_3 = 1/5, x_4 = 0, z_{LP}(3) = 28$

**分支到LP(4):**

- 没有当前最优解,$z_I = -\infty$,$z_{LP}(1) = 32$
- LP(4)的最优解:$x_1 = 0, x_2 = 0, x_3 = 1, x_4 = 1, z_{LP}(4) = 24$
- **剪枝完毕(因为都是整数)**，更新$z_I = 24$

**分支到LP(5):**

- 最优可行解$z_I = 24$
- LP(5)的最终方案是:$x_1 = 0, x_2 = 1, x_3 = 1, x_4 = 3/4, z_{LP}(5) = 25$

**分支到LP(6):**

- 当前最优解$z_I = 24$
- LP(6)的最优方案是:$x_1 = 1, x_2 = 0, x_3 = 1/5, x_4 = 0, z_{LP}(6) = 28$

**分支到LP(7):**

- 当前最优解$z_I = 24$
- LP(7)的最优解:$x_1 = 1, x_2 = 1, x_3 = 0, x_4 = 0, z_{LP}(7) = 26$
- **剪枝完毕(界限剪枝)**

**分支到LP(8):**

- 当前最优解$z_I = 26$  **(更新)**
- LP(8)的最优解:$x_1 = 0, x_2 = 1, x_3 = 1, x_4 = 1, z_{LP}(8) = 6$
- **子树剪枝(界限剪枝,因为$z_{LP}(8) < z_I$)**

**分支到LP(9):**

- 当前最优解$z_I = 26$
- LP(9)的最优解:$x_1 = 0, x_2 = 1, x_3 = 1, x_4 = 3/4, z_{LP}(9) = 25$
- **子树剪枝(界限剪枝,因为$z_{LP}(9) < z_I$)**

**分支到LP(10):**

- 当前最优解$z_I = 26$
- LP(10)的最优解:$x_1 = 1, x_2 = 0, x_3 = 0, x_4 = 1/4, z_{LP}(10) = 25$
- **子树剪枝(界限剪枝,因为$z_{LP}(10) < z_I$)**

**最终分支LP(11):**

- 当前最优解$z_I = 26$
- LP(11)的最优解:**无可行解,可被剪枝**
- **剪枝完毕(不可行剪枝)**

**最终结果:**

- 最优整数解:$x_1 = 0, x_2 = 1, x_3 = 1, x_4 = 1, z^* = 26$
---

#### 5. 分支界定法的经验总结

**算法优势:**

- 分支定界法可以加快搜索速度,仅解决**部分节点**的线性规划问题

**算法局限:**

- 分支定界法依赖于**剪枝子树**,这可能是因为节点处的整数规划(IP)问题已经被解决,或者因为该IP解不可能是最优解
- 当变量很多时,完全枚举不可能负担(即使是仅50个变量也有很大消耗)

**加速技巧:**

- **技巧一**：能够"智能地"选择最佳分支变量的启发式规则
- **技巧二**：使用"取整",例如,将非整数解通过向上或向下取整转换为整数解,以此来快速获得可行解,从而缩小搜索范围
- **示例:**$x_1 + x_2 \leq 1.5 \rightarrow x_1 + x_2 \leq 1$,or $z_{IP} \leq z_{LP} = 5.5 \rightarrow z_{IP} \leq 5$

### 四、整数规划：切平面法（Cutting Plane Method）

#### 1. 有效不等式(Valid Inequalities)

**定义:**

整数规划(IP)的有效不等式是指任何**不会排除任何可行整数解**的约束条件。

**示例问题:**

最大化目标函数:$z = 3x + 4y$

约束条件:$5x + 8y \leq 24$
$0 \leq x, y \in \mathbb{Z}$(即x和y都是非负整数)

**有效不等式的特点:**

- 约束条件$x \leq 5$是一个有效不等式
- 约束条件$x \leq 4$同样是一个有效不等式
- 整数规划的一个有效不等式也被称为**切割平面**或**切面**

**目标:**

希望找到能排除部分线性规划可行区域的切割平面。

![有效不等式图示](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMlaVoR1E2YTnF2FhTwYl6bxsZpUzoAAvQNaxtn5tFW7ufGbh4AAcs6AQADAgADeQADOAQ.png)

---

#### 2. 取整(Rounding)技术

**基本原理:**

一个分数形式的整数变量**边界可以被截断**。

**示例:**

$x \leq 1.5 \rightarrow x \leq 1$

**整数系数约束的取整:**

给定一个涉及所有整数变量且系数也为整数的约束条件:

$3x + 6y + 9z \leq 11$ 可以转化为 $x + 2y + 3z \leq \lfloor 11/3 \rfloor = 3$

**非负整数变量约束的取整:**

对于涉及非负整数变量的约束条件:

$\sum a_i x_i \leq b$ 可以转化为 $\sum \lfloor b/a_i \rfloor x_i \leq \lfloor b \rfloor$

**注意事项:**

注意左边是整数,因此右边也可以被截断,但这并不一定比原始约束条件更严格。

---

#### 3. Gomory切割(Gomory Cuts)

**定义:**

Gomory切割用于**向所有整数规划问题(IPs)中添加有效不等式**(也称为切割),对于**改进界限**非常有用。

**核心思想:**

Gomory切割是从线性规划(LP)松弛的最优单纯形表中的单个约束条件获得的。

**假设前提:**

这里假设所有变量必须取整数值。

**情况一:所有左侧系数都在0到1之间**

约束形式:$0.2x_1 + 0.3x_2 + 0.3x_3 + 0.5x_4 + x_5 = 1.8$

有效不等式(忽略来自$x_5$的贡献):

$0.2x_1 + 0.3x_2 + 0.3x_3 + 0.5x_4 \geq 0.8$

这种有效不等式通过从最优解中提取信息并创建新的约束条件,有助于排除非整数解,从而提高求解效率。

**情况二:所有左边的系数都是非负的**

约束形式:$1.2x_1 + 0.3x_2 + 2.3x_3 + 2.5x_4 + x_5 = 4.8$

有效不等式(focus on fractional parts):

$0.2x_1 + 0.3x_2 + 0.3x_3 + 0.5x_4 \geq 0.8$

**情况三:通用情况**

约束形式:$1.2x_1 - 1.3x_2 - 2.4x_3 + 11.8x_4 + x_5 = 2.9$

向下取整(特别担心负数):

$1x_1 - 2x_2 - 3x_3 + 11x_4 + x_5 \leq 2$

有效不等式(前面两个式子相减):

$0.2x_1 + 0.7x_2 + 0.6x_3 + 0.8x_4 \geq 0.9$

---

#### 4. 凸包(Convex Hull)

**定义:**

凸包是包含所有整数解的最小线性规划可行区域。

**示例1:**

最大化:$z = 3x + 4y$

约束条件:$5x + 8y \leq 24$ 
$0 \leq x, y \in \mathbb{Z}$

**添加凸包** ：  $ x + y ≤ 4,2x + 3y ≤ 9$

![凸包图示1](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMmaVoTIED8Jx_l_NbxNkksTOwvIg4AAvoNaxtn5tFWthiy-L85d48BAAMCAAN4AAM4BA.png)

**示例2:**

最大化:$z = x + y$

约束条件:$-5x + 4y \leq 0$
$6x + 2y \leq 17$
$0 \leq x, y \in \mathbb{Z}$

使用取整技术添加约束条件： $x ≤ 2,y ≤ x$

![凸包图示2](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMnaVoUFo5v-hVxICr6VmaZhEmAnrQAAvwNaxtn5tFWcVULVP5ieN8BAAMCAAN5AAM4BA.png)

---

#### 5. 切平面算法

**算法步骤:**

**步骤1**：求解线性规划松弛问题

**步骤2**：如果线性规划解是整数解,则它是原始问题的最优解。任务完成!

**步骤3**：如果线性规划解不是整数解,找到一个线性约束条件,该条件**排除线性规划解**但不排除任何整数点(总是可能的);

**步骤4**：加入切割约束条件;

**步骤5**：返回步骤1。

---

#### 6. 切平面法案例详解

**初始问题:**

最大化:$z = x + y$

约束条件:$-5x + 4y \leq 0$
$6x + 2y \leq 17$
$0 \leq x, y \in \mathbb{Z}$

有效不等式:$0 \leq x, y \in \mathbb{Z}$

最优解 = 4.5（$x = 2,y=2.5$）

![初始问题图示](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMqaVoVlJHCGdBIm-27MjKILL7tAAEfAAMOaxtn5tFWlQVbfx2xXokBAAMCAAN4AAM4BA.png)

**迭代1:添加约束y ≤ 2**

- 最优解 z = 4.1667（$x = 13/6,y=2$）
- 移除整数约束以获得线性松弛
- 最优解是对最优成本的一个上界
- 如果解是整数,则它是原始问题的最优解

![迭代1图示](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMsaVoXTU7vQnKpXJjsmMcRVQg_C7EAAgYOaxtn5tFW3pbpHT5zMDsBAAMCAAN4AAM4BA.png)

**分析:**

约束条件$y \leq 2$是一个有效的切割,因为它排除了最优的线性规划解,但没有排除任何整数点。

现在求解这个新问题的线性规划松弛。

一个切割必须同时排除线性规划解,同时保留所有可行的整数点。至少存在一个有效的切割。

*此时，仍然有变量不完全是整数。再加一个切割！*

**迭代2:添加约束x ≤ 2**

最大化:$z = x + y$

约束条件:$-5x + 4y \leq 0$
$6x + 2y \leq 17$
$y \leq 2$
$x \leq 2$
$0 \leq x, y \in \mathbb{Z}$

最优解:$ x = 2, y = 2, z = 4$

![最终解图示](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMpaVoVT_stb7HITVRFa9qYrbd-3aYAAv8Naxtn5tFWCWS5apr0heUBAAMCAAN5AAM4BA.png)

*线性规划的解都是整数，因此也是整数规划问题的最优解*

---

#### 7. 切平面法的特点总结

**算法优势:**

- 通过添加切割约束逐步收紧可行域
- 每次迭代都会改进上界
- 最终必定收敛到整数最优解

**算法局限:**

- 可能需要多次迭代
- 每次迭代需要求解一个线性规划问题
- 选择合适的切割平面需要一定技巧

**与分支界定法的比较:**

- 切平面法通过添加约束收紧可行域
- 分支界定法通过分支和剪枝搜索解空间
- 实际应用中常将两种方法结合使用(分支切割法)

---

## 第七讲 内存计算

### 一、海量内存概述

#### 1. 传统数据处理模式 vs 内存数据处理模式

**传统数据处理模式：**

- CPU与内存之间频繁交互
- 内存与磁盘(硬盘)之间存在I/O瓶颈
- 数据需要从磁盘加载到内存，处理后再写回磁盘
- **I/O操作**成为性能瓶颈

**内存数据处理模式：**

- CPU**直接与内存交互**，减少I/O操作
- 数据主要存储和处理都在内存中完成
- 大幅减少或消除磁盘I/O瓶颈
- 显著提升数据处理速度

**核心理念：** Jim Gray在2006年提出的著名观点：

- "Tape is Dead"（磁带已死）
- "Disk is Tape"（磁盘就是磁带）
- "Flash is Disk"（闪存就是磁盘）
- "RAM Locality is King"（**内存局部性为王**）

**解释：** 随着技术发展，存储介质的角色在不断演变。**内存**成为数据处理的核心，其他存储介质逐渐降级为备份或归档用途。

#### 2. 海量内存技术的发展趋势

**硬件发展：**

- **存储器芯片集成度**不断提高
- 内存价格持续下降（如图所示，从1955年到2020年呈指数级下降）
- 内存容量大幅增长，使得海量数据内存处理成为可能

**新型硬件架构：**

- **3D XPoint™ Technology**（英特尔傲腾技术）等新型存储技术的出现

**带来的机遇与挑战：** 海量内存给传统的数据管理、数据挖掘方法带来了新的机遇和挑战，需要重新设计算法和系统架构。

#### 3. 内存计算的优势

根据Aberdeen Group 2011年的研究数据对比：

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMtaVoeE59BlQfj4t0X4ahe8HAKTqMAAiwOaxtn5tFW1WsewFiTD8sBAAMCAAN5AAM4BA.png)

| 性能指标                      | 使用内存计算 (n=33) | 不使用 (n=163)     | 内存计算优势      |
| ----------------------------- | ------------------- | ------------------ | ----------------- |
| **活跃业务数据量（中位数）**  | 38 TB               | 18 TB              | **2.1倍数据量**   |
| **分析数据量（中位数）**      | 14 TB (37%全部数据) | 4 TB (22%全部数据) | **3.5倍数据量**   |
| **数据分析/查询平均响应时间** | 42秒                | 75分钟             | **107倍速度提升** |
| **每小时处理数据量**          | 1200 TB             | 3.2 TB             | **375倍效率提升** |

**主要优势：**

1. **消除了磁盘的I/O瓶颈**
2. **提高了单位时间内数据处理的能力与数据访问速度**
3. **实现了对大规模海量数据的实时分析和运算**
4. **提升数据挖掘的效率和准确度**

### 二、基于单机版内存增大优势

#### 1.关联规则

**购物篮模型**：从庞大的消费者记录中抽取关于**购物模式的信息**。

- 频繁项集是购物篮模型最基本的问题——
  - 哪些商品经常被消费者同时购买（营销）
  - 也被称为"关联规则"
  - 从病例中寻找患某种疾病的病人的共同特征等。

**关联规则挖掘**：发现大量数据中**项集之间的相关联系**，是数据挖掘中最活跃的研究领域之一。

**关联规则定义**：设I = {I₁, I₂, ..., Iₘ}是一个项目的集合，事务tᵢ(i = 1,2,...,n)是I的一个子集，则由一系列具有唯一标识TID的事务组成的D = {t₁, t₂, ..., tₙ}称为事务数据库。

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMuaVpJOJXGp6bmdSq9xPErzavBbpkAAlgLaxtn5tlW-LoCJ-HaN-IBAAMCAAN5AAM4BA.png)

关联规则形如X ⇒ Y的蕴含式，X ⊆ I，Y ⊆ I，X∩Y = ∅。

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMvaVpJz1bgQe-NDV3fv9FOJiMvM70AAl0Laxtn5tlW8LqsxQABEw8xAQADAgADeAADOAQ.png)

**度量指标**：

- 支持度(support)：support(面包,牛奶,尿布) = 2/5，计算公式为同时购买面包,牛奶,尿布的记录数/数据集记录总数
- 置信度(confidence)：confidence(面包⇒牛奶,尿布) = 2/4，计算公式为同时购买面包,牛奶,尿布的记录数/数据集中购买面包的记录数

**关联规则挖掘包含两个子问题**：

- ①发现**频繁项目集**(基础和研究重点)：寻找所有满足支持度不小于用户给定的minsupport的项目集
- ②生成关联规则：在已经发现的最大频繁项目集中，寻找置信度不小于用户给定的minconfidence的关联规则（一条规则的置信度很容易从支持度计数中推出；生成关联规则相对简单，且在内存、I/O、算法效率上的改进余地不大）

#### 2.Apriori算法

**基本信息**：最经典的关联规则挖掘算法，由Agrawal等人于1993年提出。

**基本思路**：逐层迭代，通过连接和剪枝来生成频繁项集。流程为：数据库 → 候选1-项集 →(剪枝)→ 频繁1-项集 →(连接)→ 候选2-项集 → ... → 频繁k-项集

**两条定理——先验性质**：

- 如果一个集合是频繁项集，则它的所有子集都是频繁项集
- 如果一个集合不是频繁项集，则它的所有超集都不是频繁项集

**基本步骤**：

1. 假设规模为k的频繁项集为Lₖ，它的候选项集为Cₖ。
2. 扫描数据库，对每一项进行累加计数，寻找规模为1的满足minsupport的频繁项集，然后迭代进行以下三步操作，生成所有的频繁项集：
   - ①从规模为k的频繁项集中生成规模为k+1的频繁项集的候选集Cₖ₊₁；
   - ②扫描数据库，计算候选项集中每一个候选的支持度；
   - ③将满足最小支持度的项加入Lₖ₊₁。

**发现频繁项集**：以minsupport=2（绝对支持度计数）为例，通过多趟扫描逐步生成C₁→L₁→C₂→L₂→C₃→L₃。

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMwaVpNgZm8EZj3RNcfQnavZQbn9-gAAmoLaxtn5tlW7BKOu9_vQawBAAMCAAN3AAM4BA.png)

**生成关联规则**：给定一个频繁项集I，对于它的每个非空子集a，生成满足minconfidence的规则a ⇒ (I-a)，该规则的confidence = support(I) / support(a)。示例：L₂中频繁项{I₁,I₂}，规则I₁⇒I₂的置信度 = 4/6，规则I₂⇒I₁的置信度 = 4/7。

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMxaVpOQQeqG9aLfhr7-Ruu0597WdgAAm8Laxtn5tlWfOnZQiv5Km4BAAMCAAN3AAM4BA.pngg)

**算法分析**：虽然简单且易于实现，是最具代表性的关联规则挖掘算法，

**缺点**：

1. 但随着数据集规模的不断增长，逐渐显现出一定的局限性：需多次扫描数据库，很大的I/O负载，算法的执行效率较低；
2. 产生大量的候选项目集，会消耗大量的内存；
3. 对于每一趟扫描，只有当内存大小足够容纳需要进行计数的候选集时才能正确执行。如果内存不够大，要么使用一种空间复杂度更小的算法，要么只能对一个候选集进行多次扫描，否则将会出现"**内存抖动**"的情况，即在一趟扫描中页面频繁地移进移出内存，造成运行时间的剧增。

**观察**：在Apriori算法的整个过程中，第一趟扫描时只需对规模为1的项计数，相对于对规模为2的项进行计数所需的空间而言是非常小的，而在第二趟扫描时，所有的可用空间基本都投入用于对候选集C₂进行计数。通过实验发现Apriori算法的内存瓶颈在**第二趟**扫描时出现，即对候选集C₂进行计数比对候选集C₃、C₄或规模更大的候选集进行计数所需的空间更大。

#### 3.PCY算法

**基本信息**：得名于作者Park、Chen和Yu，1995年提出。将哈希技术引入频繁项集发现中，利用第一趟扫描时未使用的大量内存空间来完整地存放一张哈希表，**减少了第二趟扫描时候选集C₂的数量。**

**主要思想**：

- 第一趟扫描：对单个项进行计数的同时将商品对散列到对应的桶中，并将该桶的计数加1。频繁桶为最终计数值不小于minsupport的桶，非频繁桶为最终最终计数值小于minsupport的桶。
- 第二趟扫描：即使一个2-项集中的每一项都是频繁的，但如果它被**散列**到非频繁桶中，它就不可能是频繁项集，可以从候选项集中删除，这样就可大大减少要考虑的2-项集。
- 第一趟扫描与第二趟扫描之间：把桶替换成对应的二进制位的位图，如果对应的是频繁桶则该位为1，否则为0。一个占32位(4字节)的桶被换成了1位，在第二趟扫描时只需要1/32的空间并销，因此在第二趟扫描时，PCY算法可用来计数的空间几乎和Apriori算法一样大。

**步骤**：第一遍扫描生成频繁1-项集，同时对2-项集进行哈希得到哈希表和位向量；第二遍扫描通过L₁自连接生成候选集，使用位图过滤（只有哈希到频繁桶的才是候选），对候选项对计数。结果是候选2-项集的数目大大减少。

- 第一步：确定每个项的 order（顺序编号）

  根据字母顺序：

  - **A 的 order = 1**
  - **B 的 order = 2**
  - **C 的 order = 3**
  - **D 的 order = 4**
  - **E 的 order = 5**

- 第二步：计算每个2-项集的哈希位置
  - 例子1：{A, C}

    ``` 
    h(A,C) = (1 × 10 + 3) mod 7
           = 13 mod 7
           = 6  ✅ 映射到位置6
    ```

  - 例子2：{B, C}

    ``` 
    h(B,C) = (2 × 10 + 3) mod 7
           = 23 mod 7
           = 2  ✅ 映射到位置2
    ```

- 第三步：进行位向量统计
  - 统计当前桶的元素个数是否$>=2$
  - 得到如下位向量<1,0,1,0,1,0,1>

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMyaVpPV-fTVf_xvopMEywhtDq5t4QAAnwLaxtn5tlWAAHwclooRoU_AQADAgADdwADOAQ.png)

**优点**：高效地产生频繁项集，提升了性能；减少了数据库的扫描次数；减少计数所需的内存空间的大小。

**分析**：最差的情况是所有桶都是频繁桶，则第二遍扫描中PCY算法需要计算的相对数目与Apriori算法相比没有任何减少。在寻找频繁3-项集以及更多项集时，PCY算法与Apriori算法相同。

#### 4.多阶段算法

**主要思路**：

- 在PCY的第一遍和第二遍之间插入额外的扫描过程，将2-项集哈希到另外的**独立的哈希表**中（使用不同的哈希函数）。
- 在每个中间过程中，只需哈希那些在以往扫描中哈希到频繁桶的频繁项。
- 需要三次扫描数据库。

**步骤**：

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAMzaVpV0b8nyHumOHDu0hNE2BaDkKYAApALaxtn5tlWv8ydwdyCoqwBAAMCAAN3AAM4BA.png)

1. 第一趟扫描与PCY算法相同；
2. 第二趟扫描中2-项集{i,j}被哈希需满足①i和j都是频繁项、②第一趟扫描时{i,j}被哈希到了一个频繁桶，使用**不同的哈希函数**建立哈希表2；
3. 第三趟扫描中{i,j}是候选2-项集需满足①i和j都是频繁项、②第一趟扫描时{i,j}被哈希到频繁桶(查询Bitmap1)、③第二趟扫描时{i,j}被哈希到频繁桶(查询Bitmap2)。

**分析**：

- Pass3的第③个条件是多阶段算法与PCY算法最本质的区别。
  - 因为在第二趟扫描时，不是所有的2-项集都被散列到桶中，因此桶的计数值变得比第一趟扫描时更小，最终结果是**更多的桶变成非频繁桶**；(过滤更多)
  - 由于两次扫描采用的**哈希函数不同**，那些在第一趟扫描时被散列到频繁桶中的非频繁2-项集很可能在第二趟扫描时被哈希到一个非频繁桶中，故排除很多通过了前两个条件判断的2-项集。
- 多阶段算法寻找频繁2-项集不只局限于使用3次扫描，
  - 可以执行更多次用桶进行哈希的扫描，并且每次使用不同的哈希函数，后面的每一趟扫描都能排除更多的2-项集；
  - 但是如果扫描的次数过多，不仅算法的执行次数更长，也有可能导致最终可用的内存小到无法对所有的频繁2-项集进行计数。

#### 5.多哈希算法

**定义**：多哈希算法(Multihash Algorithm)是PCY算法的一种变形。

**思路**：对PCY算法的第一遍扫描进行修改，将内存划分为**多张哈希表**，第二遍扫描只需对所有哈希表中都哈希到频繁桶的两个频繁项组成的项对计数。

**与多阶段算法的区别**：多阶段算法是在连续的扫描过程中使用两个不同的哈希函数和哈希表，多哈希算法是在第一次扫描的过程中同时使用两个哈希函数和两张哈希表。

**步骤**：第一遍扫描统计频繁项，同时维护哈希表1和哈希表2；第二遍扫描输入频繁项+位图1+位图2，对同时在两个哈希表中都哈希到频繁桶的候选项对计数。

**分析**：

- **优点**是只要桶的平均计数不小于阈值，频繁桶的数目仍然比较多，这样一个非频繁2-项集同时哈希到两个哈希表的频繁桶内的**概率就更低**，可以减少第二遍扫描的运算量。
- **风险**是使用两个哈希表时，每个哈希表仅有PCY算法的一半的桶，这样每个桶上的平均计数会翻倍，必须保证大多数桶的**计数不会达到阈值**。
- 多哈希算法也**不只局限于使用两个哈希表**，风险是桶的平均计数可能会超过阈值。

### 三、基于共享式内存和分布式内存结合架构优势

#### 1.三种系统架构

**SMP (对称多处理)**
- 也称UMA (一致性存储访问)
- **各处理器平等,访问内存任何地址时间相同**
- 共享相同物理内存、总线结构和系统资源
- 主要特征是"**共享**",单一寻址空间,编程简单
- 缺点:受**总线**限制,可扩展性差

**MPP (大规模并行处理)**

- **多个SMP服务器**通过互联网络连接
- "**完全无共享(shared-nothing)**"架构
- 每个节点只访问**本地资源**,通过消息传递机制交互
- 优点:可扩展性好
- 缺点:**通信开销大**,编程困难

**NUMA (非一致性存储访问)**

- **访问本地内存速度远高于远端内存**
- 具有多个CPU模块,每个模块有独立的CPU、内存、I/O
- **每个CPU可访问系统中所有物理内存空间**
- 结合SMP和MPP优势:保持对称性和单一地址空间,同时具备可扩展能力
- 属于分布/共享内存结构

#### 2.SPADE算法

**基本思想**
- 利用**垂直数据格式**和**连接-剪枝策略**
- 只需对数据库进行**三次扫描**
- 产生频繁序列时只需对垂直数据序列进行**交集操作**

**数据表示:垂直格式**
- 将序列数据库从水平格式转换为垂直格式
- 每个项用**ID_list**表示,包含(CID, TID)对
  - CID: 客户/序列标识
  - TID: 事务/时间标识
- 通过扫描数据库构建每个项的ID_list
- 计算support: 统计ID_list中distinct CID数目

**算法流程**

*第一步: 生成频繁1-序列*

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM0aVpfTSa9b05mRJF5_uKQazgpzbEAAqkLaxtn5tlWwRomaXlblkEBAAMCAAN3AAM4BA.png)

- 扫描数据库,构建每个单项的ID_list
- 统计每个项的distinct CID数目
- 与minsupport比较,得到频繁1-序列

*第二步: 连接生成候选k-序列*

**示例: 从频繁1-序列生成频繁2-序列**

频繁1-序列的ID_list:

| 项b |  |  | 项c |  |
|-----|-----|-----|-----|-----|
| CID | TID | | CID | TID |
| 1 | 2 | | 2 | 3 |
| 1 | 3 | | 3 | 2 |
| 2 | 1 | | 3 | 5 |
| 2 | 4 | | | |
| 3 | 2 | | | |

**连接过程详解:**

要生成b→c(表示b在c之前发生):
- 查找同一个CID中,TID(b) < TID(c)的记录
- CID=1: b出现在TID=2,3; c出现在TID=无 → **没有满足条件的**
- CID=2: b出现在TID=1,4; c出现在TID=3 → TID(b)=1 < TID(c)=3 ✓
- CID=3: b出现在TID=2; c出现在TID=2,5 → TID(b)=2 < TID(c)=5 ✓

要生成c→b(表示c在b之前发生):
- 查找同一个CID中,TID(c) < TID(b)的记录
- CID=1: c出现在TID=无; b出现在TID=2,3 → **没有c,不满足**
- CID=2: c出现在TID=3; b出现在TID=1,4 → TID(c)=3 < TID(b)=4 ✓
- CID=3: c出现在TID=2,5; b出现在TID=2 → TID(c)=2不小于TID(b)=2 ✗


连接后生成的频繁2-序列ID_list:
| b→c (序列模式) |        |        | c→b (序列模式) |        |        |
| -------------- | ------ | ------ | -------------- | ------ | ------ |
| CID            | TID(b) | TID(c) | CID            | TID(c) | TID(b) |
| 2              | 1      | 3      | 2              | 3      | 4      |
| 3              | 2      | 5      |                |        |        |

- 频繁(k-1)-序列与频繁(k-1)-序列连接形成候选k-序列
- **连接规则**(必须同时满足):
  1. 共享相同的CID
  2. 前面项的TID必须在后面项的TID之前(遵守时间顺序)
- 通过两个序列的ID_list交集操作生成新序列的ID_list
- 例如: b→c表示在同一CID中,b的TID < c的TID

*第三步: 剪枝得到频繁k-序列*

**判断哪些候选序列是频繁的:**

假设最小支持度minsupport = 2(至少要在2个客户中出现)

- **b→c序列**: distinct CID = {2, 3} → 2个客户 → support=2 ≥ minsupport ✓ **保留,是频繁序列**
- **c→b序列**: distinct CID = {2} → 1个客户 → support=1 < minsupport ✗ **剪枝,不是频繁序列**

**最终得到频繁2-序列:**

| b→c (频繁序列) |        |        |
| -------------- | ------ | ------ |
| CID            | TID(b) | TID(c) |
| 2              | 1      | 3      |
| 3              | 2      | 5      |

**算法的实际意义:**

SPADE算法用于**序列模式挖掘** - 发现用户购买行为的规律:
**终止条件**

- 找不到频繁序列,或
- 无法通过连接形成候选序列时,算法结束

**优化特性**
- ID_list会随着频繁序列长度增加而减小
- 连接操作速度随之加快
- 减少了内存占用和计算开销

**等价类划分(搜索空间划分)**
- 采用**基于后缀的等价类**划分搜索空间
- 形如Y→X和YX的序列都归入后缀类[X]
- 每个等价类是独立的,包含生成所有共享相同后缀的频繁序列所需的完整信息
- 可以在内存中独立处理每个等价类
- 为pSPADE的并行化提供基础

#### 3.pSPADE算法

**算法背景**
- 第一个应用共享式内存架构进行并行序列模式挖掘的算法
- 工作在SGI Origin 2000系统(NUMA体系结构)的12台处理器上
- 采用硬件分布式共享存储(HDSM)架构

**任务拆分**
- 利用SPADE算法的等价类划分性质
- 所有处理器访问整个数据库的一份拷贝
- 并行地工作于不同的等价类,异步处理全局计算树
- 每个类的挖掘工作独立,处理器不需要同步

**负载均衡策略**

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAAM3aVpltKCdutU0wKTjZeTW6Idd2GYAAtMLaxtn5tlWXDm5bdbfyrwBAAMCAAN3AAM4BA.png)

*静态负载均衡(SLB)*

- 根据等价类中**元素数量**分配权重
- 按权重递减顺序排序,依次分配给当前权值和最小的处理器
- 分配完毕后完全异步,无需同步或交互
- **示例**：P0预先分配好了C1和C3，P1预先分配好了C2。然后就按照这个分配方案来实施。即使P1已经执行完毕所有任务了，它也无法分担P0的任务。

*类间动态负载均衡(CDLB)*

- 按权重将所有类递减排列成逻辑中心任务队列
- 处理器动态从队列获取类,处理完后自动获取下一个
- **示例**：首先预估所有任务的工作量，进行排序，得C1, C2, C3。然后，分配P0来执行C1，分配P1来执行C2。结束早的那个处理器来执行C3。

*递归动态负载均衡(RDLB)*
- 有空闲处理器时,在树的每一新层递归运用**CDLB方法**
- 不同处理器能够处理新层次上的不同类
- **示例**：首先预估工作量，排序得C1、C2、C3。然后P0预先分配好了C1和C3，P1预先分配好了C2，P1执行较快，则又执行C3。此时P0已经执行完毕，则它能够分配C3的子任务（X3）。依次类推，直到完全结束。

**算法优点**
- 减少数据库扫描次数,降低I/O操作开销
- 采用异步机制,只在负载失衡时同步
- 将搜索空间分成基于后缀的类,可独立处理
- 数据局域性最大化,同步最小化
- 动态负载均衡保证处理器负载均衡
- 解决大型数据库中搜索空间大、可扩展性差的问题

---

## 第八讲 社区发现

社区发现是复杂网络分析中的重要问题，目标是找出网络中紧密连接的节点群组。

### 一、图切割（Graph Partitioning）

#### 1. 社区划分问题

给定无向图 $G = (V, E)$，其中：

- $V$ 表示所有的顶点（节点）集合
- $E$ 表示所有的边集合

**任务：** 将所有顶点分成两个不相交的组：

- 组 $A$：包含一部分节点
- 组 $B = V\backslash A$：包含剩余的所有节点（即 $V$ 中除了 $A$ 之外的所有节点）

**核心问题：** 如何评判这个划分的好坏？

#### 2. 评判准则

一个良好的社区划分应该满足：

- **最大化社区内部的连接数**：同一个社区内的节点之间应该有尽可能多的边连接
- **最小化社区之间的连接数**：不同社区之间的连接应该尽可能少

#### 3. 割（Cut）的定义

为了量化划分的质量，我们引入"割"的概念。

**割(cut)** 是指：只有一个端点在社区 $A$ 内，另一个端点在社区 $A$ 外的所有边的权重之和。

数学表达式：

$$cut(A) = \sum_{i \in A, j \notin A} w_{ij}$$

**公式解释：**

- $i \in A$：节点 $i$ 在社区 $A$ 中
- $j \notin A$：节点 $j$ 不在社区 $A$ 中（即在社区 $B$ 中）
- $w_{ij}$：连接节点 $i$ 和节点 $j$ 的边的权重（如果是无权图，权重为1）
- $\sum$：对所有满足条件的边进行求和

**通俗理解：** 割就是"跨越两个社区的边的总权重"，这个值越小，说明两个社区之间的连接越少，划分越好。

**求解方法：** 存在多项式时间算法来求解最小割问题，特别是 **Edmonds-Karp 算法**，其时间复杂度为 $O(|V| \cdot |E|^2)$。

#### 4. 最小割 (Minimum-cut)

**目标：** 找到一个划分 $(A, B)$，使得 $cut(A,B)$ 的值最小。

$$\arg\min_{A,B} cut(A,B)$$

**公式解释：**

- $\arg\min$：表示"使得后面的值最小的参数"
- 即找到使 $cut(A,B)$ 最小的划分方式 $(A, B)$

**最小割的局限性：**

虽然最小割能找到连接最少的划分，但存在明显的问题：

- **只考虑簇间的联通性**：只关心两个社区之间有多少连接
- **不考虑簇内的连通性**：不关心每个社区内部的结构
- **可能产生不平衡的划分**：例如，将一个孤立的节点分离出来，只需要切断很少的边，但这样的划分是没有意义的

**举例说明：** 假设有一个图，其中有一个节点只通过一条边连接到主图，那么最小割会将这个节点单独分离出来（只需切断1条边），但这样的划分显然不合理。

#### 5. 归一化切割 (Normalized-cut)

为了解决最小割的问题，我们引入归一化切割，它同时考虑了簇间的连通性和各簇的规模。

**体积（Volume）的定义：** 首先需要定义社区 $A$ 的"体积" $vol(A)$：

$$vol(A) = \sum_{i \in A} k_i$$

其中 $k_i$ 是节点 $i$ 的度（degree），即连接到节点 $i$ 的所有边的权重之和。$vol(A)$ 表示至少有一个端点在社区 $A$ 中的所有边的总权重，反映了社区 $A$ 的"规模"或"密度"。

**归一化切割的定义：**

$$ncut(A,B) = \frac{cut(A,B)}{vol(A)} + \frac{cut(A,B)}{vol(B)}$$

**公式解释：**

- 第一项 $\frac{cut(A,B)}{vol(A)}$：割的大小相对于社区 $A$ 的规模
- 第二项 $\frac{cut(A,B)}{vol(B)}$：割的大小相对于社区 $B$ 的规模
- 两项相加：综合考虑两个社区的规模

**为什么要归一化？** 通过除以各自的体积，我们将割的大小"标准化"了。这样如果一个社区很大（$vol$ 很大），即使割的值不变，归一化后的值也会变小，从而避免了将单个节点分离出来的情况（因为单个节点的 $vol$ 很小，归一化后的值会很大）。

**优势：**

- 使划分更加平衡，避免产生极小的社区
- 同时考虑了社区间的连接和社区的规模

**挑战：**

- 计算归一化割是 NP-hard 问题
- 需要使用近似算法或启发式方法来高效地找到好的划分

#### 6. 练习题详解

[![image.png](https://i.postimg.cc/d0KTvKjj/image.png)](https://postimg.cc/0zcNdF3z)

**题目：** 对于给定的图(红色节点和绿色节点)，分别计算最优切割和最小切割的 $ncut$ 值。

**题目分析：** 从图中可以看到两种切割方式：

- **最优切割**（蓝色虚线）：在红色社区（左侧）和绿色社区（右侧）之间进行切割
- **最小切割**（红色虚线）：将右下角单个绿色节点孤立出来

**（1）最小切割的 $ncut$ 值计算**

划分方式：社区 $A$ 为红色节点+5个绿色节点，社区 $B$ 为右下角单个绿色节点。

- $cut(A,B) = 1$（只有1条边连接孤立节点）
- $vol(B) = 0$（节点完全孤立，内部没有边）
- $ncut_{\text{min}} = \frac{1}{vol(A)} + \frac{1}{0} = +\infty$

这说明**将单个节点完全孤立是一个极差的划分**！

**（2）最优切割的 $ncut$ 值计算**

划分方式：社区 $A$ 为所有红色节点（左侧10个节点），社区 $B$ 为所有绿色节点（右侧6个节点）。

- $cut(A,B) = 2$（2条边跨越蓝色虚线）
- $vol(A) = 2 \times 15 = 30$（红色区域内部15条边）
- $vol(B) = 2 \times 9 = 18$（绿色区域内部9条边）
- $ncut_{\text{optimal}} = \frac{2}{30} + \frac{2}{18} = \frac{1}{15} + \frac{1}{9} = \frac{8}{45} \approx 0.178$

**结果对比：**

| 切割方式 | $cut(A,B)$ | $vol(A)$ | $vol(B)$ | $ncut$ 值 |
| -------- | ---------- | -------- | -------- | --------- |
| 最小切割 | 1          | >0       | 0        | $+\infty$ |
| 最优切割 | 2          | 30       | 18       | 0.178     |

**结论：**

1. 最小切割将单个节点孤立后，$vol(B) = 0$ 导致 $ncut$ 值趋向无穷大，这是最差的划分
2. 最优切割虽然 $cut$ 值不是最小，但 $ncut$ 值很小，实现了平衡且合理的划分
3. 归一化切割通过考虑社区规模，避免了不合理的极端划分，$ncut$ 值越小说明划分越好

### 二、边介数（Edge Betweenness）

#### 1. 边介数的定义

**边介数（Edge Betweenness）**：通过该边的最短路径的数量。

**作用：**
- 用于衡量图中一条边的重要性或中心性
- 反映图中有多少条最短路径经过该边

**重要性判断：**
- 若很多最短路径都经过该边，则该边对于保持图的高效连接性就非常重要
- 相反，如果仅少数最短路径经过该边，则该边的重要性就较低

**应用价值：**

边介数有助于识别图中的关键连接，即这些连接一旦断裂会显著影响图中节点之间的通信效率。

**示例：**

[![image.png](https://i.postimg.cc/L892K9J7/image.png)](https://postimg.cc/mt507GNN)

在下图中，不同的边具有不同的边介数值：
- 左侧的边：$b = 16$（有16条最短路径经过）
- 右侧的边：$b = 7.5$（有7.5条最短路径经过）

边介数越大，该边在网络中的重要性越高。

#### 2. Girvan-Newman方法（简称GN方法）

**GN方法定义：**

Girvan-Newman方法是一种基于边介数概念的层次聚类算法，适用于无向无权网络。

**算法流程：**

重复以下步骤直到没有边剩余：
1. **计算边介数**：计算网络中所有边的边介数
2. **移除边介数最高的边**：找到边介数最大的边并将其从图中删除
3. **重新计算**：在每个步骤后，需要重新计算剩余边的边介数

**输出结果：**
- 相连接的边构成社区
- 可输出网络的层次分解

**重要提示：** 在每个步骤，均需重新计算边介数，因为移除一条边会影响其他边的最短路径。

#### 3. GN方法案例分析

考虑下图所示的网络，应用GN方法进行社区划分：

[![image.png](https://i.postimg.cc/QNQDn96X/image.png)](https://postimg.cc/JtzSsnVg)

**Step 1：** 计算所有边的边介数，移除边介数最高的边（边7-8，边介数为49）

结果：图被分成两个主要部分

**Step 2：** 重新计算剩余边的边介数，继续移除边介数最高的边

结果：进一步细分，形成更小的社区

**Step 3：** 持续迭代，直到所有边都被移除

结果：每个节点成为独立的社区

**最终输出：层次状的网络划分**

通过记录每次移除边的顺序，可以构建一个层次树（dendrogram），展示网络在不同粒度下的社区结构。

#### 4. 如何计算边介数

**（1）基本方法：构建根节点到其余子节点的最短路径数量**  

**步骤1：构建最短路径树**

从起始节点（如节点A）开始，使用BFS构建到所有其他节点的最短路径树，并标记每个节点的层次：
- 第0层：起始节点A
- 第1层：与A直接相连的节点（B, C, D, E）
- 第2层：距离A为2的节点（F, G, H）
- 第3层：距离A为3的节点（I, J）
- 第4层：距离A为4的节点（K）

**步骤2：计算最短路径数量**

计算从起始节点A到网络中其他每个节点的最短路径数量。

**公式：**

从A到某个节点X的最短路径数量 = 所有能到达X的**父节点**的最短路径数量之和

**示例：**

[![image.png](https://i.postimg.cc/0QgrRzLg/image.png)](https://postimg.cc/xkR9L1fg)

- 从A到H的最短路径数量 = 从A到D的最短路径数量 + 从A到E的最短路径数量
- 从A到K的最短路径数量 = 从A到I的最短路径数量 + 从A到J的最短路径数量

**（2）自底向上计算边介数**：如果存在多条最短路径，则可按比例划分边介数。

**算法步骤：**

1. **添加边流**
   - 初始化：每个节点的流 = 1 + 其所有子边的流之和
   - 根据父节点的值分配流

2. **对于每个起始节点U，重复广度优先搜索过程**

**详细计算规则：**

对于某条边 $(X, Y)$，其边介数的计算遵循以下规则：
- 如果从A到Y只有一条最短路径经过X，则该边获得完整的流
- 如果从A到Y有多条最短路径（通过不同的父节点），则按照各父节点的最短路径数量比例分配流

**具体案例：**

[![image.png](https://i.postimg.cc/bvGrGxQt/image.png)](https://postimg.cc/8FSN9rXp)

以节点为K为例：
- K对于A而言是**叶子节点**，所以他的流为1（根据算法规则：子节点的流为0），
- 共有2条最短路径可被分配，根据I，J各有三条最短路径，为3：3，即1：1，因此每条边分配 $\frac{1}{2}$

以节点I为例：
- A-I的最短路径总和算1，外加经过I到K的0.5，所以I的流为1.5
- I有1.5可被分配，按照2:1的比例划分（因为A到F有2条最短路径，到G有1条最短路径）
- 故边$V_{F,I}$得到的流为1，边$V_{G,I}$得到的流为0.5

以此自下而上故能得到所有边的边介数

#### 5. 练习题

**题目**：给定下图所示的网络结构，请计算从节点B开始的路径边介数。

[![image.png](https://i.postimg.cc/Y0bsBHGx/image.png)](https://postimg.cc/CnnNb94Z)



**步骤1：构建最短路径树**

从起始节点B开始，使用BFS构建到所有其他节点的最短路径树，并标记每个节点的层次：

- 第0层：起始节点B
- 第1层：与B直接相连的节点（A，C，F）
- 第2层：距离B为2的节点（D，E，I）
- 第3层：距离B为3的节点（G，H，K）
- 第4层：距离B为4的节点（J）

**步骤2：计算最短路径数量**

计算从起始节点B到网络中其他每个节点的最短路径数量。定义节点B到节点I的最短路径数量的方法为$N(i)$，故

- 第0层：起始节点B
- 第1层：与B直接相连的节点$N(A) = 1$,$N(C) = 1$,$N(F) = 1$
- 第2层：距离B为2的节点$N(D) = N(A)=1$,$N(E) = N(A)=1$,$N(I)=N(F) = 1$
- 第3层：距离B为3的节点$N(G) = N(D)+N(I)=2$,$N(H) = N(D)+N(E)=2$,$N(K)=N(I) = 1$
- 第4层：距离B为4的节点$N(J) = N(G)+N(H)+N(K) = 5$

**步骤3：自底向上计算边介数**

每个节点的流 = 1 + 其所有子边的流之和，根据父节点的最短路径数量按比例分配流。

- 第4层：距离B为4的节点（J），J为叶子节点，所以J的流为1，分配边流：
  $$V_{G,J} = \frac{N(G)}{N(J)} \times 1 = \frac{2}{5}, \quad V_{H,J} = \frac{N(H)}{N(J)} \times 1 = \frac{2}{5}, \quad V_{K,J} = \frac{N(K)}{N(J)} \times 1 = \frac{1}{5}$$

- 第3层：距离B为3的节点（G，H，K），计算各自的流：
  - G的流 $= 1 + \frac{2}{5} = \frac{7}{5}$，分配边流：$V_{D,G} = \frac{N(D)}{N(G)} \times \frac{7}{5} = \frac{1}{2} \times \frac{7}{5} = \frac{7}{10}$，$V_{I,G} = \frac{N(I)}{N(G)} \times \frac{7}{5} = \frac{1}{2} \times \frac{7}{5} = \frac{7}{10}$
  - H的流 $= 1 + \frac{2}{5} = \frac{7}{5}$，分配边流：$V_{D,H} = \frac{N(D)}{N(H)} \times \frac{7}{5} = \frac{1}{2} \times \frac{7}{5} = \frac{7}{10}$，$V_{E,H} = \frac{N(E)}{N(H)} \times \frac{7}{5} = \frac{1}{2} \times \frac{7}{5} = \frac{7}{10}$
  - K的流 $= 1 + \frac{1}{5} = \frac{6}{5}$，分配边流：$V_{I,K} = \frac{N(I)}{N(K)} \times \frac{6}{5} = 1 \times \frac{6}{5} = \frac{6}{5}$

- 第2层：距离B为2的节点（D，E，I），计算各自的流：
  - D的流 $= 1 + \frac{7}{10} + \frac{7}{10} = 1 + \frac{14}{10} = \frac{12}{5}$，分配边流：$V_{A,D} = \frac{N(A)}{N(D)} \times \frac{12}{5} = 1 \times \frac{12}{5} = \frac{12}{5}$
  - E的流 $= 1 + \frac{7}{10} = \frac{17}{10}$，分配边流：$V_{A,E} = \frac{N(A)}{N(E)} \times \frac{17}{10} = 1 \times \frac{17}{10} = \frac{17}{10}$
  - I的流 $= 1 + \frac{7}{10} + \frac{6}{5} = 1 + \frac{7}{10} + \frac{12}{10} = \frac{29}{10}$，分配边流：$V_{F,I} = \frac{N(F)}{N(I)} \times \frac{29}{10} = 1 \times \frac{29}{10} = \frac{29}{10}$

- 第1层：距离B为1的节点（A，C，F），计算各自的流：
  - A的流 $= 1 + \frac{12}{5} + \frac{17}{10} = 1 + \frac{24}{10} + \frac{17}{10} = \frac{51}{10}$，分配边流：$V_{B,A} = \frac{51}{10} = 5.1$
  - C的流 $= 1 + 0 = 1$，分配边流：$V_{B,C} = 1$
  - F的流 $= 1 + \frac{29}{10} = \frac{39}{10}$，分配边流：$V_{B,F} = \frac{39}{10} = 3.9$

****

### 三、模块度（Modularity）

#### 1.模块度

模块度（Modularity）是衡量图结构划分优劣的重要指标。

令 G=(V,E) 为一个无向图，其邻接矩阵为 A：

$$A_{ij} = \begin{cases} 
1, & \text{if } (v_i, v_j) \in E \\
0, & \text{otherwise}
\end{cases}$$

模块度的定义为：

$$Q = \frac{1}{2m}\sum_{i,j} \left(A_{ij} - \frac{k_i k_j}{2m}\right)\delta(C_i, C_j)$$

其中，$m$表示**边的数量**，$Ci $表示第 $i$ 个社区。$k_i$ 是顶点 $v_i$ 的**度**（即与顶点  $v_i$  相连的边的数量），$δ(Ci, Cj) = 1（如果 Ci = Cj）$，否则为 0。

**模块度的直观解读**

模块度用于衡量网络被**划分为社区的好坏程度**的一种度量。给定网络被划分为一组 c ∈ C 的情况：

$$Q \propto \sum_{i,j}\left(A_{ij} - \frac{k_i k_j}{2m}\right)\delta(C_i, C_j) = \left[\sum_{i,j} A_{ij} - \sum_{i,j} \frac{k_i k_j}{2m}\right]\delta(C_i, C_j)$$

$$= \sum_{c \in C} [(\# \text{ edges within group } c) - (\text{expected } \# \text{ edges within group } c)]$$

给定一个图 G，含 n 个节点和 m 条边，构建一个随机图 G'：
- 保持相同的度分布，但边是随机生成
- G' 是一个多重图

**模块度计算**

$$Q = \frac{1}{2m}\sum_{c \in C}\sum_{i \in c}\sum_{j \in c}\left(A_{ij} - \frac{k_i k_j}{2m}\right)$$

- 模块度的取值范围是 [-1, 1]
- 如果组内边的数量超过了预期数量，则模块度值为正
- 当模块度 M 大于 0.3 至 0.7 时，意味着输入图中存在显著的社区结构
- 是用于评估社区结构好坏的度量

**模块度案例**

$m = 8, k_1 = 2, k_2 = 2, k_3 = 3, k_4 = 3, k_5 = 2, k_6 = 2, k_7 = 2$

1. **划分方案1**（社区A={1,2,3}，社区B={4,5,6,7}）

   ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANRaV5VaCIwZd3Q4kn5TQwHNxugrp8AAnoOaxtLRfBWBOxKsr6rBD8BAAMCAAN5AAM4BA.png)
   $$
   \begin{aligned}
   Q
   &= \frac{1}{2m}\sum_{i,j}
   \left(
   A_{ij} - \frac{k_i k_j}{16}
   \right)\delta(C_i, C_j) \\[6pt]
   &= \frac{1}{16}\Big[
   (0 - \tfrac{k_1 k_1}{16})
   + 2(1 - \tfrac{k_1 k_2}{16})
   + 2(1 - \tfrac{k_1 k_3}{16})
   + (0 - \tfrac{k_2 k_2}{16}) \\
   &\quad
   + 2(1 - \tfrac{k_2 k_3}{16})
   + (0 - \tfrac{k_3 k_3}{16})
   + (0 - \tfrac{k_4 k_4}{16})
   + 2(1 - \tfrac{k_4 k_5}{16}) \\
   &\quad
   + 2(1 - \tfrac{k_4 k_6}{16})
   + 2(0 - \tfrac{k_4 k_7}{16})
   + (0 - \tfrac{k_5 k_5}{16})
   + 2(0 - \tfrac{k_5 k_6}{16}) \\
   &\quad
   + 2(1 - \tfrac{k_5 k_7}{16})
   + (0 - \tfrac{k_6 k_6}{16})
   + 2(1 - \tfrac{k_6 k_7}{16})
   + (0 - \tfrac{k_7 k_7}{16})
   \Big] \\[6pt]
   &= \frac{51}{128}
   \end{aligned}
   $$

2. 划分方案2（社区A={1,2}，社区B={3,4,5,6,7}）

   ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANSaV5WcL79hn-E7M1rQf59i6qMmy8AAn8OaxtLRfBWmemGRUNSdX0BAAMCAAN5AAM4BA.png)

   
   $$
   \begin{aligned}
   Q
   &= \frac{1}{2m}\sum_{i,j}
   \left(
   A_{ij} - \frac{k_i k_j}{16}
   \right)\delta(C_i, C_j) \\[6pt]
   &= \frac{1}{16}\Big[
   (0 - \tfrac{k_1 k_1}{16})
   + 2(1 - \tfrac{k_1 k_2}{16})
   + (0 - \tfrac{k_2 k_2}{16})
   + (0 - \tfrac{k_3 k_3}{16}) \\
   &\quad
   + 2(1 - \tfrac{k_3 k_4}{16})
   + 2(0 - \tfrac{k_3 k_5}{16})
   + 2(0 - \tfrac{k_3 k_6}{16})
   + 2(0 - \tfrac{k_3 k_7}{16}) \\
   &\quad
   + (0 - \tfrac{k_4 k_4}{16})
   + 2(1 - \tfrac{k_4 k_5}{16})
   + 2(1 - \tfrac{k_4 k_6}{16})
   + 2(0 - \tfrac{k_4 k_7}{16}) \\
   &\quad
   + (0 - \tfrac{k_5 k_5}{16})
   + 2(0 - \tfrac{k_5 k_6}{16})
   + 2(1 - \tfrac{k_5 k_7}{16})
   + (0 - \tfrac{k_6 k_6}{16}) \\
   &\quad
   + 2(1 - \tfrac{k_6 k_7}{16})
   + (0 - \tfrac{k_7 k_7}{16})
   \Big] \\[6pt]
   &= \frac{19}{128}
   \end{aligned}
   $$

#### 2. 模块度应用

---

** （1）针对加权图的模块度**

给定一个无向图 $G = (V, E)$，其邻接矩阵为 $A$，并关联一个权重矩阵 $W$：

$$
W_{ij} =
\begin{cases}
w_{ij}, & \text{if } A_{ij} = 1 \\
0, & \text{otherwise}
\end{cases}
$$

模块度被定义为：

$$
Q = \frac{1}{2m}
\sum_{i,j}
\left(
W_{ij} - \frac{k_i k_j}{2m}
\right)
\delta(C_i, C_j)
$$

其中：

- $m$ 表示图中所有边的**总权重**
- $C_i$ 表示节点 $v_i$ 所属的社区
- $k_i$ 不再是节点 $v_i$ 的度，而是连接到 $v_i$ 的所有边的**权重之和**

---

**（2）针对有向图的模块度**

给定有向图 $G = (V, E)$，其邻接矩阵为 $A$：

$$
A_{ij} =
\begin{cases}
1, & \text{if } (v_i, v_j) \in E \\
0, & \text{otherwise}
\end{cases}
$$

模块度被定义为（**注意分母是 $m$，不是 $2m$**）：

$$
Q = \frac{1}{m}
\sum_{i,j}
\left(
A_{ij} - \frac{k_i^{\text{out}} k_j^{\text{in}}}{m}
\right)
\delta(C_i, C_j)
$$

其中：

- $m$ 表示图中的总边数
- $C_i$ 表示节点 $v_i$ 所属的社区
- $k_i^{\text{out}}$ 和 $k_i^{\text{in}}$ 分别表示节点 $v_i$ 的出度和入度

---

**（3）模块度矩阵形式**

对于无向图，模块度还可以写成矩阵形式。

定义一个 $n \times k$ 的社区指派矩阵 $S$，其中：

- $S_{ir} = 1$ 表示节点 $v_i$ 属于第 $r$ 个社区
- $S_{ir} = 0$ 表示节点 $v_i$ 不属于第 $r$ 个社区

则有：

$$
\delta(C_i, C_j) = \sum_r S_{ir} S_{jr}
$$

定义实对称矩阵 $B$，其元素为：

$$
B_{ij} = A_{ij} - \frac{k_i k_j}{2m}
$$

社区结构的模块度可以改写为：

$$
Q
= \frac{1}{2m}
\sum_{i,j}
\left(
A_{ij} - \frac{k_i k_j}{2m}
\right)
\delta(C_i, C_j)
$$

$$
= \frac{1}{2m}
\sum_{i,j}
B_{ij}
\sum_r S_{ir} S_{jr}
$$

$$
= \frac{1}{2m}
\sum_{i,j}
\sum_r
B_{ij} S_{ir} S_{jr}
$$

$$
= \frac{1}{2m}
\operatorname{Tr}(S^{\mathsf T} B S)
$$

其中，$\operatorname{Tr}(S^{\mathsf T} B S)$ 表示矩阵 $S^{\mathsf T} B S$ 的迹，即其对角元素之和。


#### 3. 谱方法

谱方法：自顶向下的迭代式社区发现方法，基于分裂思想。

- 每次只将一个图分成两个社区，以此类推，直到模块度不再变化为止
- 假设每次划分时，划分的两个社区分别为社区 1 和社区 2
- 顶点要么落在社区 1，要么在社区 2

---

**（1）二分划分变量的定义**

因此定义变量：

$$
s_i =
\begin{cases}
1, & \text{如果顶点 } v_i \text{ 在社区 1} \\
-1, & \text{否则}
\end{cases}
$$

---

**（2）二分情况下的模块度表达式**

因此，二分社区的模块度可以改写为：

$$
Q
= \frac{1}{4m}
\sum_{i,j}
\left(
A_{ij} - \frac{k_i k_j}{2m}
\right)
(s_i s_j + 1)
$$

$$
= \frac{1}{4m}
\sum_{i,j}
\left(
A_{ij} - \frac{k_i k_j}{2m}
\right)
s_i s_j
$$

$$
= \frac{1}{4m}
s^{\mathsf T} B s
$$

其中模块度矩阵 $B$ 定义为：

$$
B_{ij} = A_{ij} - \frac{k_i k_j}{2m}
$$

注意到，在模块度矩阵 $B$ 中，每一行和每一列的元素之和均为 0，因此向量
$(1,1,\dots,1)$ 是特征值为 0 的特征向量。

---

**（3）模块度矩阵的谱分解**

假设模块度矩阵 $B$ 具有 $n$ 个正交特征向量 $\{u_i\}$，对应特征值为：

$$
\beta_1 \ge \beta_2 \ge \cdots \ge \beta_n
$$

因此，划分向量 $s = (s_1, s_2, \dots, s_n)$ 可以展开为：

$$
s = \sum_{i=1}^n a_i u_i,
\qquad
a_i = u_i^{\mathsf T} s
$$

---

**（4）模块度的谱展开形式**

将上述展开代入模块度表达式，得到：

$$
Q
= \frac{1}{4m}
\sum_i a_i u_i^{\mathsf T} B
\sum_j a_j u_j
$$

利用特征向量的正交性，可进一步化简为：

$$
Q
= \frac{1}{4m}
\sum_{i=1}^n
(u_i^{\mathsf T} s)^2 \beta_i
$$

由此可见，模块度由所有特征值 $\beta_i$ 共同决定。

---

**（5）基于最大特征值的近似最优化**

给定图 $G$，其模块度矩阵 $B$ 的特征值和特征向量是固定的。

为了最大化模块度，需要考虑所有特征值 $\beta_i$，但计算代价较高。

因此，通常仅考虑最大的特征值 $\beta_1$ 及其对应的特征向量 $u_1$。

若对划分向量 $s$ 不加限制，最优解应使 $s$ 与 $u_1$ 平行。

但由于 $s_i \in \{1, -1\}$，问题转化为最大化点积 $u_1^{\mathsf T} s$。

因此定义划分规则为：

$$
s_i =
\begin{cases}
1, & \text{如果 } u_{1i} > 0 \\
-1, & \text{否则}
\end{cases}
$$

即在最大特征值对应的特征向量 $u_1$ 中：

- 同号分量对应的顶点属于同一社区
- 不同号分量对应的顶点属于不同社区

---

**（6）扩展到多个社区的递归划分问题**

鉴于图中可能包含超过 2 个社区，因此希望可以划分为更多部分。

一种自然的做法是重复进行二分划分：

- 首先将网络分成两部分
- 然后对每个子图继续应用上述方法

但这种方法并不正确，原因在于：

- 边的删除会改变模块度的定义
- 后续的模块度最大化将不断放大误差

---

**（7）基于模块度增量的正确递归策略**

为避免上述问题，每次仅考虑划分带来的模块度增量。

设子社区 $g$ 的规模为 $n$，其模块度增量定义为：

$$
\Delta Q
= \frac{1}{2m}
\left[
\frac{1}{2}
\sum_{i,j \in g} B_{ij}(s_i s_j + 1)
- \sum_{i,j \in g} B_{ij}
\right]
$$

$$
= \frac{1}{4m}
\left[
\sum_{i,j \in g} B_{ij} s_i s_j
- \sum_{i,j \in g} B_{ij}
\right]
$$

$$
= \frac{1}{4m}
\sum_{i,j \in g}
\left[
B_{ij}
- \delta_{ij}
\sum_{k \in g} B_{ik}
\right]
s_i s_j
$$

$$
= \frac{1}{4m}
s^{\mathsf T} B^{(g)} s
$$

其中，当 $i=j$ 时 $\delta_{ij}=1$，否则 $\delta_{ij}=0$。

---

因此，仅当模块度增量 $\Delta Q > 0$ 时，才继续划分该子社区；否则停止划分。

由此可以保证，每一次社区划分都会使整体模块度单调增加。


### 四、Louvain 方法

#### 1. Louvain 方法概述

Louvain 方法是一种社区检测的贪心算法，具有以下特点：

- 支持有向图和加权图
- 提供层次化分区
- 社区数量不是超参数，算法自动确定
- 广泛用于研究大型网络，因为：
  - 快速：运行时间仅为 $O(|E|)$，其中 $|E|$ 是边的数量
  - 收敛速度快
  - 输出的模块度高（即“更好的社区”）

Louvain 算法以**贪心方式**逐步最大化模块度。  
每次遍历包含两个阶段，迭代重复这些遍历，直到模块度不再增加为止。

---

#### 2. 模块度重写

在 Louvain 方法中，模块度可以重写为更便于计算的形式：

$$
M
= \frac{1}{2m}
\sum_{i,j}
\left(
A_{ij} - \frac{k_i k_j}{2m}
\right)
\delta(C_i, C_j)
$$

$$
= \left[
\sum_{i,j} \frac{A_{ij}}{2m}
- \frac{\sum_i k_i \sum_j k_j}{4m^2}
\right]
\delta(C_i, C_j)
$$

$$
= \sum_{c \in C}
\left[
\frac{\Sigma_{in}^c}{2m}
- \left(
\frac{\Sigma_{tot}^c}{2m}
\right)^2
\right]
$$

其中：

- $\Sigma_{in}^c$ 是社区 $c$ 内部顶点之间的边权重之和
- $\Sigma_{tot}^c$ 是社区 $c$ 中所有顶点的边权重总和
- $m$ 是图中所有边的权重总和

---

#### 3. Louvain 方法：阶段 1（模块度重写）

**初始化：**  
将图中的每个顶点放入一个独立的社区（每个社区一个顶点）。

**迭代过程：**  
对于每个顶点 $v_i$，算法执行以下计算：

**（1）** 计算当把顶点 $v_i$ 从其当前社区移动到某个邻近顶点 $v_j$ 的社区时模块度的增量 $\Delta Q$  
**（2）** 将 $v_i$ 移动到能够产生最大模块度增量 $\Delta Q$ 的社区  
**（3）** 循环运行直到没有移动能带来增益为止

第一阶段在达到模块度的局部最大值时停止，即当任何单个移动都不能再改进模块度时。

需要注意的是，算法的输出依赖于考虑顶点的顺序，但研究表明顶点顺序对最终模块度的影响并不显著。

---

#### 4. 模块度增益计算

**模块度变化的两个部分：**

模块度的变化可以分为两个部分：

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANTaV5faZtI_tsmseZ_WIQdgqyVIOcAApkOaxtLRfBWgwfq6Z7HJQ0BAAMCAAN5AAM4BA.png)

- **增益**：$\Delta Q(v_i \to C)$，表示将顶点 $v_i$ 移动到社区 $C$ 时模块度 $Q$ 的增益
- **损失**：$\Delta Q(D \to v_i)$，表示将顶点 $v_i$ 从社区 $D$ 中移出时模块度 $Q$ 的损失

---

**将顶点 $v_i$ 移入社区 $C$ 的增益：**
$$
\Delta Q(v_i \to C)
=
\left[
\frac{\Sigma_{in}^C + k_{i,in}^C}{2m}
- \left(
\frac{\Sigma_{tot}^C + k_i}{2m}
\right)^2
\right]
-
\left[
\frac{\Sigma_{in}^C}{2m}
- \left(
\frac{\Sigma_{tot}^C}{2m}
\right)^2
- \left(
\frac{k_i}{2m}
\right)^2
\right]
$$

$$
=
\left[
\frac{k_{i,in}^C}{2m}
- \frac{\Sigma_{tot}^C \cdot k_i}{2m^2}
\right]
$$

其中：

- $k_{i,in}^C$ 是顶点 $v_i$ 与社区 $C$ 内部顶点之间的边权重之和
- $k_i$ 是顶点 $v_i$ 的度（所有相连边的权重之和）

---

**将顶点 $v_i$ 从社区 $D$ 中移出的损失：**

设 $D'$ 是移出 $v_i$ 后的社区 $D$，则：

$$
\Delta Q(D \to v_i)
= - \Delta Q(v_i \to D')
$$

$$
=
\frac{\Sigma_{tot}^{D'} \cdot k_i}{2m^2}
- \frac{k_{i,in}^{D'}}{2m}
$$

---

**总的模块度变化：**

$$
\Delta Q
= \Delta Q(v_i \to C)
+ \Delta Q(D \to v_i)
$$

---

#### 5. Louvain 方法：阶段 2（社区聚合）

在第一阶段获得的分区被收缩成超级节点，并按照以下方式创建加权网络：

- 如果对应社区之间的顶点之间至少存在一条边，则超级节点之间是连接的。
- 两个超级节点之间边的权重是它们对应分区之间所有边的权重之和。
- 聚合之后，图成为一个加权图，

---

#### 7. Louvain 方法分析

**计算效率：**

- 算法运行速度快，在第一次遍历后社区数量急剧减少
- 后续遍历中的计算量显著降低
- 模块度增益计算简单
- 时间复杂度为 $O(|E|)$  对于包含 $10^6$ 个顶点的图，找到社区结构所需时间通常不到 1 分钟

**其他优势：**

- 社区数量**不是超参**数，算法自动确定
- 可以用于评估社区结构的质量
- 可通过模块度曲线确定最佳的簇数量

---

**模块度用于确定簇的数量：**

在**层次聚类**等方法中，可以通过计算不同切割高度下的模块度，
选择模块度最大时对应的簇数量作为最优划分。

模块度曲线通常呈现“先上升、后下降”的趋势，其峰值对应最佳的社区划分。


---

# 第九讲 子模函数及其应用

## 一、应用背景

#### 1.特征选择（Feature Selection）
- **问题描述**：给定一组特征 X₁, ..., Xₙ，构造子集 A = (Xᵢ₁, ..., Xᵢₖ) 用以预测目标变量 Y
- **核心问题**：如何选取 k 个特征，使子集信息量最丰富？
- **信息增益**：I(A; Y) = H(Y) − H(Y | A)
  - H(Y)：Y 的熵（表示不确定性）
  - H(Y | A)：给定 A 条件下 Y 的条件熵
  - I(A; Y) 描述通过知道 A 能够获得关于 Y 的信息量

#### 2.影响力最大化（Influence Maximization）
- 基于社交网络，向哪些用户投放广告以达到最佳传播效果
- 找出最具影响力的博客或个人，将信息快速、有效地传播给受众

#### 3.传感器部署（Sensor Placement）

- **问题**：给定水分配网络，如何部署传感器以快速检测污染？
- **函数定义**：f(A) 表示在子集 A 处部署传感器的效用值
- **效用特性**：
  - 信息量高的配置（如 A = {1, 2, 3}）：f(A) 值大
  - 信息冗余度大的配置（如 A = {1, 4, 5}）：f(A) 值较低
  
  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANUaV5jKXZi9WeFQH5M638icsCCJ9IAAtYLaxtLRfhWFZG4A5qdE4MBAAMCAAN5AAM4BA.png)

#### 4.图的割函数（Graph Cut）

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANSaV5WcL79hn-E7M1rQf59i6qMmy8AAn8OaxtLRfBWmemGRUNSdX0BAAMCAAN5AAM4BA.png)

- **定义**：对无向图 G(V, E)，割函数 f(S) = |{(u, v) | u ∈ S ⊂ V, v ∈ Sᶜ}|
- **含义**：集合 S 与其补集之间的边数
- **示例**：S = {1, 2, 3} 时 f(S) = 1；S = {1, 2} 时 f(S) = 2

#### 5. 连续优化

**凸函数优化（求最小值）**

- 若 f: Rⁿ → R 是**凸函数**，则可高效获取最小值
- **凸函数特性**：连接凸函数图像上任意两点的线段总是在函数图像**之上**或**恰好位于**图像上
- 几何直观：U形曲线，底部有唯一最小值点

**凹函数优化（求最大值）**

- 若 f: Rⁿ → R 是**凹函数**，则可高效获取最大值
- **凹函数特性**：连接凹函数图像上任意两点的线段总是在函数图像**之下**或**恰好位于**图像上
- 几何直观：倒U形曲线，顶部有唯一最大值点

#### 6. 离散优化：从凹性到子模性

**连续优化中的凹函数**

- 若 f : Rⁿ → R 是凹函数，则可高效获取最大值
- 连接凹函数图像上任意两点的线段总在函数图像之下或恰好位于图像上
- 导数 f'(x) 随 x 增加而非递增

**离散情况下的子模性**

- 对于函数 f : {0,1}ⁿ → R
- 离散导数：∂ᵢf(x) = f(x + eᵢ) − f(x)
- 若 ∂ᵢf(x) 随 x 增加而非递增，则函数是子模的
- eᵢ 表示第 i 个分量为 1，其余分量为 0 的单位向量

---

## 二、子模函数

#### 1. 集合函数基础

**定义**

- 给定有限集合 V = {1, 2, ···, n}
- 集合函数：f : 2^V → R（或 f : {0, 1}ⁿ → R）
- 2^V 是集合 V 的幂集

**集合函数的基本性质**

1. **单调性**：若 A ⊆ B ⊆ X，则 F(A) ≤ F(B)
2. **非负性**：对于所有 S ⊆ X，F(A) ≥ 0
3. **规范化**：F(∅) = 0

#### 2.子模性定义

![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANWaV5lr_Hw0NXqRAOI5SBaO_JzPrwAAuELaxtLRfhW58TfAAEECVARAQADAgADeQADOAQ.png)

**定义1：基本形式**

对于函数 f : 2^V → R，如果对于所有 A, B ⊆ V，均有：

​	$f(A) + f(B) ≥ f(A ∪ B) + f(A ∩ B)$ 则该函数是子模的。

等价形式：$f(A) − f(A ∩ B) ≥ f(A ∪ B) − f(B)$

**定义2：边际效用递减**

对于所有 $S ⊆ T ⊆ V$，对于所有 $v ∈ V  T$：$f(S ∪ {v}) − f(S) ≥ f(T ∪ {v}) − f(T)$

**经济学解释**：对象在更大的上下文中增加的价值逐渐减少

**定义3：群体边际效用递减**

对于所有 S ⊆ T ⊆ V，且 C ⊆ V \ T：$f(S ∪ C) − f(S) ≥ f(T ∪ C) − f(T)$
#### 4. 子模性的闭合性质

子模性在非负线性组合下具有闭合性质：

1. **非负线性组合**：若 f₁ 和 f₂ 都是子模函数，a₁, a₂ ≥ 0，则 a₁f₁ + a₂f₂ 是子模函数

2. **集合限制**：若 S ⊂ V 是固定集合，则 f'(A) = f(A ∩ S) 和 f(A) = f(Aᶜ) 都是子模的

3. **期望保持**：若 fθ(A) 是子模的，则 Σθ P(θ)fθ(A) 也是子模的

4. **多目标优化**：若 f₁, ···, fₘ 都是子模的，且 λᵢ > 0，则 Σᵢλᵢfᵢ(A) 也是子模的

#### 5. 典型案例

**案例1：传感器部署**

- **边际效应**：Δf(s|A) = f(A ∪ {s}) − f(A)

- 若 A = {1, 2}，增加部署 s 的效果显著

- 若 A = {1, 2, 3}，增加部署 s 的效果一般

- **验证子模性**：∀A ⊂ B，s ∉ B，Δf(s|A) ≥ Δf(s|B)

  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANUaV5jKXZi9WeFQH5M638icsCCJ9IAAtYLaxtLRfhWFZG4A5qdE4MBAAMCAAN5AAM4BA.png)

  

**案例2：计算不同颜色数量**

- 给定一组球的集合 S，f(S) 计算不同颜色的数量

- 子模性：对象在更大上下文中增加的价值逐渐减少

  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANXaV5miALOKTzjr_C6OeCkJcEFO7oAAucLaxtLRfhWEE4mA1oSBO4BAAMCAAN4AAM4BA.png)

**案例3：集合覆盖**

- C 的覆盖定义为：f(C) = |⋃_{sᵢ∈C} sᵢ|

- 满足单调性和子模性

  ![](https://telegraph-image-43w.pages.dev/file/AgACAgUAAyEGAATTNkFKAANYaV5nkfDhNPdeX0WIvKaYWdv0WnAAAu0LaxtLRfhWrcZqq_4ZEyMBAAMCAAN5AAM4BA.png)

---

## 三、集合覆盖问题

#### 1. k-最大覆盖问题

**问题定义**

- **集合覆盖**：每个条目 u 是由某些基础元素组成的子集
- **覆盖函数**：f(S) = |⋃_{u∈S} u|（所有属于 S 中子集的并集的大小）
- **边际覆盖增加**：f(S ∪ {v}) − f(S)

**k-最大覆盖问题**

- **目标**：寻找 k 个子集，使联合覆盖尽可能大
- **复杂性**：NP-hard 问题（无多项式时间算法，除非 P=NP）

**示例（k=2）**

- 给定：
  - 真实集合：{a, b, c, d, e, f, g, h, i, j, k, l}
  - 子集：
    - A₁ = {a, b, c, d}
    - A₂ = {e, f, g, h}
    - A₃ = {i, j, k, l}
    - A₄ = {a, e}
    - A₅ = {i, b, f, g}
    - A₆ = {c, d, g, h, k, l}
    - A₇ = {l}

- **计算**：
  - A₆ 有 6 个元素，A₁, A₂, A₃, A₅ 各有 4 个元素
  - |A1 ∪ A6| = 8, |A2 ∪ A6| = 8, |A3 ∪ A6| = 8, |A5 ∪ A6| = 9
- |A₅ ∪ A₆| = 9（最大）
  
- **结果**：C = {A₅, A₆} 是最大覆盖集合

#### 2. 抽取式文本摘要问题

**给定**：
- 关键词集合 W = {w₁, w₂, ···, wₙ}
- 句子集合 S = {s₁, s₂, ···, sₘ}
- 每个 sⱼ = {wₖ | wₖ ∈ W}

**目标**：找到 k 个句子，包含尽可能多的关键词

**数学表达**：
```
最大化：Σⱼ₌₁ⁿ Σᵢ₌₁ᵐ Xᵢsᵢⱼ
约束条件：Σᵢ₌₁ᵐ Xᵢ = k
```

其中：
- Xᵢ = 1（若 sᵢ ∈ C），0（否则）
- sᵢⱼ = 1（若 wᵢ ∈ sⱼ），0（否则）

#### 3.子模覆盖

C的覆盖被定义为：f(C)=|⋃1_(s_i∈C)▒s_i |

令 C ⊂ D, 且 sk ∈ D, 我们有：

f(C∪{S_k })-f(C)=|s_k-⋃1_(S_i∈C)▒s_i |≥|s_k-⋃1_(s_i∈D)▒s_i |=f(D∪{s_k })-f(D)

此外, 由于 ⋃1_(s_i∈C)▒〖s_i⊂⋃1_(s_i∈D)▒s_i 〗 , 则：f (C) ≤ f (D).

#### 4. 爬山算法（Greedy Algorithm）

**算法流程**

```
1. 初始化 C = ∅
2. for i = 1 to k do
3.   c = arg max_{s∈S\C} [f(C ∪ {s}) − f(C)]
4.   C = C ∪ {c}
5. output C
```

**理论保证**

若集合函数 f 是单调、子模的，且 f(∅) = 0，则贪心算法可达到 **(1 − 1/e)** 的近似率：

```
f(S) ≥ (1 − 1/e) max_{S'⊆V, |S'|=k} f(S')
```

其中 e ≈ 2.718（自然常数）

**算法示例**

- **给定**：
  - 关键词集合 W = {w₁, w₂, ···, w₈}
  - 9个句子 s₁, s₂, ..., s₉
  - 目标：选择 k=3 个句子
- **第一轮**：
  - 计算每个句子的覆盖增益 Δ(Sᵢ)
  - s₄ 具有最大覆盖增益（Δ = 4），被选中
  - C = {s₄}
- **第二轮**：
  - 在剩余句子中计算边际增益
  - s₅ 和 s₈ 具有最大边际增益（Δ = 2）
  - 选择 s₅
  - C = {s₄, s₅}
- **第三轮**：
  - s₁, s₈, s₉ 具有相同边际增益（Δ = 1）
  - 选择 s₁
  - C = {s₄, s₅, s₁}

- **最终输出**：C = {s₄, s₅, s₁}

#### 5. 最小规模集合覆盖问题

**问题定义**

- **输入**：
  - 元素集合 X = {e₁, e₂, ..., eₙ}
  - m 个子集 S₁, S₂, ..., Sₘ ⊆ E
- **输出**：找到集合 I ⊆ {1,2,...,m}，满足：
  - ⋃ᵢ∈I Sᵢ = X
  - |I| 最小化

- **注意**：顶点覆盖问题是集合覆盖问题的特例

**实际案例**

软件公司员工各有不同技能（C++, Python, Linux, Database, Network...）
- 项目需要多种技能 a₁, a₂, ...
- 如何组建最精干的队伍完成项目？

**贪心近似算法**

```
Greedy-Set-Cover(X, F)
1. U ← X
2. I ← ∅
3. while U ≠ ∅
4.   选择 Sᵢ 使得 |Sᵢ ∩ U| 最大
5.   U ← U − Sᵢ
6.   I ← I ∪ {i}
7. return I
```

**理论结果**

**定理**：GREEDY-SET-COVER 是一个多项式时间的 ρ(n) 近似算法，其中：
```
ρ(n) = H(max{|S| : S ∈ F})
```
H 是调和级数：H(d) = 1 + 1/2 + 1/3 + ... + 1/d
